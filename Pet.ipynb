{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063ba929-72fc-43a5-8f85-66079ed63853",
   "metadata": {},
   "source": [
    "# Basic Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d922f5f-d752-4957-a2f2-23a60230e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import tqdm\n",
    "import clip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import funct\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4c2f59-d6b1-4432-b28f-d8299badbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdad181-783f-43f3-a3ed-6a0627656034",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0da918-6eff-4984-a4e1-fe571975f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# datasets for fine-tuning and evaluating resnet50\n",
    "resnet_train = datasets.OxfordIIITPet(root='./data',split='trainval',download=True,transform=transform)\n",
    "resnet_test=datasets.OxfordIIITPet(root='./data',split='test',download=True,transform=transform)\n",
    "# dataset for evaluating Clip\n",
    "clip_test=datasets.OxfordIIITPet(root='./data',split='test',download=True)\n",
    "\n",
    "train_dataloader=torch.utils.data.DataLoader(resnet_train,batch_size=50,shuffle=True,num_workers=2)\n",
    "test_dataloader=torch.utils.data.DataLoader(resnet_test,batch_size=20,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c3b3b-fad4-4784-9642-a42fce62cc33",
   "metadata": {},
   "source": [
    "# Evaluating CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acfa6fc-1a7b-4188-9789-6ad913c07731",
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUAL_BACKBONE='RN50x64'\n",
    "names=resnet_train.classes\n",
    "\n",
    "model, preprocess = clip.load(VISUAL_BACKBONE, device ,download_root='/shareddata/clip/')\n",
    "\n",
    "text_inputs=torch.cat([clip.tokenize(f\"a photo of the pet {c}\") for c in names]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de200dc2-641d-4dc2-bd5e-df67fcf605a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [03:15<00:00, 18.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of Clip on OxfordIIITPet dataset is 93.32%, visual encoder is RN50x64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=funct.clip_testing(model,preprocess,clip_test,device,text_inputs)\n",
    "\n",
    "print(f\"the accuracy of Clip on OxfordIIITPet dataset is {accuracy*100:.2f}%, visual encoder is {VISUAL_BACKBONE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16ffeb-839f-4579-8c2f-456295969215",
   "metadata": {},
   "source": [
    "# Fine-tuning and Evaluating ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbad9dd-4186-448c-93fc-38a3d0e622de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet50=models.resnet50(pretrained=True)\n",
    "resnet50.fc=torch.nn.Linear(2048,37) ##add a fully connected layer to adjust the output dimension\n",
    "resnet50=resnet50.to(device)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0dd424a-7dc6-4f71-9ebb-d1964072245e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:18<00:00,  3.95it/s]\n",
      "100%|██████████| 184/184 [00:09<00:00, 18.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of ResNet on OxfordIIITPet dataset is 75.33%, the training epoch is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:17<00:00,  4.13it/s]\n",
      "100%|██████████| 74/74 [00:18<00:00,  4.02it/s]\n",
      "100%|██████████| 74/74 [00:17<00:00,  4.14it/s]\n",
      "100%|██████████| 74/74 [00:18<00:00,  3.99it/s]\n",
      "100%|██████████| 184/184 [00:10<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of ResNet on OxfordIIITPet dataset is 88.28%, the training epoch is 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:18<00:00,  4.05it/s]\n",
      "100%|██████████| 74/74 [00:18<00:00,  4.00it/s]\n",
      "100%|██████████| 74/74 [00:18<00:00,  4.02it/s]\n",
      "100%|██████████| 74/74 [00:18<00:00,  4.03it/s]\n",
      "100%|██████████| 184/184 [00:10<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of ResNet on OxfordIIITPet dataset is 90.52%, the training epoch is 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:18<00:00,  4.11it/s]\n",
      "100%|██████████| 74/74 [00:18<00:00,  4.04it/s]\n",
      "100%|██████████| 74/74 [00:17<00:00,  4.12it/s]\n",
      "100%|██████████| 74/74 [00:17<00:00,  4.17it/s]\n",
      "100%|██████████| 184/184 [00:09<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of ResNet on OxfordIIITPet dataset is 90.76%, the training epoch is 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:17<00:00,  4.21it/s]\n",
      "100%|██████████| 74/74 [00:17<00:00,  4.16it/s]\n",
      "100%|██████████| 74/74 [00:17<00:00,  4.17it/s]\n",
      "100%|██████████| 74/74 [00:18<00:00,  4.11it/s]\n",
      "100%|██████████| 184/184 [00:08<00:00, 21.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of ResNet on OxfordIIITPet dataset is 90.92%, the training epoch is 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:17<00:00,  4.17it/s]\n",
      "100%|██████████| 74/74 [00:17<00:00,  4.20it/s]\n",
      "100%|██████████| 74/74 [00:17<00:00,  4.11it/s]\n",
      "100%|██████████| 184/184 [00:10<00:00, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of ResNet on OxfordIIITPet dataset is 91.09%, the training epoch is 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH): # training resnet50 until the accuracy converges.\n",
    "    funct.resnet_training(resnet50,criterion,optimizer,train_dataloader,device)\n",
    "    if(i%4==0 or i+1==EPOCH):\n",
    "        corrects=funct.resnet_testing(resnet50,test_dataloader,device)\n",
    "        accuracy=corrects/len(resnet_test)\n",
    "        print(f\"the accuracy of ResNet on OxfordIIITPet dataset is {accuracy*100:.2f}%, the training epoch is {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28deecf0-90e0-4447-9790-db535218e3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1/30 Train Loss: 0.0334 Acc: 0.0467\n",
      "Begin test......\n",
      "Test Loss: 0.0326 Acc: 0.0536\n",
      "Epoch: 2/30 Train Loss: 0.0318 Acc: 0.0705\n",
      "Begin test......\n",
      "Test Loss: 0.0309 Acc: 0.0908\n",
      "Epoch: 3/30 Train Loss: 0.0310 Acc: 0.0822\n",
      "Begin test......\n",
      "Test Loss: 0.0311 Acc: 0.0951\n",
      "Epoch: 4/30 Train Loss: 0.0308 Acc: 0.0892\n",
      "Begin test......\n",
      "Test Loss: 0.0305 Acc: 0.1006\n",
      "Epoch: 5/30 Train Loss: 0.0307 Acc: 0.0901\n",
      "Begin test......\n",
      "Test Loss: 0.0305 Acc: 0.1065\n",
      "Epoch: 6/30 Train Loss: 0.0295 Acc: 0.1159\n",
      "Begin test......\n",
      "Test Loss: 0.0289 Acc: 0.1344\n",
      "Epoch: 7/30 Train Loss: 0.0290 Acc: 0.1248\n",
      "Begin test......\n",
      "Test Loss: 0.0285 Acc: 0.1460\n",
      "Epoch: 8/30 Train Loss: 0.0289 Acc: 0.1288\n",
      "Begin test......\n",
      "Test Loss: 0.0287 Acc: 0.1423\n",
      "Epoch: 9/30 Train Loss: 0.0287 Acc: 0.1312\n",
      "Begin test......\n",
      "Test Loss: 0.0280 Acc: 0.1523\n",
      "Epoch: 10/30 Train Loss: 0.0285 Acc: 0.1395\n",
      "Begin test......\n",
      "Test Loss: 0.0280 Acc: 0.1538\n",
      "Epoch: 11/30 Train Loss: 0.0274 Acc: 0.1585\n",
      "Begin test......\n",
      "Test Loss: 0.0270 Acc: 0.1747\n",
      "Epoch: 12/30 Train Loss: 0.0273 Acc: 0.1631\n",
      "Begin test......\n",
      "Test Loss: 0.0264 Acc: 0.1913\n",
      "Epoch: 13/30 Train Loss: 0.0272 Acc: 0.1643\n",
      "Begin test......\n",
      "Test Loss: 0.0263 Acc: 0.1928\n",
      "Epoch: 14/30 Train Loss: 0.0271 Acc: 0.1668\n",
      "Begin test......\n",
      "Test Loss: 0.0263 Acc: 0.1963\n",
      "Epoch: 15/30 Train Loss: 0.0269 Acc: 0.1709\n",
      "Begin test......\n",
      "Test Loss: 0.0262 Acc: 0.1980\n",
      "Epoch: 16/30 Train Loss: 0.0262 Acc: 0.1867\n",
      "Begin test......\n",
      "Test Loss: 0.0254 Acc: 0.2099\n",
      "Epoch: 17/30 Train Loss: 0.0260 Acc: 0.1917\n",
      "Begin test......\n",
      "Test Loss: 0.0262 Acc: 0.1979\n",
      "Epoch: 18/30 Train Loss: 0.0260 Acc: 0.1935\n",
      "Begin test......\n",
      "Test Loss: 0.0253 Acc: 0.2155\n",
      "Epoch: 19/30 Train Loss: 0.0259 Acc: 0.1951\n",
      "Begin test......\n",
      "Test Loss: 0.0252 Acc: 0.2181\n",
      "Epoch: 20/30 Train Loss: 0.0259 Acc: 0.1948\n",
      "Begin test......\n",
      "Test Loss: 0.0256 Acc: 0.2056\n",
      "Epoch: 21/30 Train Loss: 0.0254 Acc: 0.2081\n",
      "Begin test......\n",
      "Test Loss: 0.0245 Acc: 0.2304\n",
      "Epoch: 22/30 Train Loss: 0.0253 Acc: 0.2099\n",
      "Begin test......\n",
      "Test Loss: 0.0244 Acc: 0.2346\n",
      "Epoch: 23/30 Train Loss: 0.0252 Acc: 0.2117\n",
      "Begin test......\n",
      "Test Loss: 0.0245 Acc: 0.2375\n",
      "Epoch: 24/30 Train Loss: 0.0253 Acc: 0.2107\n",
      "Begin test......\n",
      "Test Loss: 0.0246 Acc: 0.2326\n",
      "Epoch: 25/30 Train Loss: 0.0252 Acc: 0.2134\n",
      "Begin test......\n",
      "Test Loss: 0.0243 Acc: 0.2427\n",
      "Epoch: 26/30 Train Loss: 0.0249 Acc: 0.2205\n",
      "Begin test......\n",
      "Test Loss: 0.0243 Acc: 0.2402\n",
      "Epoch: 27/30 Train Loss: 0.0248 Acc: 0.2229\n",
      "Begin test......\n",
      "Test Loss: 0.0242 Acc: 0.2469\n",
      "Epoch: 28/30 Train Loss: 0.0248 Acc: 0.2214\n",
      "Begin test......\n",
      "Test Loss: 0.0241 Acc: 0.2452\n",
      "Epoch: 29/30 Train Loss: 0.0248 Acc: 0.2237\n",
      "Begin test......\n",
      "Test Loss: 0.0240 Acc: 0.2504\n",
      "Epoch: 30/30 Train Loss: 0.0247 Acc: 0.2254\n",
      "Begin test......\n",
      "Test Loss: 0.0241 Acc: 0.2506\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-100 transform\n",
    "transform_cifar100_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set_cifar100 = torchvision.datasets.CIFAR100(root='../data', train=True,\n",
    "                                                   download=True, transform=transform_cifar100_train)\n",
    "train_dataloader_cifar100 = torch.utils.data.DataLoader(train_set_cifar100, batch_size=BATCH_SIZE,\n",
    "                                                        shuffle=True, num_workers=2)\n",
    "\n",
    "test_set_cifar100 = torchvision.datasets.CIFAR100(root='../data', train=False,\n",
    "                                                  download=True, transform=transform_cifar100_test)\n",
    "test_dataloader_cifar100 = torch.utils.data.DataLoader(test_set_cifar100, batch_size=BATCH_SIZE,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "\n",
    "class_names_cifar100 = [str(i) for i in range(100)]  # CIFAR-100 has 100 classes\n",
    "\n",
    "# Modify the model to accommodate 100 output classes\n",
    "class ConvNetCIFAR100(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetCIFAR100, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 100)  # Change the output to 100 classes for CIFAR-100\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the modified model\n",
    "model_cifar100 = ConvNetCIFAR100()\n",
    "model_cifar100.to(device)\n",
    "\n",
    "optimizer_cifar100 = optim.SGD(model_cifar100.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler_cifar100 = torch.optim.lr_scheduler.StepLR(optimizer_cifar100, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "criterion_cifar100 = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_batch(model_cifar100, image, target):\n",
    "    output = model_cifar100(image)\n",
    "    loss = criterion_cifar100(output, target)\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model_cifar100, image, target):\n",
    "    output = model_cifar100(image)\n",
    "    loss = criterion_cifar100(output, target)\n",
    "    return output, loss\n",
    "\n",
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model_cifar100.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader_cifar100):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model_cifar100, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_cifar100.step()\n",
    "        optimizer_cifar100.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set_cifar100)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set_cifar100)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler_cifar100.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model_cifar100.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader_cifar100):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model_cifar100, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set_cifar100)\n",
    "        val_acc = val_corrects.double() / len(test_set_cifar100)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model_cifar100.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1/30 Train Loss: 0.0173 Acc: 0.2024\n",
      "Begin test......\n",
      "Test Loss: 0.0175 Acc: 0.1983\n",
      "Epoch: 2/30 Train Loss: 0.0161 Acc: 0.2396\n",
      "Begin test......\n",
      "Test Loss: 0.0229 Acc: 0.1852\n",
      "Epoch: 3/30 Train Loss: 0.0170 Acc: 0.2192\n",
      "Begin test......\n",
      "Test Loss: 0.0165 Acc: 0.2144\n",
      "Epoch: 4/30 Train Loss: 0.0158 Acc: 0.2594\n",
      "Begin test......\n",
      "Test Loss: 0.0150 Acc: 0.2943\n",
      "Epoch: 5/30 Train Loss: 0.0148 Acc: 0.2942\n",
      "Begin test......\n",
      "Test Loss: 0.0145 Acc: 0.2986\n",
      "Epoch: 6/30 Train Loss: 0.0140 Acc: 0.3364\n",
      "Begin test......\n",
      "Test Loss: 0.0138 Acc: 0.3282\n",
      "Epoch: 7/30 Train Loss: 0.0135 Acc: 0.3636\n",
      "Begin test......\n",
      "Test Loss: 0.0133 Acc: 0.3623\n",
      "Epoch: 8/30 Train Loss: 0.0133 Acc: 0.3648\n",
      "Begin test......\n",
      "Test Loss: 0.0132 Acc: 0.3530\n",
      "Epoch: 9/30 Train Loss: 0.0130 Acc: 0.3762\n",
      "Begin test......\n",
      "Test Loss: 0.0131 Acc: 0.3659\n",
      "Epoch: 10/30 Train Loss: 0.0129 Acc: 0.3798\n",
      "Begin test......\n",
      "Test Loss: 0.0132 Acc: 0.3788\n",
      "Epoch: 11/30 Train Loss: 0.0124 Acc: 0.4148\n",
      "Begin test......\n",
      "Test Loss: 0.0126 Acc: 0.4055\n",
      "Epoch: 12/30 Train Loss: 0.0122 Acc: 0.4208\n",
      "Begin test......\n",
      "Test Loss: 0.0124 Acc: 0.4128\n",
      "Epoch: 13/30 Train Loss: 0.0120 Acc: 0.4308\n",
      "Begin test......\n",
      "Test Loss: 0.0124 Acc: 0.4138\n",
      "Epoch: 14/30 Train Loss: 0.0121 Acc: 0.4260\n",
      "Begin test......\n",
      "Test Loss: 0.0121 Acc: 0.4341\n",
      "Epoch: 15/30 Train Loss: 0.0118 Acc: 0.4410\n",
      "Begin test......\n",
      "Test Loss: 0.0121 Acc: 0.4298\n",
      "Epoch: 16/30 Train Loss: 0.0117 Acc: 0.4436\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.4379\n",
      "Epoch: 17/30 Train Loss: 0.0115 Acc: 0.4468\n",
      "Begin test......\n",
      "Test Loss: 0.0123 Acc: 0.4280\n",
      "Epoch: 18/30 Train Loss: 0.0116 Acc: 0.4548\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.4416\n",
      "Epoch: 19/30 Train Loss: 0.0115 Acc: 0.4506\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.4360\n",
      "Epoch: 20/30 Train Loss: 0.0114 Acc: 0.4568\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.4363\n",
      "Epoch: 21/30 Train Loss: 0.0114 Acc: 0.4632\n",
      "Begin test......\n",
      "Test Loss: 0.0119 Acc: 0.4446\n",
      "Epoch: 22/30 Train Loss: 0.0113 Acc: 0.4712\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.4536\n",
      "Epoch: 23/30 Train Loss: 0.0111 Acc: 0.4712\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.4497\n",
      "Epoch: 24/30 Train Loss: 0.0112 Acc: 0.4720\n",
      "Begin test......\n",
      "Test Loss: 0.0117 Acc: 0.4504\n",
      "Epoch: 25/30 Train Loss: 0.0112 Acc: 0.4748\n",
      "Begin test......\n",
      "Test Loss: 0.0117 Acc: 0.4525\n",
      "Epoch: 26/30 Train Loss: 0.0110 Acc: 0.4764\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.4569\n",
      "Epoch: 27/30 Train Loss: 0.0110 Acc: 0.4718\n",
      "Begin test......\n",
      "Test Loss: 0.0117 Acc: 0.4536\n",
      "Epoch: 28/30 Train Loss: 0.0109 Acc: 0.4808\n",
      "Begin test......\n",
      "Test Loss: 0.0117 Acc: 0.4535\n",
      "Epoch: 29/30 Train Loss: 0.0109 Acc: 0.4818\n",
      "Begin test......\n",
      "Test Loss: 0.0117 Acc: 0.4589\n",
      "Epoch: 30/30 Train Loss: 0.0109 Acc: 0.4752\n",
      "Begin test......\n",
      "Test Loss: 0.0117 Acc: 0.4544\n"
     ]
    }
   ],
   "source": [
    "# STL-10 transform\n",
    "transform_stl10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(96, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "transform_stl10_test = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_set_stl10 = torchvision.datasets.STL10(root='../data', split='train',\n",
    "                                             download=True, transform=transform_stl10_train)\n",
    "train_dataloader_stl10 = torch.utils.data.DataLoader(train_set_stl10, batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True, num_workers=2)\n",
    "\n",
    "test_set_stl10 = torchvision.datasets.STL10(root='../data', split='test',\n",
    "                                            download=True, transform=transform_stl10_test)\n",
    "test_dataloader_stl10 = torch.utils.data.DataLoader(test_set_stl10, batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False, num_workers=2)\n",
    "\n",
    "class_names_stl10 = ['airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck']\n",
    "\n",
    "# Modify the model to accommodate 10 output classes\n",
    "class ConvNetSTL10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetSTL10, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)  # Change the output to 10 classes for STL-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the modified model\n",
    "model_stl10 = ConvNetSTL10()\n",
    "model_stl10.to(device)\n",
    "\n",
    "optimizer_stl10 = optim.SGD(model_stl10.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler_stl10 = torch.optim.lr_scheduler.StepLR(optimizer_stl10, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "criterion_stl10 = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_batch(model_stl10, image, target):\n",
    "    output = model_stl10(image)\n",
    "    loss = criterion_stl10(output, target)\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model_stl10, image, target):\n",
    "    output = model_stl10(image)\n",
    "    loss = criterion_cifar100(output, target)\n",
    "    return output, loss\n",
    "\n",
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model_stl10.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader_stl10):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model_stl10, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_stl10.step()\n",
    "        optimizer_stl10.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set_stl10)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set_stl10)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler_stl10.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model_stl10.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader_stl10):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model_stl10, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set_stl10)\n",
    "        val_acc = val_corrects.double() / len(test_set_stl10)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model_stl10.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cifar10在之前作业已得到数据，故不运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### cifar100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_cifar100_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "#裁剪到相同scale\n",
    "\n",
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar100_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar100_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion =nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    output =  model(image)\n",
    "    loss = criterion(output, target)\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    output =  model(image)\n",
    "    loss = criterion(output, target)\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0156 Acc: 0.2512\n",
      "Train Recall: 0.2512 F1 Score: 0.2377\n",
      "Begin test......\n",
      "Test Loss: 0.0142 Acc: 0.3326\n",
      "Test Recall: 0.3326 F1 Score: 0.3041\n",
      "Epoch: 2/30 Train Loss: 0.0144 Acc: 0.3095\n",
      "Train Recall: 0.2804 F1 Score: 0.2704\n",
      "Begin test......\n",
      "Test Loss: 0.0139 Acc: 0.3410\n",
      "Test Recall: 0.3410 F1 Score: 0.3338\n",
      "Epoch: 3/30 Train Loss: 0.0142 Acc: 0.3248\n",
      "Train Recall: 0.2952 F1 Score: 0.2862\n",
      "Begin test......\n",
      "Test Loss: 0.0138 Acc: 0.3389\n",
      "Test Recall: 0.3389 F1 Score: 0.3161\n",
      "Epoch: 4/30 Train Loss: 0.0140 Acc: 0.3274\n",
      "Train Recall: 0.3032 F1 Score: 0.2950\n",
      "Begin test......\n",
      "Test Loss: 0.0132 Acc: 0.3690\n",
      "Test Recall: 0.3690 F1 Score: 0.3342\n",
      "Epoch: 5/30 Train Loss: 0.0140 Acc: 0.3300\n",
      "Train Recall: 0.3086 F1 Score: 0.3006\n",
      "Begin test......\n",
      "Test Loss: 0.0132 Acc: 0.3695\n",
      "Test Recall: 0.3695 F1 Score: 0.3572\n",
      "Epoch: 6/30 Train Loss: 0.0132 Acc: 0.3669\n",
      "Train Recall: 0.3183 F1 Score: 0.3105\n",
      "Begin test......\n",
      "Test Loss: 0.0126 Acc: 0.4093\n",
      "Test Recall: 0.4093 F1 Score: 0.3908\n",
      "Epoch: 7/30 Train Loss: 0.0131 Acc: 0.3747\n",
      "Train Recall: 0.3264 F1 Score: 0.3189\n",
      "Begin test......\n",
      "Test Loss: 0.0124 Acc: 0.4194\n",
      "Test Recall: 0.4194 F1 Score: 0.4031\n",
      "Epoch: 8/30 Train Loss: 0.0130 Acc: 0.3792\n",
      "Train Recall: 0.3330 F1 Score: 0.3258\n",
      "Begin test......\n",
      "Test Loss: 0.0121 Acc: 0.4226\n",
      "Test Recall: 0.4226 F1 Score: 0.4110\n",
      "Epoch: 9/30 Train Loss: 0.0129 Acc: 0.3922\n",
      "Train Recall: 0.3396 F1 Score: 0.3326\n",
      "Begin test......\n",
      "Test Loss: 0.0122 Acc: 0.4349\n",
      "Test Recall: 0.4349 F1 Score: 0.4116\n",
      "Epoch: 10/30 Train Loss: 0.0127 Acc: 0.4024\n",
      "Train Recall: 0.3458 F1 Score: 0.3391\n",
      "Begin test......\n",
      "Test Loss: 0.0123 Acc: 0.4426\n",
      "Test Recall: 0.4426 F1 Score: 0.4367\n",
      "Epoch: 11/30 Train Loss: 0.0122 Acc: 0.4286\n",
      "Train Recall: 0.3534 F1 Score: 0.3469\n",
      "Begin test......\n",
      "Test Loss: 0.0116 Acc: 0.4708\n",
      "Test Recall: 0.4708 F1 Score: 0.4603\n",
      "Epoch: 12/30 Train Loss: 0.0121 Acc: 0.4329\n",
      "Train Recall: 0.3600 F1 Score: 0.3537\n",
      "Begin test......\n",
      "Test Loss: 0.0115 Acc: 0.4695\n",
      "Test Recall: 0.4695 F1 Score: 0.4522\n",
      "Epoch: 13/30 Train Loss: 0.0120 Acc: 0.4337\n",
      "Train Recall: 0.3657 F1 Score: 0.3595\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.4461\n",
      "Test Recall: 0.4461 F1 Score: 0.4454\n",
      "Epoch: 14/30 Train Loss: 0.0119 Acc: 0.4419\n",
      "Train Recall: 0.3711 F1 Score: 0.3651\n",
      "Begin test......\n",
      "Test Loss: 0.0111 Acc: 0.4959\n",
      "Test Recall: 0.4959 F1 Score: 0.4877\n",
      "Epoch: 15/30 Train Loss: 0.0119 Acc: 0.4435\n",
      "Train Recall: 0.3759 F1 Score: 0.3700\n",
      "Begin test......\n",
      "Test Loss: 0.0111 Acc: 0.4845\n",
      "Test Recall: 0.4845 F1 Score: 0.4781\n",
      "Epoch: 16/30 Train Loss: 0.0115 Acc: 0.4606\n",
      "Train Recall: 0.3812 F1 Score: 0.3755\n",
      "Begin test......\n",
      "Test Loss: 0.0110 Acc: 0.4959\n",
      "Test Recall: 0.4959 F1 Score: 0.4871\n",
      "Epoch: 17/30 Train Loss: 0.0115 Acc: 0.4624\n",
      "Train Recall: 0.3860 F1 Score: 0.3804\n",
      "Begin test......\n",
      "Test Loss: 0.0109 Acc: 0.4987\n",
      "Test Recall: 0.4987 F1 Score: 0.4874\n",
      "Epoch: 18/30 Train Loss: 0.0114 Acc: 0.4669\n",
      "Train Recall: 0.3905 F1 Score: 0.3850\n",
      "Begin test......\n",
      "Test Loss: 0.0110 Acc: 0.4981\n",
      "Test Recall: 0.4981 F1 Score: 0.4931\n",
      "Epoch: 19/30 Train Loss: 0.0114 Acc: 0.4714\n",
      "Train Recall: 0.3948 F1 Score: 0.3893\n",
      "Begin test......\n",
      "Test Loss: 0.0107 Acc: 0.5103\n",
      "Test Recall: 0.5103 F1 Score: 0.5024\n",
      "Epoch: 20/30 Train Loss: 0.0113 Acc: 0.4724\n",
      "Train Recall: 0.3986 F1 Score: 0.3933\n",
      "Begin test......\n",
      "Test Loss: 0.0108 Acc: 0.5071\n",
      "Test Recall: 0.5071 F1 Score: 0.4944\n",
      "Epoch: 21/30 Train Loss: 0.0112 Acc: 0.4784\n",
      "Train Recall: 0.4024 F1 Score: 0.3972\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.5246\n",
      "Test Recall: 0.5246 F1 Score: 0.5151\n",
      "Epoch: 22/30 Train Loss: 0.0111 Acc: 0.4819\n",
      "Train Recall: 0.4061 F1 Score: 0.4008\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5236\n",
      "Test Recall: 0.5236 F1 Score: 0.5189\n",
      "Epoch: 23/30 Train Loss: 0.0111 Acc: 0.4857\n",
      "Train Recall: 0.4095 F1 Score: 0.4044\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5251\n",
      "Test Recall: 0.5251 F1 Score: 0.5234\n",
      "Epoch: 24/30 Train Loss: 0.0111 Acc: 0.4874\n",
      "Train Recall: 0.4128 F1 Score: 0.4077\n",
      "Begin test......\n",
      "Test Loss: 0.0104 Acc: 0.5316\n",
      "Test Recall: 0.5316 F1 Score: 0.5250\n",
      "Epoch: 25/30 Train Loss: 0.0111 Acc: 0.4860\n",
      "Train Recall: 0.4157 F1 Score: 0.4107\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.5203\n",
      "Test Recall: 0.5203 F1 Score: 0.5189\n",
      "Epoch: 26/30 Train Loss: 0.0109 Acc: 0.4920\n",
      "Train Recall: 0.4186 F1 Score: 0.4137\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5296\n",
      "Test Recall: 0.5296 F1 Score: 0.5182\n",
      "Epoch: 27/30 Train Loss: 0.0109 Acc: 0.4942\n",
      "Train Recall: 0.4214 F1 Score: 0.4165\n",
      "Begin test......\n",
      "Test Loss: 0.0103 Acc: 0.5342\n",
      "Test Recall: 0.5342 F1 Score: 0.5267\n",
      "Epoch: 28/30 Train Loss: 0.0109 Acc: 0.4917\n",
      "Train Recall: 0.4239 F1 Score: 0.4191\n",
      "Begin test......\n",
      "Test Loss: 0.0103 Acc: 0.5402\n",
      "Test Recall: 0.5402 F1 Score: 0.5341\n",
      "Epoch: 29/30 Train Loss: 0.0109 Acc: 0.4950\n",
      "Train Recall: 0.4264 F1 Score: 0.4216\n",
      "Begin test......\n",
      "Test Loss: 0.0104 Acc: 0.5325\n",
      "Test Recall: 0.5325 F1 Score: 0.5233\n",
      "Epoch: 30/30 Train Loss: 0.0109 Acc: 0.4973\n",
      "Train Recall: 0.4288 F1 Score: 0.4240\n",
      "Begin test......\n",
      "Test Loss: 0.0103 Acc: 0.5343\n",
      "Test Recall: 0.5343 F1 Score: 0.5282\n"
     ]
    }
   ],
   "source": [
    "CRtraining_loss = []\n",
    "CRtraining_acc = []\n",
    "CRtesting_loss = []\n",
    "CRtesting_acc = []\n",
    "CRtrain_preds = []\n",
    "CRtrain_targets = []\n",
    "CRtest_preds = []\n",
    "CRtest_targets = []\n",
    "CRtrain_f1_scores = []\n",
    "CRtest_f1_scores = []\n",
    "CRlayer_gradients = [[] for _ in range(len(list(model.parameters())))]\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        CRtrain_preds.extend(preds.cpu().tolist())\n",
    "        CRtrain_targets.extend(target.cpu().tolist())\n",
    "\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        for i, (name, param) in enumerate(model.named_parameters()):\n",
    "            if param.grad is not None:\n",
    "                CRlayer_gradients[i].append(param.grad.abs().mean().item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    CRtrain_recall = recall_score(CRtrain_targets, CRtrain_preds, average='weighted')\n",
    "    CRtrain_f1 = f1_score(CRtrain_targets, CRtrain_preds, average='weighted')\n",
    "    CRtrain_f1_scores.append(CRtrain_f1)\n",
    "    CRepoch_loss = running_cls_loss / len(train_set)\n",
    "    CRepoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {CRepoch_loss:.4f} Acc: {CRepoch_acc:.4f}')\n",
    "    print(f'Train Recall: {CRtrain_recall:.4f} F1 Score: {CRtrain_f1:.4f}')\n",
    "    CRtraining_loss.append(CRepoch_loss)\n",
    "    CRtraining_acc.append(CRepoch_acc.cpu().detach().numpy())\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "\n",
    "        CRval_loss = 0.0\n",
    "        CRval_corrects = 0\n",
    "        CRtest_preds = []\n",
    "        CRtest_targets = []\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            CRtest_preds.extend(preds.cpu().tolist())\n",
    "            CRtest_targets.extend(target.cpu().tolist())\n",
    "\n",
    "            CRval_loss += loss.item()\n",
    "            CRval_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        CRtest_recall = recall_score(CRtest_targets, CRtest_preds, average='weighted')\n",
    "        CRtest_f1 = f1_score(CRtest_targets, CRtest_preds, average='weighted')\n",
    "        CRtest_f1_scores.append(CRtest_f1)\n",
    "        CRval_loss = CRval_loss / len(test_set)\n",
    "        CRval_acc = CRval_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {CRval_loss:.4f} Acc: {CRval_acc:.4f}')\n",
    "        print(f'Test Recall: {CRtest_recall:.4f} F1 Score: {CRtest_f1:.4f}')\n",
    "        CRtesting_loss.append(CRval_loss)\n",
    "        CRtesting_acc.append(CRval_acc.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 94523550.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 33658153.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 21108653.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 5436794.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform_mnist_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "transform_mnist_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 加载 MNIST 训练数据集\n",
    "train_set = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                       download=True, transform=transform_mnist_train)\n",
    "train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, num_workers=2)\n",
    "\n",
    "# 加载 MNIST 测试数据集\n",
    "test_set = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                      download=True, transform=transform_mnist_test)\n",
    "test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, num_workers=2)\n",
    "\n",
    "# 类别名称\n",
    "class_names = [str(i) for i in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3)  # 修改为 1 个输入通道\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
    "        # 调整全连接层的输入尺寸\n",
    "        self.fc1 = nn.Linear(8 * 5 * 5, 32)  # 注意这里的尺寸可能需要调整\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 5 * 5)  # 注意这里的尺寸可能需要调整\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model=model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion =nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0037 Acc: 0.8555\n",
      "Train Recall: 0.8555 F1 Score: 0.8551\n",
      "Begin test......\n",
      "Test Loss: 0.0016 Acc: 0.9409\n",
      "Test Recall: 0.9409 F1 Score: 0.9409\n",
      "Epoch: 2/30 Train Loss: 0.0017 Acc: 0.9333\n",
      "Train Recall: 0.8944 F1 Score: 0.8942\n",
      "Begin test......\n",
      "Test Loss: 0.0014 Acc: 0.9517\n",
      "Test Recall: 0.9517 F1 Score: 0.9519\n",
      "Epoch: 3/30 Train Loss: 0.0015 Acc: 0.9407\n",
      "Train Recall: 0.9098 F1 Score: 0.9097\n",
      "Begin test......\n",
      "Test Loss: 0.0019 Acc: 0.9323\n",
      "Test Recall: 0.9323 F1 Score: 0.9325\n",
      "Epoch: 4/30 Train Loss: 0.0015 Acc: 0.9433\n",
      "Train Recall: 0.9182 F1 Score: 0.9181\n",
      "Begin test......\n",
      "Test Loss: 0.0012 Acc: 0.9559\n",
      "Test Recall: 0.9559 F1 Score: 0.9559\n",
      "Epoch: 5/30 Train Loss: 0.0014 Acc: 0.9448\n",
      "Train Recall: 0.9235 F1 Score: 0.9234\n",
      "Begin test......\n",
      "Test Loss: 0.0014 Acc: 0.9481\n",
      "Test Recall: 0.9481 F1 Score: 0.9482\n",
      "Epoch: 6/30 Train Loss: 0.0010 Acc: 0.9596\n",
      "Train Recall: 0.9295 F1 Score: 0.9295\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.9640\n",
      "Test Recall: 0.9640 F1 Score: 0.9640\n",
      "Epoch: 7/30 Train Loss: 0.0009 Acc: 0.9624\n",
      "Train Recall: 0.9342 F1 Score: 0.9342\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.9699\n",
      "Test Recall: 0.9699 F1 Score: 0.9699\n",
      "Epoch: 8/30 Train Loss: 0.0009 Acc: 0.9637\n",
      "Train Recall: 0.9379 F1 Score: 0.9379\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.9640\n",
      "Test Recall: 0.9640 F1 Score: 0.9639\n",
      "Epoch: 9/30 Train Loss: 0.0009 Acc: 0.9650\n",
      "Train Recall: 0.9409 F1 Score: 0.9409\n",
      "Begin test......\n",
      "Test Loss: 0.0010 Acc: 0.9617\n",
      "Test Recall: 0.9617 F1 Score: 0.9617\n",
      "Epoch: 10/30 Train Loss: 0.0009 Acc: 0.9639\n",
      "Train Recall: 0.9432 F1 Score: 0.9432\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.9664\n",
      "Test Recall: 0.9664 F1 Score: 0.9665\n",
      "Epoch: 11/30 Train Loss: 0.0007 Acc: 0.9705\n",
      "Train Recall: 0.9457 F1 Score: 0.9457\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.9718\n",
      "Test Recall: 0.9718 F1 Score: 0.9718\n",
      "Epoch: 12/30 Train Loss: 0.0007 Acc: 0.9719\n",
      "Train Recall: 0.9479 F1 Score: 0.9478\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.9717\n",
      "Test Recall: 0.9717 F1 Score: 0.9717\n",
      "Epoch: 13/30 Train Loss: 0.0007 Acc: 0.9712\n",
      "Train Recall: 0.9497 F1 Score: 0.9496\n",
      "Begin test......\n",
      "Test Loss: 0.0009 Acc: 0.9650\n",
      "Test Recall: 0.9650 F1 Score: 0.9651\n",
      "Epoch: 14/30 Train Loss: 0.0007 Acc: 0.9715\n",
      "Train Recall: 0.9512 F1 Score: 0.9512\n",
      "Begin test......\n",
      "Test Loss: 0.0008 Acc: 0.9717\n",
      "Test Recall: 0.9717 F1 Score: 0.9716\n",
      "Epoch: 15/30 Train Loss: 0.0007 Acc: 0.9720\n",
      "Train Recall: 0.9526 F1 Score: 0.9526\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.9721\n",
      "Test Recall: 0.9721 F1 Score: 0.9721\n",
      "Epoch: 16/30 Train Loss: 0.0006 Acc: 0.9745\n",
      "Train Recall: 0.9540 F1 Score: 0.9540\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.9732\n",
      "Test Recall: 0.9732 F1 Score: 0.9732\n",
      "Epoch: 17/30 Train Loss: 0.0006 Acc: 0.9750\n",
      "Train Recall: 0.9552 F1 Score: 0.9552\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.9754\n",
      "Test Recall: 0.9754 F1 Score: 0.9754\n",
      "Epoch: 18/30 Train Loss: 0.0006 Acc: 0.9753\n",
      "Train Recall: 0.9563 F1 Score: 0.9563\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.9744\n",
      "Test Recall: 0.9744 F1 Score: 0.9744\n",
      "Epoch: 19/30 Train Loss: 0.0006 Acc: 0.9756\n",
      "Train Recall: 0.9573 F1 Score: 0.9573\n",
      "Begin test......\n",
      "Test Loss: 0.0007 Acc: 0.9750\n",
      "Test Recall: 0.9750 F1 Score: 0.9750\n",
      "Epoch: 20/30 Train Loss: 0.0006 Acc: 0.9757\n",
      "Train Recall: 0.9583 F1 Score: 0.9582\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9755\n",
      "Test Recall: 0.9755 F1 Score: 0.9755\n",
      "Epoch: 21/30 Train Loss: 0.0006 Acc: 0.9777\n",
      "Train Recall: 0.9592 F1 Score: 0.9592\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9767\n",
      "Test Recall: 0.9767 F1 Score: 0.9767\n",
      "Epoch: 22/30 Train Loss: 0.0006 Acc: 0.9771\n",
      "Train Recall: 0.9600 F1 Score: 0.9600\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9758\n",
      "Test Recall: 0.9758 F1 Score: 0.9758\n",
      "Epoch: 23/30 Train Loss: 0.0006 Acc: 0.9778\n",
      "Train Recall: 0.9608 F1 Score: 0.9608\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9763\n",
      "Test Recall: 0.9763 F1 Score: 0.9763\n",
      "Epoch: 24/30 Train Loss: 0.0006 Acc: 0.9776\n",
      "Train Recall: 0.9615 F1 Score: 0.9615\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9766\n",
      "Test Recall: 0.9766 F1 Score: 0.9766\n",
      "Epoch: 25/30 Train Loss: 0.0006 Acc: 0.9774\n",
      "Train Recall: 0.9621 F1 Score: 0.9621\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9750\n",
      "Test Recall: 0.9750 F1 Score: 0.9750\n",
      "Epoch: 26/30 Train Loss: 0.0005 Acc: 0.9784\n",
      "Train Recall: 0.9627 F1 Score: 0.9627\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9758\n",
      "Test Recall: 0.9758 F1 Score: 0.9758\n",
      "Epoch: 27/30 Train Loss: 0.0005 Acc: 0.9785\n",
      "Train Recall: 0.9633 F1 Score: 0.9633\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9757\n",
      "Test Recall: 0.9757 F1 Score: 0.9757\n",
      "Epoch: 28/30 Train Loss: 0.0005 Acc: 0.9788\n",
      "Train Recall: 0.9639 F1 Score: 0.9639\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9770\n",
      "Test Recall: 0.9770 F1 Score: 0.9770\n",
      "Epoch: 29/30 Train Loss: 0.0005 Acc: 0.9782\n",
      "Train Recall: 0.9644 F1 Score: 0.9644\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9770\n",
      "Test Recall: 0.9770 F1 Score: 0.9770\n",
      "Epoch: 30/30 Train Loss: 0.0005 Acc: 0.9790\n",
      "Train Recall: 0.9648 F1 Score: 0.9648\n",
      "Begin test......\n",
      "Test Loss: 0.0006 Acc: 0.9764\n",
      "Test Recall: 0.9764 F1 Score: 0.9764\n"
     ]
    }
   ],
   "source": [
    "CRtraining_loss = []\n",
    "CRtraining_acc = []\n",
    "CRtesting_loss = []\n",
    "CRtesting_acc = []\n",
    "CRtrain_preds = []\n",
    "CRtrain_targets = []\n",
    "CRtest_preds = []\n",
    "CRtest_targets = []\n",
    "CRtrain_f1_scores = []\n",
    "CRtest_f1_scores = []\n",
    "CRlayer_gradients = [[] for _ in range(len(list(model.parameters())))]\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        CRtrain_preds.extend(preds.cpu().tolist())\n",
    "        CRtrain_targets.extend(target.cpu().tolist())\n",
    "\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        for i, (name, param) in enumerate(model.named_parameters()):\n",
    "            if param.grad is not None:\n",
    "                CRlayer_gradients[i].append(param.grad.abs().mean().item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    CRtrain_recall = recall_score(CRtrain_targets, CRtrain_preds, average='weighted')\n",
    "    CRtrain_f1 = f1_score(CRtrain_targets, CRtrain_preds, average='weighted')\n",
    "    CRtrain_f1_scores.append(CRtrain_f1)\n",
    "    CRepoch_loss = running_cls_loss / len(train_set)\n",
    "    CRepoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {CRepoch_loss:.4f} Acc: {CRepoch_acc:.4f}')\n",
    "    print(f'Train Recall: {CRtrain_recall:.4f} F1 Score: {CRtrain_f1:.4f}')\n",
    "    CRtraining_loss.append(CRepoch_loss)\n",
    "    CRtraining_acc.append(CRepoch_acc.cpu().detach().numpy())\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "\n",
    "        CRval_loss = 0.0\n",
    "        CRval_corrects = 0\n",
    "        CRtest_preds = []\n",
    "        CRtest_targets = []\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            CRtest_preds.extend(preds.cpu().tolist())\n",
    "            CRtest_targets.extend(target.cpu().tolist())\n",
    "\n",
    "            CRval_loss += loss.item()\n",
    "            CRval_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        CRtest_recall = recall_score(CRtest_targets, CRtest_preds, average='weighted')\n",
    "        CRtest_f1 = f1_score(CRtest_targets, CRtest_preds, average='weighted')\n",
    "        CRtest_f1_scores.append(CRtest_f1)\n",
    "        CRval_loss = CRval_loss / len(test_set)\n",
    "        CRval_acc = CRval_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {CRval_loss:.4f} Acc: {CRval_acc:.4f}')\n",
    "        print(f'Test Recall: {CRtest_recall:.4f} F1 Score: {CRtest_f1:.4f}')\n",
    "        CRtesting_loss.append(CRval_loss)\n",
    "        CRtesting_acc.append(CRval_acc.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

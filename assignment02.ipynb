{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Application of CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip\n",
    "\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "VISUAL_BACKBONE = ['RN50','RN101','ViT-B/32','ViT-B/16','ViT-L/14'] # RN50, RN101, RN50x4, RN50x16, ViT-B/32, ViT-B/16, ViT-L/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "#     transforms.Resize(size=224),\n",
    "#     transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='/shareddata', train=True,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "test_set = torchvision.datasets.CIFAR10(root='/shareddata', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "dataset_name = 'CIFAR10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_food101_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Adjust normalization values\n",
    "])\n",
    "\n",
    "transform_food101_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Adjust normalization values\n",
    "])\n",
    "\n",
    "# Load FOOD101 dataset\n",
    "train_set = torchvision.datasets.Food101(root='/shareddata', split='train',\n",
    "                                                  download=True, transform=transform_food101_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                                       shuffle=True, num_workers=2)\n",
    "\n",
    "test_set= torchvision.datasets.Food101(root='/shareddata', split='test',\n",
    "                                                download=True, transform=transform_food101_test)\n",
    "test_dataloader= torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                                      shuffle=False, num_workers=2)\n",
    "\n",
    "# Define class names for FOOD101 dataset\n",
    "class_names = train_set.classes\n",
    "dataset_name = 'FOOD101'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# 定义训练集和测试集路径\n",
    "train_path = 'data/train'\n",
    "test_path = 'data/test'\n",
    "\n",
    "# 加载训练集\n",
    "train_set = ImageFolder(root=train_path, transform=transform)\n",
    "train_dataloader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载测试集\n",
    "test_set = ImageFolder(root=test_path, transform=transform)\n",
    "test_dataloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "class_names = ['Covid-19','No_findings','Pneumonia']\n",
    "dataset_name = 'COVID-19'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_MNIST_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.13251467,), (0.31048027,)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root='/shareddata', train=True,\n",
    "                                     download=True, transform=transform_MNIST_test)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "test_set = torchvision.datasets.MNIST(root='/shareddata', train=False,\n",
    "                                     download=True, transform=transform_MNIST_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "dataset_name = 'MNIST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "def clipModel(VISUAL):\n",
    "    model, preprocess = clip.load(name=VISUAL, device=device, download_root='/shareddata/clip/')\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'A photo of a' # you can try different prompt\n",
    "\n",
    "def prompt_encode(prompt):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        prompt (str): the text prefix before the class\n",
    "\n",
    "    Returns:\n",
    "        text_inputs(torch.Tensor)\n",
    "\n",
    "    \"\"\"\n",
    "    text_inputs = torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in class_names]).to(device) \n",
    "\n",
    "    return text_inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model, image, text_inputs):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "    \n",
    "        logits,_=model(image,text_inputs)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on FOOD101 is 68.27%, visual encoder is RN50.\n",
      "Time taken for this loop: 122.24733400344849 seconds\n",
      "the zero-shot performance on FOOD101 is 72.58%, visual encoder is RN101.\n",
      "Time taken for this loop: 161.1329128742218 seconds\n",
      "the zero-shot performance on FOOD101 is 77.85%, visual encoder is ViT-B/32.\n",
      "Time taken for this loop: 78.58697891235352 seconds\n",
      "the zero-shot performance on FOOD101 is 84.17%, visual encoder is ViT-B/16.\n",
      "Time taken for this loop: 186.66975164413452 seconds\n"
     ]
    }
   ],
   "source": [
    "perf = []\n",
    "for i in range(len(VISUAL_BACKBONE)):\n",
    "    model = clipModel(VISUAL_BACKBONE[i])\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        var_correct = 0\n",
    "        for image, target in test_dataloader:\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            _, preds = torch.max(model_inference(model, image, prompt_encode(prompt)), 1)\n",
    "\n",
    "            var_correct += torch.sum(preds == target.data)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        val_acc = var_correct / len(test_set)\n",
    "        perf.append({\"accuracy\": val_acc, \"time\": elapsed_time})\n",
    "\n",
    "        print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE[i]}.\")\n",
    "        print(f\"Time taken for this loop: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7244444444444444\n",
      "Training time: 348.6578907966614 seconds\n",
      "Testing time: 0.08835625648498535 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# X_train = train_set.data\n",
    "# y_train = train_set.targets\n",
    "# X_test = test_set.data\n",
    "# y_test = test_set.targets\n",
    "\n",
    "# X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "# X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "# Iterate through the training data loader to get images and labels\n",
    "for images, labels in train_dataloader:\n",
    "    X_train.append(images.view(images.size(0), -1).numpy())\n",
    "    y_train.append(labels.numpy())\n",
    "\n",
    "# Iterate through the test data loader to get images and labels\n",
    "for images, labels in test_dataloader:\n",
    "    X_test.append(images.view(images.size(0), -1).numpy())\n",
    "    y_test.append(labels.numpy())\n",
    "\n",
    "# Concatenate the batches to get the full datasets\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "# def dataset_to_numpy(dataset):\n",
    "#     data = []\n",
    "#     labels = []\n",
    "#     for i in range(len(dataset)):\n",
    "#         sample = dataset[i]\n",
    "#         data.append(sample[0].view(1, -1).numpy())\n",
    "#         labels.append(sample[1])\n",
    "#     return np.stack(data), np.array(labels)\n",
    "\n",
    "# X_train, y_train = dataset_to_numpy(train_set)\n",
    "# X_test, y_test = dataset_to_numpy(test_set)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "print(\"Testing time:\", testing_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6755555555555556\n",
      "Training time: 94.6327064037323 seconds\n",
      "Testing time: 0.011090755462646484 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# X_train = train_set.data\n",
    "# y_train = train_set.targets\n",
    "# X_test = test_set.data\n",
    "# y_test = test_set.targets\n",
    "\n",
    "# X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "# X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "# Iterate through the training data loader to get images and labels\n",
    "for images, labels in train_dataloader:\n",
    "    X_train.append(images.view(images.size(0), -1).numpy())\n",
    "    y_train.append(labels.numpy())\n",
    "\n",
    "# Iterate through the test data loader to get images and labels\n",
    "for images, labels in test_dataloader:\n",
    "    X_test.append(images.view(images.size(0), -1).numpy())\n",
    "    y_test.append(labels.numpy())\n",
    "\n",
    "# Concatenate the batches to get the full datasets\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "# def dataset_to_numpy(dataset):\n",
    "#     data = []\n",
    "#     labels = []\n",
    "#     for i in range(len(dataset)):\n",
    "#         sample = dataset[i]\n",
    "#         data.append(sample[0].view(1, -1).numpy())\n",
    "#         labels.append(sample[1])\n",
    "#     return np.stack(data), np.array(labels)\n",
    "\n",
    "# X_train, y_train = dataset_to_numpy(train_set)\n",
    "# X_test, y_test = dataset_to_numpy(test_set)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "print(\"Testing time:\", testing_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7422222222222222\n",
      "Training time: 23.756004095077515 seconds\n",
      "Testing time: 0.019083261489868164 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# X_train = train_set.data\n",
    "# y_train = train_set.targets\n",
    "# X_test = test_set.data\n",
    "# y_test = test_set.targets\n",
    "\n",
    "# X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "# X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "# Iterate through the training data loader to get images and labels\n",
    "for images, labels in train_dataloader:\n",
    "    X_train.append(images.view(images.size(0), -1).numpy())\n",
    "    y_train.append(labels.numpy())\n",
    "\n",
    "# Iterate through the test data loader to get images and labels\n",
    "for images, labels in test_dataloader:\n",
    "    X_test.append(images.view(images.size(0), -1).numpy())\n",
    "    y_test.append(labels.numpy())\n",
    "\n",
    "# Concatenate the batches to get the full datasets\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "# def dataset_to_numpy(dataset):\n",
    "#     data = []\n",
    "#     labels = []\n",
    "#     for i in range(len(dataset)):\n",
    "#         sample = dataset[i]\n",
    "#         data.append(sample[0].view(1, -1).numpy())\n",
    "#         labels.append(sample[1])\n",
    "#     return np.stack(data), np.array(labels)\n",
    "\n",
    "# X_train, y_train = dataset_to_numpy(train_set)\n",
    "# X_test, y_test = dataset_to_numpy(test_set)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "print(\"Testing time:\", testing_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 08:52:59.240099: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-02 08:52:59.335934: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-02 08:52:59.773732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-02 08:52:59.773760: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-02 08:52:59.776492: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-02 08:53:00.036239: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "Training time: 526.8241138458252 seconds\n",
      "Accuracy: 98.37%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import mnist\n",
    "(x_train_image,y_train_label), (x_test_image,y_test_label) = mnist.load_data()\n",
    "\n",
    "x_train = x_train_image.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test_image.reshape(10000, 784).astype('float32') / 255\n",
    "clf = svm.SVC(C=5.0, kernel='rbf', gamma=0.05)\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(x_train, y_train_label)\n",
    "print(\"Training time: {} seconds\".format(time.time() - start_time))\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_label, y_pred)\n",
    "print(\"Accuracy: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 592/592 [02:12<00:00,  4.48it/s]\n",
      "Epoch 2/15: 100%|██████████| 592/592 [02:13<00:00,  4.44it/s]\n",
      "Epoch 3/15: 100%|██████████| 592/592 [02:12<00:00,  4.46it/s]\n",
      "Epoch 4/15: 100%|██████████| 592/592 [02:13<00:00,  4.44it/s]\n",
      "Epoch 5/15: 100%|██████████| 592/592 [02:11<00:00,  4.49it/s]\n",
      "Epoch 6/15: 100%|██████████| 592/592 [02:12<00:00,  4.45it/s]\n",
      "Epoch 7/15: 100%|██████████| 592/592 [02:13<00:00,  4.45it/s]\n",
      "Epoch 8/15: 100%|██████████| 592/592 [02:16<00:00,  4.34it/s]\n",
      "Epoch 9/15: 100%|██████████| 592/592 [02:12<00:00,  4.46it/s]\n",
      "Epoch 10/15: 100%|██████████| 592/592 [02:14<00:00,  4.41it/s]\n",
      "Epoch 11/15: 100%|██████████| 592/592 [02:09<00:00,  4.56it/s]\n",
      "Epoch 12/15: 100%|██████████| 592/592 [02:11<00:00,  4.51it/s]\n",
      "Epoch 13/15: 100%|██████████| 592/592 [02:12<00:00,  4.48it/s]\n",
      "Epoch 14/15: 100%|██████████| 592/592 [02:11<00:00,  4.50it/s]\n",
      "Epoch 15/15: 100%|██████████| 592/592 [02:11<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1990.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 198/198 [00:52<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time: 52.31 seconds\n",
      "Acc: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 15\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 54 * 54, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 54 * 54)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_batch(model, image, target):    \n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    return output, loss\n",
    "def test_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    return output, loss\n",
    "\n",
    "start_train_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_data_loader = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{NUM_EPOCHS}', dynamic_ncols=True)\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_data_loader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_data_loader.close()\n",
    "\n",
    "end_train_time = time.time()\n",
    "\n",
    "train_time = end_train_time - start_train_time\n",
    "print(f\"Training time: {train_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "val_loss = 0.0\n",
    "val_corrects = 0\n",
    "\n",
    "start_test_time = time.time()\n",
    "\n",
    "test_data_loader = tqdm(test_dataloader, desc='Testing', dynamic_ncols=True)\n",
    "\n",
    "for batch_idx, (image, target) in enumerate(test_data_loader):\n",
    "    image = image.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    outputs, loss = test_batch(model, image, target)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "test_data_loader.close()\n",
    "\n",
    "end_test_time = time.time()\n",
    "\n",
    "test_time = end_test_time - start_test_time\n",
    "print(f'Testing time: {test_time:.2f} seconds')\n",
    "\n",
    "val_acc = val_corrects.double() / len(test_set)\n",
    "print(f'Acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: 100%|██████████| 8/8 [00:08<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1781, Accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8737, Accuracy: 0.5300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 8/8 [00:09<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7282, Accuracy: 0.6689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6312, Accuracy: 0.7044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 8/8 [00:09<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6222, Accuracy: 0.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 8/8 [00:08<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5216, Accuracy: 0.7722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 8/8 [00:08<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4421, Accuracy: 0.8022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 8/8 [00:08<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4299, Accuracy: 0.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 8/8 [00:08<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3762, Accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 8/8 [00:08<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3803, Accuracy: 0.8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 8/8 [00:09<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5217, Accuracy: 0.8344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 8/8 [00:09<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6194, Accuracy: 0.7567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 8/8 [00:08<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5643, Accuracy: 0.7567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 8/8 [00:09<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4234, Accuracy: 0.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 8/8 [00:09<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3908, Accuracy: 0.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3717, Accuracy: 0.8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5883, Accuracy: 0.8278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|██████████| 8/8 [00:09<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5369, Accuracy: 0.7544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|██████████| 8/8 [00:10<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4364, Accuracy: 0.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|██████████| 8/8 [00:08<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3620, Accuracy: 0.8278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|██████████| 8/8 [00:08<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3525, Accuracy: 0.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|██████████| 8/8 [00:08<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3860, Accuracy: 0.8389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|██████████| 8/8 [00:14<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5535, Accuracy: 0.7633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|██████████| 8/8 [00:17<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3538, Accuracy: 0.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████| 8/8 [00:17<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3560, Accuracy: 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4896, Accuracy: 0.8178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设置路径和数据增强\n",
    "path = Path('data')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载训练集\n",
    "train_set = datasets.ImageFolder(root=path / 'train', transform=transform)\n",
    "train_dataloader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载验证集\n",
    "valid_set = datasets.ImageFolder(root=path / 'test', transform=transform)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# 定义卷积块\n",
    "def conv_block(ni, nf, size=3, stride=1):\n",
    "    for_pad = lambda s: s if s > 2 else 3\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, nf, kernel_size=size, stride=stride, padding=(for_pad(size) - 1)//2, bias=False),\n",
    "        nn.BatchNorm2d(nf),\n",
    "        nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "    )\n",
    "\n",
    "# 定义三次卷积\n",
    "def triple_conv(ni, nf):\n",
    "    return nn.Sequential(\n",
    "        conv_block(ni, nf),\n",
    "        conv_block(nf, ni, size=1),\n",
    "        conv_block(ni, nf)\n",
    "    )\n",
    "\n",
    "# 定义模型\n",
    "class XRayModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XRayModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            conv_block(3, 8),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            conv_block(8, 16),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            triple_conv(16, 32),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            triple_conv(32, 64),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            triple_conv(64, 128),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            triple_conv(128, 256),\n",
    "            conv_block(256, 128, size=1),\n",
    "            conv_block(128, 256),\n",
    "            nn.Conv2d(256, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(507, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = XRayModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练模型\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    corrects = 0\n",
    "\n",
    "    for images, labels in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{epochs}'):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = total_loss / len(train_dataloader)\n",
    "    accuracy = corrects.double() / len(train_set)\n",
    "    print(f'Train Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# 验证模型\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "val_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(valid_dataloader, desc='Validation'):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "val_loss /= len(valid_dataloader)\n",
    "val_accuracy = val_corrects.double() / len(valid_set)\n",
    "print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

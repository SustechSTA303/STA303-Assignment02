{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP\n",
    "VISUAL_BACKBONE = 'ViT-B/16' # RN50, ViT-B/32, ViT-B/16\n",
    "BATCH_SIZE = 128\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device, download_root='/shareddata/clip/')\n",
    "model.to(device);\n",
    "\n",
    "def model_inference(model, image, text):\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    logit_scale = model.logit_scale.exp()\n",
    "    logits = logit_scale * image_features @ text_features.t()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "the zero-shot performance on CIFAR is 83.49%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "test_set = CIFAR10(root='/shareddata', train=False, download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "prompt = [f\"A photo of a {class_name}\" for class_name in class_names]\n",
    "\n",
    "text_inputs = torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in class_names]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image, text_inputs)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "\n",
    "    print(f\"the zero-shot performance on CIFAR is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "The zero-shot performance on CIFAR-100 is 3.77%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "# Transform for CIFAR-100 test set\n",
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 test set\n",
    "test_set_cifar100 = CIFAR100(root='./data', train=False, download=True, transform=transform_cifar100_test)\n",
    "test_dataloader_cifar100 = DataLoader(test_set_cifar100, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Class names for CIFAR-100\n",
    "class_names_cifar100 = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bicycle', 'bottle', 'bowl', 'boy',\n",
    "    'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee',\n",
    "    'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant',\n",
    "    'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower',\n",
    "    'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom',\n",
    "    'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate',\n",
    "    'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark',\n",
    "    'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper',\n",
    "    'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe',\n",
    "    'whale', 'willow_tree', 'wolf', 'woman', 'worm', 'zebra', 'mushroom']\n",
    "\n",
    "# Prompt for CLIP model\n",
    "prompt = \"It’s a picture of a\"\n",
    "text_inputs_cifar100 = torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in class_names_cifar100]).to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader_cifar100):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Test model\n",
    "        logits_cifar100 = model_inference(model, image, text_inputs_cifar100)\n",
    "        _, preds_cifar100 = torch.max(logits_cifar100, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds_cifar100 == target.data)\n",
    "\n",
    "    val_acc_cifar100 = val_corrects.double() / len(test_set_cifar100)\n",
    "\n",
    "    print(f\"The zero-shot performance on CIFAR-100 is {val_acc_cifar100*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3: DTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zero-shot performance on DTD is 42.91%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "# Transform for DTD test set\n",
    "transform_dtd_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Download and load DTD test set\n",
    "dtd_test_set = datasets.ImageFolder(root='/shareddata/dtd/dtd/images', transform=transform_dtd_test)\n",
    "dtd_test_dataloader = DataLoader(dtd_test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Prompt for CLIP model\n",
    "prompt = \"It’s a picture featuring patterns of\"\n",
    "\n",
    "# Tokenize class names for CLIP model input\n",
    "text_inputs_dtd = torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in dtd_test_set.classes]).to(device)\n",
    "\n",
    "# Test on DTD dataset\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(dtd_test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Test model\n",
    "        logits_dtd = model_inference(model, image, text_inputs_dtd)\n",
    "        _, preds_dtd = torch.max(logits_dtd, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds_dtd == target.data)\n",
    "\n",
    "    val_acc_dtd = val_corrects.double() / len(dtd_test_set)\n",
    "\n",
    "    print(f\"The zero-shot performance on DTD is {val_acc_dtd*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4: Oxford Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_dict = {\n",
    "'21': 'fire lily',\n",
    " '3': 'canterbury bells',\n",
    " '45': 'bolero deep blue',\n",
    " '1': 'pink primrose',\n",
    " '34': 'mexican aster',\n",
    " '27': 'prince of wales feathers',\n",
    " '7': 'moon orchid',\n",
    " '16': 'globe-flower',\n",
    " '25': 'grape hyacinth',\n",
    " '26': 'corn poppy',\n",
    " '79': 'toad lily',\n",
    " '39': 'siam tulip',\n",
    " '24': 'red ginger',\n",
    " '67': 'spring crocus',\n",
    " '35': 'alpine sea holly',\n",
    " '32': 'garden phlox',\n",
    " '10': 'globe thistle',\n",
    " '6': 'tiger lily',\n",
    " '93': 'ball moss',\n",
    " '33': 'love in the mist',\n",
    " '9': 'monkshood',\n",
    " '102': 'blackberry lily',\n",
    " '14': 'spear thistle',\n",
    " '19': 'balloon flower',\n",
    " '100': 'blanket flower',\n",
    " '13': 'king protea',\n",
    " '49': 'oxeye daisy',\n",
    " '15': 'yellow iris',\n",
    " '61': 'cautleya spicata',\n",
    " '31': 'carnation',\n",
    " '64': 'silverbush',\n",
    " '68': 'bearded iris',\n",
    " '63': 'black-eyed susan',\n",
    " '69': 'windflower',\n",
    " '62': 'japanese anemone',\n",
    " '20': 'giant white arum lily',\n",
    " '38': 'great masterwort',\n",
    " '4': 'sweet pea',\n",
    " '86': 'tree mallow',\n",
    " '101': 'trumpet creeper',\n",
    " '42': 'daffodil',\n",
    " '22': 'pincushion flower',\n",
    " '2': 'hard-leaved pocket orchid',\n",
    " '54': 'sunflower',\n",
    " '66': 'osteospermum',\n",
    " '70': 'tree poppy',\n",
    " '85': 'desert-rose',\n",
    " '99': 'bromelia',\n",
    " '87': 'magnolia',\n",
    " '5': 'english marigold',\n",
    " '92': 'bee balm',\n",
    " '28': 'stemless gentian',\n",
    " '97': 'mallow',\n",
    " '57': 'gaura',\n",
    " '40': 'lenten rose',\n",
    " '47': 'marigold',\n",
    " '59': 'orange dahlia',\n",
    " '48': 'buttercup',\n",
    " '55': 'pelargonium',\n",
    " '36': 'ruby-lipped cattleya',\n",
    " '91': 'hippeastrum',\n",
    " '29': 'artichoke',\n",
    " '71': 'gazania',\n",
    " '90': 'canna lily',\n",
    " '18': 'peruvian lily',\n",
    " '98': 'mexican petunia',\n",
    " '8': 'bird of paradise',\n",
    " '30': 'sweet william',\n",
    " '17': 'purple coneflower',\n",
    " '52': 'wild pansy',\n",
    " '84': 'columbine',\n",
    " '12': \"colt's foot\",\n",
    " '11': 'snapdragon',\n",
    " '96': 'camellia',\n",
    " '23': 'fritillary',\n",
    " '50': 'common dandelion',\n",
    " '44': 'poinsettia',\n",
    " '53': 'primula',\n",
    " '72': 'azalea',\n",
    " '65': 'californian poppy',\n",
    " '80': 'anthurium',\n",
    " '76': 'morning glory',\n",
    " '37': 'cape flower',\n",
    " '56': 'bishop of llandaff',\n",
    " '60': 'pink-yellow dahlia',\n",
    " '82': 'clematis',\n",
    " '58': 'geranium',\n",
    " '75': 'thorn apple',\n",
    " '41': 'barbeton daisy',\n",
    " '95': 'bougainvillea',\n",
    " '43': 'sword lily',\n",
    " '83': 'hibiscus',\n",
    " '78': 'lotus lotus',\n",
    " '88': 'cyclamen',\n",
    " '94': 'foxglove',\n",
    " '81': 'frangipani',\n",
    " '74': 'rose',\n",
    " '89': 'watercress',\n",
    " '73': 'water lily',\n",
    " '46': 'wallflower',\n",
    " '77': 'passion flower',\n",
    " '51': 'petunia'\n",
    "}\n",
    "\n",
    "# 提取所有的值\n",
    "class_names_oxford_flowers = flower_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zero-shot performance on Oxford Flowers is 0.67%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "# Transform for Oxford Flowers test set\n",
    "transform_oxford_flowers_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "test_set_oxford_flowers = torchvision.datasets.ImageFolder(root='/shareddata/flowers-102', transform=transform_oxford_flowers_test)\n",
    "test_dataloader_oxford_flowers = DataLoader(test_set_oxford_flowers, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# 提示词 for CLIP 模型\n",
    "prompt_oxford_flowers = \"It’s a picture of a flower from dataset oxford flowers, specifically a\"\n",
    "\n",
    "# Tokenize 类别名称 for CLIP 模型输入\n",
    "text_inputs_oxford_flowers = torch.cat([clip.tokenize(f\"{prompt_oxford_flowers} {c}\") for c in class_names_oxford_flowers]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader_oxford_flowers):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Test model\n",
    "        logits_oxford_flowers = model_inference(model, image, text_inputs_oxford_flowers) \n",
    "        _, preds_oxford_flowers = torch.max(logits_oxford_flowers, 1)\n",
    "\n",
    "        val_corrects += torch.sum(preds_oxford_flowers == target.data)\n",
    "\n",
    "    val_acc_oxford_flowers = val_corrects.double() / len(test_set_oxford_flowers)\n",
    "\n",
    "    print(f\"The zero-shot performance on Oxford Flowers is {val_acc_oxford_flowers*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5: COIL-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zero-shot performance on COIL-20 is 6.94%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "# Transform for COIL-20 test set\n",
    "transform_coil20_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Download and load COIL-20 test set\n",
    "coil20_test_set = datasets.ImageFolder(root='data/coil20', transform=transform_coil20_test)\n",
    "coil20_test_dataloader = DataLoader(coil20_test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Prompt for CLIP model\n",
    "prompt = \"It’s a picture of an object from the COIL-20 dataset, specifically a\"\n",
    "\n",
    "# Tokenize class names for CLIP model input\n",
    "text_inputs_coil20 = torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in coil20_test_set.classes]).to(device)\n",
    "\n",
    "# Test on COIL-20 dataset\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(coil20_test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Test model\n",
    "        logits_coil20 = model_inference(model, image,text_inputs_coil20)\n",
    "        _, preds_coil20 = torch.max(logits_coil20, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds_coil20 == target.data)\n",
    "\n",
    "    val_acc_coil20 = val_corrects.double() / len(coil20_test_set)\n",
    "\n",
    "    print(f\"The zero-shot performance on COIL-20 is {val_acc_coil20*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 6: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zero-shot performance on MNIST is 28.58%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "# Transform for MNIST test set\n",
    "transform_mnist_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to RGB for compatibility\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Download and load MNIST test set\n",
    "mnist_test_set = datasets.MNIST(root='/shareddata/MNIST', train=False, transform=transform_mnist_test, download=True)\n",
    "mnist_test_dataloader = DataLoader(mnist_test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Prompt for CLIP model\n",
    "prompt = \"It’s a picture of a handwritten digit, specifically a\"\n",
    "\n",
    "# Tokenize class names for CLIP model input\n",
    "text_inputs_mnist = torch.cat([clip.tokenize(f\"{prompt} {i}\") for i in range(10)]).to(device)\n",
    "\n",
    "def model_inference(model, image, text):\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    logit_scale = model.logit_scale.exp()\n",
    "    logits = logit_scale * image_features @ text_features.t()\n",
    "\n",
    "    return logits\n",
    "\n",
    "# Test on MNIST dataset\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(mnist_test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Test model\n",
    "        logits_mnist = model_inference(model, image, text_inputs_mnist)\n",
    "        _, preds_mnist = torch.max(logits_mnist, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds_mnist == target.data)\n",
    "\n",
    "    val_acc_mnist = val_corrects.double() / len(mnist_test_set)\n",
    "\n",
    "    print(f\"The zero-shot performance on MNIST is {val_acc_mnist*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 ResNet-18 模型\n",
    "class SimpleResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleResNet18, self).__init__()\n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(resnet18.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "# # Optimizer\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0229529229271443\n",
      "Epoch 2, Loss: 0.7814653910639341\n",
      "Epoch 3, Loss: 0.6861904384687428\n",
      "Epoch 4, Loss: 0.632746474517276\n",
      "Epoch 5, Loss: 0.5956372027964238\n",
      "Epoch 6, Loss: 0.569012791680558\n",
      "Epoch 7, Loss: 0.5500335960894289\n",
      "Epoch 8, Loss: 0.5191921680174825\n",
      "Epoch 9, Loss: 0.5112663771947632\n",
      "Epoch 10, Loss: 0.4874238667585661\n",
      "Test Accuracy: 89.54%\n"
     ]
    }
   ],
   "source": [
    "# 将CIFAR-10数据预处理\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载训练集和测试集\n",
    "train_set = datasets.CIFAR10(root='/shareddata', train=True, download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = datasets.CIFAR10(root='/shareddata', train=False, download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化模型\n",
    "num_classes = 10  # CIFAR-10 有 10 个类别\n",
    "resnet18_model = SimpleResNet18(num_classes)\n",
    "resnet18_model.to(device)\n",
    "\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    resnet18_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet18_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_dataloader)}\")\n",
    "\n",
    "# 在测试集上评估模型\n",
    "resnet18_model.eval()\n",
    "corrects = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet18_model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_accuracy = corrects.double() / len(test_set)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1, Loss: 2.818615010022507\n",
      "Epoch 3, Loss: 1.8864550090506864\n",
      "Epoch 4, Loss: 1.7327599918750851\n",
      "Epoch 5, Loss: 1.6371336522919442\n",
      "Epoch 6, Loss: 1.5405272187479317\n",
      "Epoch 7, Loss: 1.4584246318968361\n",
      "Epoch 8, Loss: 1.394640124362448\n",
      "Epoch 9, Loss: 1.3470561726928671\n",
      "Epoch 10, Loss: 1.3047759773786112\n",
      "Test Accuracy on CIFAR-100: 69.65%\n"
     ]
    }
   ],
   "source": [
    "# 将CIFAR-100数据集预处理的代码\n",
    "transform_cifar100_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载CIFAR-100训练集和测试集\n",
    "train_set_cifar100 = datasets.CIFAR100(root='/shareddata', train=True, download=True, transform=transform_cifar100_train)\n",
    "train_dataloader_cifar100 = torch.utils.data.DataLoader(train_set_cifar100, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set_cifar100 = datasets.CIFAR100(root='/shareddata', train=False, download=True, transform=transform_cifar100_test)\n",
    "test_dataloader_cifar100 = torch.utils.data.DataLoader(test_set_cifar100, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# 初始化模型\n",
    "num_classes_cifar100 = 100  # CIFAR-100有100个类别\n",
    "resnet18_model_cifar100 = SimpleResNet18(num_classes_cifar100)\n",
    "\n",
    "# 将模型移到GPU上\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18_model_cifar100.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion_cifar100 = nn.CrossEntropyLoss()\n",
    "optimizer_cifar100 = optim.Adam(resnet18_model_cifar100.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    resnet18_model_cifar100.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader_cifar100:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer_cifar100.zero_grad()\n",
    "        outputs = resnet18_model_cifar100(images)\n",
    "        loss = criterion_cifar100(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_cifar100.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_dataloader_cifar100)}\")\n",
    "\n",
    "# 在测试集上评估模型\n",
    "resnet18_model_cifar100.eval()\n",
    "corrects_cifar100 = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader_cifar100:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet18_model_cifar100(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corrects_cifar100 += torch.sum(preds == labels.data)\n",
    "\n",
    "test_accuracy_cifar100 = corrects_cifar100.double() / len(test_set_cifar100)\n",
    "print(f\"Test Accuracy on CIFAR-100: {test_accuracy_cifar100 * 100:.2f}%\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.369425392150879\n",
      "Epoch 2, Loss: 1.7675701326794095\n",
      "Epoch 3, Loss: 1.615386954943339\n",
      "Epoch 4, Loss: 1.5855771117740207\n",
      "Epoch 5, Loss: 1.4016689247555203\n",
      "Epoch 6, Loss: 1.2852866583400302\n",
      "Epoch 7, Loss: 1.1690501107109919\n",
      "Epoch 8, Loss: 1.1540569543838501\n",
      "Epoch 9, Loss: 1.0839050465159945\n",
      "Epoch 10, Loss: 1.0653971989949544\n",
      "Test Accuracy on DTD: 65.20%\n"
     ]
    }
   ],
   "source": [
    "# 将DTD数据集预处理的代码\n",
    "transform_dtd_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "transform_dtd_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# 加载DTD训练集和测试集\n",
    "train_set_dtd = datasets.ImageFolder(root='/shareddata/dtd/dtd/images', transform=transform_dtd_train)\n",
    "train_dataloader_dtd = torch.utils.data.DataLoader(train_set_dtd, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set_dtd = datasets.ImageFolder(root='/shareddata/dtd/dtd/images', transform=transform_dtd_test)\n",
    "test_dataloader_dtd = torch.utils.data.DataLoader(test_set_dtd, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# 初始化模型\n",
    "num_classes_dtd = len(train_set_dtd.classes)  # DTD数据集的类别数\n",
    "resnet18_model_dtd = SimpleResNet18(num_classes_dtd)\n",
    "resnet18_model_dtd.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion_dtd = nn.CrossEntropyLoss()\n",
    "optimizer_dtd = optim.Adam(resnet18_model_dtd.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    resnet18_model_dtd.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader_dtd:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer_dtd.zero_grad()\n",
    "        outputs = resnet18_model_dtd(images)\n",
    "        loss = criterion_dtd(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_dtd.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_dataloader_dtd)}\")\n",
    "\n",
    "# 在测试集上评估模型\n",
    "resnet18_model_dtd.eval()\n",
    "corrects_dtd = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader_dtd:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet18_model_dtd(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corrects_dtd += torch.sum(preds == labels.data)\n",
    "\n",
    "test_accuracy_dtd = corrects_dtd.double() / len(test_set_dtd)\n",
    "print(f\"Test Accuracy on DTD: {test_accuracy_dtd * 100:.2f}%\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6671897567187747\n",
      "Epoch 2, Loss: 0.6446548672392964\n",
      "Epoch 3, Loss: 0.6427348675206304\n"
     ]
    }
   ],
   "source": [
    "# 将Oxford Flowers数据集预处理\n",
    "transform_flowers_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "transform_flowers_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# 加载Oxford Flowers训练集和测试集\n",
    "train_set_flowers = datasets.ImageFolder(root='/shareddata/flowers-102', transform=transform_flowers_train)\n",
    "train_dataloader_flowers = torch.utils.data.DataLoader(train_set_flowers, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set_flowers = datasets.ImageFolder(root='/shareddata/flowers-102', transform=transform_flowers_test)\n",
    "test_dataloader_flowers = torch.utils.data.DataLoader(test_set_flowers, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# 初始化模型\n",
    "num_classes_flowers = len(train_set_flowers.classes)  # Oxford Flowers数据集的类别数\n",
    "resnet18_model_flowers = SimpleResNet18(num_classes_flowers)\n",
    "resnet18_model_flowers.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion_flowers = nn.CrossEntropyLoss()\n",
    "optimizer_flowers = optim.Adam(resnet18_model_flowers.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    resnet18_model_flowers.train()\n",
    "    running_loss_flowers = 0.0\n",
    "    for images_flowers, labels_flowers in train_dataloader_flowers:\n",
    "        images_flowers, labels_flowers = images_flowers.to(device), labels_flowers.to(device)\n",
    "        optimizer_flowers.zero_grad()\n",
    "        outputs_flowers = resnet18_model_flowers(images_flowers)\n",
    "        loss_flowers = criterion_flowers(outputs_flowers, labels_flowers)\n",
    "        loss_flowers.backward()\n",
    "        optimizer_flowers.step()\n",
    "        running_loss_flowers += loss_flowers.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss_flowers / len(train_dataloader_flowers)}\")\n",
    "\n",
    "# 在测试集上评估模型\n",
    "resnet18_model_flowers.eval()\n",
    "corrects_flowers = 0\n",
    "with torch.no_grad():\n",
    "    for images_flowers, labels_flowers in test_dataloader_flowers:\n",
    "        images_flowers, labels_flowers = images_flowers.to(device), labels_flowers.to(device)\n",
    "        outputs_flowers = resnet18_model_flowers(images_flowers)\n",
    "        _, preds_flowers = torch.max(outputs_flowers, 1)\n",
    "        corrects_flowers += torch.sum(preds_flowers == labels_flowers.data)\n",
    "\n",
    "test_accuracy_flowers = corrects_flowers.double() / len(test_set_flowers)\n",
    "print(f\"Test Accuracy on Oxford Flowers: {test_accuracy_flowers * 100:.2f}%\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将COIL-20数据集预处理\n",
    "transform_coil20_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "transform_coil20_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# 加载COIL-20训练集和测试集\n",
    "train_set_coil20 = datasets.ImageFolder(root='data/coil20', transform=transform_coil20_train)  # 替换为COIL-20数据集的路径\n",
    "train_dataloader_coil20 = torch.utils.data.DataLoader(train_set_coil20, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set_coil20 = datasets.ImageFolder(root='data/coil20', transform=transform_coil20_test)  # 替换为COIL-20数据集的路径\n",
    "test_dataloader_coil20 = torch.utils.data.DataLoader(test_set_coil20, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# 初始化模型\n",
    "num_classes_coil20 = len(train_set_coil20.classes)  # COIL-20数据集的类别数\n",
    "resnet18_model_coil20 = SimpleResNet18(num_classes_coil20)\n",
    "resnet18_model_coil20.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion_coil20 = nn.CrossEntropyLoss()\n",
    "optimizer_coil20 = optim.Adam(resnet18_model_coil20.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    resnet18_model_coil20.train()\n",
    "    running_loss_coil20 = 0.0\n",
    "    for images_coil20, labels_coil20 in train_dataloader_coil20:\n",
    "        images_coil20, labels_coil20 = images_coil20.to(device), labels_coil20.to(device)\n",
    "        optimizer_coil20.zero_grad()\n",
    "        outputs_coil20 = resnet18_model_coil20(images_coil20)\n",
    "        loss_coil20 = criterion_coil20(outputs_coil20, labels_coil20)\n",
    "        loss_coil20.backward()\n",
    "        optimizer_coil20.step()\n",
    "        running_loss_coil20 += loss_coil20.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss_coil20 / len(train_dataloader_coil20)}\")\n",
    "\n",
    "# 在测试集上评估模型\n",
    "resnet18_model_coil20.eval()\n",
    "corrects_coil20 = 0\n",
    "with torch.no_grad():\n",
    "    for images_coil20, labels_coil20 in test_dataloader_coil20:\n",
    "        images_coil20, labels_coil20 = images_coil20.to(device), labels_coil20.to(device)\n",
    "        outputs_coil20 = resnet18_model_coil20(images_coil20)\n",
    "        _, preds_coil20 = torch.max(outputs_coil20, 1)\n",
    "        corrects_coil20 += torch.sum(preds_coil20 == labels_coil20.data)\n",
    "\n",
    "test_accuracy_coil20 = corrects_coil20.double() / len(test_set_coil20)\n",
    "print(f\"Test Accuracy on COIL-20: {test_accuracy_coil20 * 100:.2f}%\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将MNIST数据集预处理\n",
    "transform_mnist_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整大小以匹配ResNet-18的期望输入\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Grayscale(3),  # 将图像转换为RGB格式\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # 根据MNIST数据集的特性设置标准化参数\n",
    "])\n",
    "\n",
    "transform_mnist_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# 加载MNIST训练集和测试集\n",
    "train_set_mnist = datasets.MNIST(root='/shareddata/MNIST', train=True, download=True, transform=transform_mnist_train)\n",
    "train_dataloader_mnist = torch.utils.data.DataLoader(train_set_mnist, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set_mnist = datasets.MNIST(root='/shareddata/MNIST', train=False, download=True, transform=transform_mnist_test)\n",
    "test_dataloader_mnist = torch.utils.data.DataLoader(test_set_mnist, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# 初始化模型\n",
    "num_classes_mnist = 10  # MNIST数据集的类别数\n",
    "resnet18_model_mnist = SimpleResNet18(num_classes_mnist)\n",
    "resnet18_model_mnist.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion_mnist = nn.CrossEntropyLoss()\n",
    "optimizer_mnist = optim.Adam(resnet18_model_mnist.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    resnet18_model_mnist.train()\n",
    "    running_loss_mnist = 0.0\n",
    "    for images_mnist, labels_mnist in train_dataloader_mnist:\n",
    "        images_mnist, labels_mnist = images_mnist.to(device), labels_mnist.to(device)\n",
    "        optimizer_mnist.zero_grad()\n",
    "        outputs_mnist = resnet18_model_mnist(images_mnist)\n",
    "        loss_mnist = criterion_mnist(outputs_mnist, labels_mnist)\n",
    "        loss_mnist.backward()\n",
    "        optimizer_mnist.step()\n",
    "        running_loss_mnist += loss_mnist.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss_mnist / len(train_dataloader_mnist)}\")\n",
    "\n",
    "# 在测试集上评估模型\n",
    "resnet18_model_mnist.eval()\n",
    "corrects_mnist = 0\n",
    "with torch.no_grad():\n",
    "    for images_mnist, labels_mnist in test_dataloader_mnist:\n",
    "        images_mnist, labels_mnist = images_mnist.to(device), labels_mnist.to(device)\n",
    "        outputs_mnist = resnet18_model_mnist(images_mnist)\n",
    "        _, preds_mnist = torch.max(outputs_mnist, 1)\n",
    "        corrects_mnist += torch.sum(preds_mnist == labels_mnist.data)\n",
    "\n",
    "test_accuracy_mnist = corrects_mnist.double() / len(test_set_mnist)\n",
    "print(f\"Test Accuracy on MNIST: {test_accuracy_mnist * 100:.2f}%\")\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

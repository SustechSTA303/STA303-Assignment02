{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01: Multi-class Classification \n",
    "In this Assignment, you will train a deep model on the CIFAR10 from the scratch using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 100\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 300\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR100(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR100(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = train_set.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu3(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        \n",
    "        x = self.relu4(self.dropout1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (relu4): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "from torch.optim import lr_scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=1.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: raw scores (logits) for each class. [batch_size, num_classes]\n",
    "        y_true: ground truth labels. [batch_size]\n",
    "        \"\"\"\n",
    "        # Convert y_true labels into one-hot encoding\n",
    "        y_true_onehot = torch.zeros(y_pred.size(), device=y_pred.device).scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "        \n",
    "        # Calculate softmax over y_pred for calculating probabilities\n",
    "        probs = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        focal_loss = -self.alpha * (y_true_onehot * torch.log(probs) * (1 - probs) ** self.gamma).sum(dim=1).mean()\n",
    "        \n",
    "        return focal_loss\n",
    "\n",
    "\n",
    "#criterion = nn.L1Loss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = FocalLoss(gamma=0.5)\n",
    "#criterion = FocalLoss(gamma=2.0)\n",
    "\n",
    "def one_hot_encoding(target, num_classes):\n",
    "    return F.one_hot(target, num_classes=num_classes).float()\n",
    "\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "   # model.eval()\n",
    "   # with torch.no_grad():\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "        \n",
    "        \n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/300 Train Loss: 0.0719 Acc: 0.0156\n",
      "f1 score in 0th epoch is 0.0\n",
      "Begin test......\n",
      "Test Loss: 0.0713 Acc: 0.0366\n",
      "Epoch: 2/300 Train Loss: 0.0708 Acc: 0.0307\n",
      "f1 score in 1th epoch is 0.020833333333333332\n",
      "Begin test......\n",
      "Test Loss: 0.0702 Acc: 0.0619\n",
      "Epoch: 3/300 Train Loss: 0.0697 Acc: 0.0435\n",
      "f1 score in 2th epoch is 0.010416666666666666\n",
      "Begin test......\n",
      "Test Loss: 0.0686 Acc: 0.0745\n",
      "Epoch: 4/300 Train Loss: 0.0684 Acc: 0.0545\n",
      "f1 score in 3th epoch is 0.0390625\n",
      "Begin test......\n",
      "Test Loss: 0.0672 Acc: 0.0854\n",
      "Epoch: 5/300 Train Loss: 0.0672 Acc: 0.0602\n",
      "f1 score in 4th epoch is 0.075\n",
      "Begin test......\n",
      "Test Loss: 0.0657 Acc: 0.0950\n",
      "Epoch: 6/300 Train Loss: 0.0663 Acc: 0.0660\n",
      "f1 score in 5th epoch is 0.07465277777777778\n",
      "Begin test......\n",
      "Test Loss: 0.0652 Acc: 0.1017\n",
      "Epoch: 7/300 Train Loss: 0.0657 Acc: 0.0688\n",
      "f1 score in 6th epoch is 0.06045918367346938\n",
      "Begin test......\n",
      "Test Loss: 0.0644 Acc: 0.1059\n",
      "Epoch: 8/300 Train Loss: 0.0652 Acc: 0.0728\n",
      "f1 score in 7th epoch is 0.060491071428571436\n",
      "Begin test......\n",
      "Test Loss: 0.0639 Acc: 0.1120\n",
      "Epoch: 9/300 Train Loss: 0.0647 Acc: 0.0746\n",
      "f1 score in 8th epoch is 0.06832010582010584\n",
      "Begin test......\n",
      "Test Loss: 0.0633 Acc: 0.1188\n",
      "Epoch: 10/300 Train Loss: 0.0643 Acc: 0.0781\n",
      "f1 score in 9th epoch is 0.059375\n",
      "Begin test......\n",
      "Test Loss: 0.0628 Acc: 0.1238\n",
      "Epoch: 11/300 Train Loss: 0.0638 Acc: 0.0826\n",
      "f1 score in 10th epoch is 0.055275974025974034\n",
      "Begin test......\n",
      "Test Loss: 0.0626 Acc: 0.1281\n",
      "Epoch: 12/300 Train Loss: 0.0636 Acc: 0.0838\n",
      "f1 score in 11th epoch is 0.06313657407407408\n",
      "Begin test......\n",
      "Test Loss: 0.0622 Acc: 0.1287\n",
      "Epoch: 13/300 Train Loss: 0.0635 Acc: 0.0839\n",
      "f1 score in 12th epoch is 0.0651480463980464\n",
      "Begin test......\n",
      "Test Loss: 0.0620 Acc: 0.1310\n",
      "Epoch: 14/300 Train Loss: 0.0632 Acc: 0.0895\n",
      "f1 score in 13th epoch is 0.06908852556173985\n",
      "Begin test......\n",
      "Test Loss: 0.0616 Acc: 0.1347\n",
      "Epoch: 15/300 Train Loss: 0.0630 Acc: 0.0878\n",
      "f1 score in 14th epoch is 0.06595238095238096\n",
      "Begin test......\n",
      "Test Loss: 0.0617 Acc: 0.1398\n",
      "Epoch: 16/300 Train Loss: 0.0628 Acc: 0.0896\n",
      "f1 score in 15th epoch is 0.07266958302114553\n",
      "Begin test......\n",
      "Test Loss: 0.0613 Acc: 0.1405\n",
      "Epoch: 17/300 Train Loss: 0.0628 Acc: 0.0911\n",
      "f1 score in 16th epoch is 0.06981668250050603\n",
      "Begin test......\n",
      "Test Loss: 0.0612 Acc: 0.1419\n",
      "Epoch: 18/300 Train Loss: 0.0626 Acc: 0.0935\n",
      "f1 score in 17th epoch is 0.06869698588448588\n",
      "Begin test......\n",
      "Test Loss: 0.0612 Acc: 0.1441\n",
      "Epoch: 19/300 Train Loss: 0.0625 Acc: 0.0935\n",
      "f1 score in 18th epoch is 0.06741604521209785\n",
      "Begin test......\n",
      "Test Loss: 0.0611 Acc: 0.1439\n",
      "Epoch: 20/300 Train Loss: 0.0624 Acc: 0.0946\n",
      "f1 score in 19th epoch is 0.06554159178240061\n",
      "Begin test......\n",
      "Test Loss: 0.0609 Acc: 0.1459\n",
      "Epoch: 21/300 Train Loss: 0.0624 Acc: 0.0938\n",
      "f1 score in 20th epoch is 0.0640294229579944\n",
      "Begin test......\n",
      "Test Loss: 0.0609 Acc: 0.1460\n",
      "Epoch: 22/300 Train Loss: 0.0623 Acc: 0.0936\n",
      "f1 score in 21th epoch is 0.06629443788534697\n",
      "Begin test......\n",
      "Test Loss: 0.0608 Acc: 0.1465\n",
      "Epoch: 23/300 Train Loss: 0.0622 Acc: 0.0972\n",
      "f1 score in 22th epoch is 0.06710249133018012\n",
      "Begin test......\n",
      "Test Loss: 0.0608 Acc: 0.1474\n",
      "Epoch: 24/300 Train Loss: 0.0622 Acc: 0.0953\n",
      "f1 score in 23th epoch is 0.06651592042217043\n",
      "Begin test......\n",
      "Test Loss: 0.0607 Acc: 0.1475\n",
      "Epoch: 25/300 Train Loss: 0.0622 Acc: 0.0982\n",
      "f1 score in 24th epoch is 0.06515180081356553\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1457\n",
      "Epoch: 26/300 Train Loss: 0.0620 Acc: 0.0964\n",
      "f1 score in 25th epoch is 0.06339956470753982\n",
      "Begin test......\n",
      "Test Loss: 0.0606 Acc: 0.1485\n",
      "Epoch: 27/300 Train Loss: 0.0621 Acc: 0.0970\n",
      "f1 score in 26th epoch is 0.06527162319645981\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1482\n",
      "Epoch: 28/300 Train Loss: 0.0621 Acc: 0.0972\n",
      "f1 score in 27th epoch is 0.0683980177152446\n",
      "Begin test......\n",
      "Test Loss: 0.0606 Acc: 0.1490\n",
      "Epoch: 29/300 Train Loss: 0.0621 Acc: 0.0954\n",
      "f1 score in 28th epoch is 0.06853940126365929\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1493\n",
      "Epoch: 30/300 Train Loss: 0.0620 Acc: 0.0963\n",
      "f1 score in 29th epoch is 0.06718254952678328\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1498\n",
      "Epoch: 31/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 30th epoch is 0.06444527976864065\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1486\n",
      "Epoch: 32/300 Train Loss: 0.0620 Acc: 0.0975\n",
      "f1 score in 31th epoch is 0.06589584260996678\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1494\n",
      "Epoch: 33/300 Train Loss: 0.0619 Acc: 0.0990\n",
      "f1 score in 32th epoch is 0.06391343123576448\n",
      "Begin test......\n",
      "Test Loss: 0.0606 Acc: 0.1512\n",
      "Epoch: 34/300 Train Loss: 0.0619 Acc: 0.0973\n",
      "f1 score in 33th epoch is 0.06269410290962604\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1494\n",
      "Epoch: 35/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 34th epoch is 0.0629219538145706\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 36/300 Train Loss: 0.0619 Acc: 0.0980\n",
      "f1 score in 35th epoch is 0.06325799575683257\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1509\n",
      "Epoch: 37/300 Train Loss: 0.0619 Acc: 0.0992\n",
      "f1 score in 36th epoch is 0.06213832784634492\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1488\n",
      "Epoch: 38/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 37th epoch is 0.06357765804456982\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1505\n",
      "Epoch: 39/300 Train Loss: 0.0619 Acc: 0.0978\n",
      "f1 score in 38th epoch is 0.06482447151661547\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1516\n",
      "Epoch: 40/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 39th epoch is 0.06836221336122168\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1507\n",
      "Epoch: 41/300 Train Loss: 0.0619 Acc: 0.1006\n",
      "f1 score in 40th epoch is 0.07015190032118787\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1517\n",
      "Epoch: 42/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 41th epoch is 0.07149466821919613\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1503\n",
      "Epoch: 43/300 Train Loss: 0.0618 Acc: 0.1005\n",
      "f1 score in 42th epoch is 0.07206020826438495\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1505\n",
      "Epoch: 44/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 43th epoch is 0.07542837075224738\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 45/300 Train Loss: 0.0619 Acc: 0.0972\n",
      "f1 score in 44th epoch is 0.07631370465965559\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1511\n",
      "Epoch: 46/300 Train Loss: 0.0619 Acc: 0.0972\n",
      "f1 score in 45th epoch is 0.07565458428926525\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1505\n",
      "Epoch: 47/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 46th epoch is 0.07460612936922163\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 48/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 47th epoch is 0.07578037050721946\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 49/300 Train Loss: 0.0619 Acc: 0.0990\n",
      "f1 score in 48th epoch is 0.07604255365367754\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1508\n",
      "Epoch: 50/300 Train Loss: 0.0618 Acc: 0.0990\n",
      "f1 score in 49th epoch is 0.07456600797910476\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 51/300 Train Loss: 0.0619 Acc: 0.0969\n",
      "f1 score in 50th epoch is 0.07313081418673692\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 52/300 Train Loss: 0.0618 Acc: 0.0995\n",
      "f1 score in 51th epoch is 0.07171357295462133\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1500\n",
      "Epoch: 53/300 Train Loss: 0.0619 Acc: 0.0980\n",
      "f1 score in 52th epoch is 0.0744554469004829\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1515\n",
      "Epoch: 54/300 Train Loss: 0.0619 Acc: 0.0993\n",
      "f1 score in 53th epoch is 0.07610048606615274\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 55/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 54th epoch is 0.07671232801221499\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1513\n",
      "Epoch: 56/300 Train Loss: 0.0619 Acc: 0.1008\n",
      "f1 score in 55th epoch is 0.0749940783614311\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1506\n",
      "Epoch: 57/300 Train Loss: 0.0619 Acc: 0.0974\n",
      "f1 score in 56th epoch is 0.07388492863603985\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1509\n",
      "Epoch: 58/300 Train Loss: 0.0618 Acc: 0.1010\n",
      "f1 score in 57th epoch is 0.07445130646555743\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1504\n",
      "Epoch: 59/300 Train Loss: 0.0619 Acc: 0.0986\n",
      "f1 score in 58th epoch is 0.07655241768363\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 60/300 Train Loss: 0.0619 Acc: 0.0969\n",
      "f1 score in 59th epoch is 0.07658337145256071\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1510\n",
      "Epoch: 61/300 Train Loss: 0.0619 Acc: 0.0972\n",
      "f1 score in 60th epoch is 0.07510287282335819\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1501\n",
      "Epoch: 62/300 Train Loss: 0.0618 Acc: 0.1005\n",
      "f1 score in 61th epoch is 0.07724186424500036\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1521\n",
      "Epoch: 63/300 Train Loss: 0.0618 Acc: 0.0988\n",
      "f1 score in 62th epoch is 0.07678763940809773\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1524\n",
      "Epoch: 64/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 63th epoch is 0.07727753961070011\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1511\n",
      "Epoch: 65/300 Train Loss: 0.0618 Acc: 0.0985\n",
      "f1 score in 64th epoch is 0.07697632003395005\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1518\n",
      "Epoch: 66/300 Train Loss: 0.0619 Acc: 0.0968\n",
      "f1 score in 65th epoch is 0.07650064506402193\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1513\n",
      "Epoch: 67/300 Train Loss: 0.0618 Acc: 0.0992\n",
      "f1 score in 66th epoch is 0.07707862388913922\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1511\n",
      "Epoch: 68/300 Train Loss: 0.0618 Acc: 0.0999\n",
      "f1 score in 67th epoch is 0.07677768792916355\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1512\n",
      "Epoch: 69/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 68th epoch is 0.0762570138078364\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1501\n",
      "Epoch: 70/300 Train Loss: 0.0619 Acc: 0.0981\n",
      "f1 score in 69th epoch is 0.07545089479459383\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1498\n",
      "Epoch: 71/300 Train Loss: 0.0619 Acc: 0.0993\n",
      "f1 score in 70th epoch is 0.0766640688815925\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 72/300 Train Loss: 0.0619 Acc: 0.0986\n",
      "f1 score in 71th epoch is 0.07765724674447128\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1515\n",
      "Epoch: 73/300 Train Loss: 0.0619 Acc: 0.1000\n",
      "f1 score in 72th epoch is 0.077287187995873\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1505\n",
      "Epoch: 74/300 Train Loss: 0.0618 Acc: 0.1000\n",
      "f1 score in 73th epoch is 0.07662843719935258\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1509\n",
      "Epoch: 75/300 Train Loss: 0.0618 Acc: 0.0998\n",
      "f1 score in 74th epoch is 0.07756114324791114\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1507\n",
      "Epoch: 76/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 75th epoch is 0.0765314888489991\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 77/300 Train Loss: 0.0619 Acc: 0.0975\n",
      "f1 score in 76th epoch is 0.07706876798896206\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1514\n",
      "Epoch: 78/300 Train Loss: 0.0618 Acc: 0.0987\n",
      "f1 score in 77th epoch is 0.07755876640880469\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1524\n",
      "Epoch: 79/300 Train Loss: 0.0618 Acc: 0.0988\n",
      "f1 score in 78th epoch is 0.07714439146592383\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1527\n",
      "Epoch: 80/300 Train Loss: 0.0618 Acc: 0.1002\n",
      "f1 score in 79th epoch is 0.07708938134950535\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1493\n",
      "Epoch: 81/300 Train Loss: 0.0619 Acc: 0.0996\n",
      "f1 score in 80th epoch is 0.07597142940588976\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1521\n",
      "Epoch: 82/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 81th epoch is 0.07517469694653116\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 83/300 Train Loss: 0.0619 Acc: 0.0973\n",
      "f1 score in 82th epoch is 0.07490292937243742\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1520\n",
      "Epoch: 84/300 Train Loss: 0.0619 Acc: 0.0975\n",
      "f1 score in 83th epoch is 0.07624207349047805\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1509\n",
      "Epoch: 85/300 Train Loss: 0.0619 Acc: 0.0999\n",
      "f1 score in 84th epoch is 0.07786896876105293\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1515\n",
      "Epoch: 86/300 Train Loss: 0.0619 Acc: 0.0967\n",
      "f1 score in 85th epoch is 0.07774857676845888\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 87/300 Train Loss: 0.0619 Acc: 0.0968\n",
      "f1 score in 86th epoch is 0.07690629128981599\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 88/300 Train Loss: 0.0618 Acc: 0.1000\n",
      "f1 score in 87th epoch is 0.07656941550513609\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 89/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 88th epoch is 0.07679093214786861\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1500\n",
      "Epoch: 90/300 Train Loss: 0.0618 Acc: 0.0993\n",
      "f1 score in 89th epoch is 0.0772100831319243\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 91/300 Train Loss: 0.0619 Acc: 0.0997\n",
      "f1 score in 90th epoch is 0.07828617122259358\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 92/300 Train Loss: 0.0619 Acc: 0.0995\n",
      "f1 score in 91th epoch is 0.07849487430273337\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1508\n",
      "Epoch: 93/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 92th epoch is 0.07791021837654284\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 94/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 93th epoch is 0.07914167577951162\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1505\n",
      "Epoch: 95/300 Train Loss: 0.0618 Acc: 0.0996\n",
      "f1 score in 94th epoch is 0.08001830782231731\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 96/300 Train Loss: 0.0619 Acc: 0.0975\n",
      "f1 score in 95th epoch is 0.07961190528152617\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1521\n",
      "Epoch: 97/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 96th epoch is 0.07876404864806823\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1509\n",
      "Epoch: 98/300 Train Loss: 0.0619 Acc: 0.0984\n",
      "f1 score in 97th epoch is 0.07839169375115206\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1507\n",
      "Epoch: 99/300 Train Loss: 0.0619 Acc: 0.0974\n",
      "f1 score in 98th epoch is 0.0779650998232065\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1507\n",
      "Epoch: 100/300 Train Loss: 0.0619 Acc: 0.0996\n",
      "f1 score in 99th epoch is 0.07885702003002569\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 101/300 Train Loss: 0.0619 Acc: 0.1005\n",
      "f1 score in 100th epoch is 0.07899525884565824\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 102/300 Train Loss: 0.0619 Acc: 0.1001\n",
      "f1 score in 101th epoch is 0.07815387888611051\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 103/300 Train Loss: 0.0619 Acc: 0.0981\n",
      "f1 score in 102th epoch is 0.07859496457998572\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1515\n",
      "Epoch: 104/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 103th epoch is 0.07949711823640453\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1510\n",
      "Epoch: 105/300 Train Loss: 0.0619 Acc: 0.0984\n",
      "f1 score in 104th epoch is 0.07946695927615623\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1520\n",
      "Epoch: 106/300 Train Loss: 0.0619 Acc: 0.1006\n",
      "f1 score in 105th epoch is 0.08008674165906063\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 107/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 106th epoch is 0.08125235777981524\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 108/300 Train Loss: 0.0619 Acc: 0.0990\n",
      "f1 score in 107th epoch is 0.08104963133905743\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1516\n",
      "Epoch: 109/300 Train Loss: 0.0619 Acc: 0.0992\n",
      "f1 score in 108th epoch is 0.08064678942094433\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1512\n",
      "Epoch: 110/300 Train Loss: 0.0619 Acc: 0.0996\n",
      "f1 score in 109th epoch is 0.07980940161031538\n",
      "Begin test......\n",
      "Test Loss: 0.0602 Acc: 0.1522\n",
      "Epoch: 111/300 Train Loss: 0.0619 Acc: 0.0962\n",
      "f1 score in 110th epoch is 0.07938277707400884\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1511\n",
      "Epoch: 112/300 Train Loss: 0.0618 Acc: 0.0997\n",
      "f1 score in 111th epoch is 0.07866669288556238\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1522\n",
      "Epoch: 113/300 Train Loss: 0.0619 Acc: 0.0967\n",
      "f1 score in 112th epoch is 0.07875066898853875\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1516\n",
      "Epoch: 114/300 Train Loss: 0.0619 Acc: 0.0978\n",
      "f1 score in 113th epoch is 0.08029860177240213\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 115/300 Train Loss: 0.0619 Acc: 0.0980\n",
      "f1 score in 114th epoch is 0.07966852599304707\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 116/300 Train Loss: 0.0619 Acc: 0.0996\n",
      "f1 score in 115th epoch is 0.07980133442409144\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1512\n",
      "Epoch: 117/300 Train Loss: 0.0619 Acc: 0.0978\n",
      "f1 score in 116th epoch is 0.07944521556831997\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1503\n",
      "Epoch: 118/300 Train Loss: 0.0618 Acc: 0.0988\n",
      "f1 score in 117th epoch is 0.08016010219077187\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1531\n",
      "Epoch: 119/300 Train Loss: 0.0619 Acc: 0.0976\n",
      "f1 score in 118th epoch is 0.08027115893472087\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1515\n",
      "Epoch: 120/300 Train Loss: 0.0619 Acc: 0.1000\n",
      "f1 score in 119th epoch is 0.08037776798197743\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1520\n",
      "Epoch: 121/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 120th epoch is 0.07956981443646044\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 122/300 Train Loss: 0.0618 Acc: 0.0992\n",
      "f1 score in 121th epoch is 0.0797075887805075\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 123/300 Train Loss: 0.0618 Acc: 0.0994\n",
      "f1 score in 122th epoch is 0.07935048223917149\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1519\n",
      "Epoch: 124/300 Train Loss: 0.0618 Acc: 0.0985\n",
      "f1 score in 123th epoch is 0.07976353936403383\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1505\n",
      "Epoch: 125/300 Train Loss: 0.0618 Acc: 0.0982\n",
      "f1 score in 124th epoch is 0.07962413265224366\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1513\n",
      "Epoch: 126/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 125th epoch is 0.07995420172552582\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1501\n",
      "Epoch: 127/300 Train Loss: 0.0619 Acc: 0.0986\n",
      "f1 score in 126th epoch is 0.08053881579007763\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1522\n",
      "Epoch: 128/300 Train Loss: 0.0619 Acc: 0.0973\n",
      "f1 score in 127th epoch is 0.08013424419954006\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 129/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 128th epoch is 0.08028194649339543\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1509\n",
      "Epoch: 130/300 Train Loss: 0.0618 Acc: 0.1002\n",
      "f1 score in 129th epoch is 0.079688300466061\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1507\n",
      "Epoch: 131/300 Train Loss: 0.0618 Acc: 0.0990\n",
      "f1 score in 130th epoch is 0.07926125816306481\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1516\n",
      "Epoch: 132/300 Train Loss: 0.0619 Acc: 0.0999\n",
      "f1 score in 131th epoch is 0.07910855800005945\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1516\n",
      "Epoch: 133/300 Train Loss: 0.0619 Acc: 0.0986\n",
      "f1 score in 132th epoch is 0.07943970583994328\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1518\n",
      "Epoch: 134/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 133th epoch is 0.07877069947186688\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 135/300 Train Loss: 0.0619 Acc: 0.0995\n",
      "f1 score in 134th epoch is 0.07867855322221225\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1523\n",
      "Epoch: 136/300 Train Loss: 0.0618 Acc: 0.0997\n",
      "f1 score in 135th epoch is 0.0786393093215435\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1516\n",
      "Epoch: 137/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 136th epoch is 0.07840975788655502\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1513\n",
      "Epoch: 138/300 Train Loss: 0.0619 Acc: 0.0984\n",
      "f1 score in 137th epoch is 0.07857952885436048\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1502\n",
      "Epoch: 139/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 138th epoch is 0.0782429951719927\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1497\n",
      "Epoch: 140/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 139th epoch is 0.07812545386880014\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 141/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 140th epoch is 0.07791394980220273\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1503\n",
      "Epoch: 142/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 141th epoch is 0.0772882535476027\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1504\n",
      "Epoch: 143/300 Train Loss: 0.0619 Acc: 0.0983\n",
      "f1 score in 142th epoch is 0.07855771920652993\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 144/300 Train Loss: 0.0619 Acc: 0.0979\n",
      "f1 score in 143th epoch is 0.0786959572411937\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1511\n",
      "Epoch: 145/300 Train Loss: 0.0618 Acc: 0.0996\n",
      "f1 score in 144th epoch is 0.07839807140400744\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 146/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 145th epoch is 0.07773790990877193\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 147/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 146th epoch is 0.07840418993030748\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1514\n",
      "Epoch: 148/300 Train Loss: 0.0619 Acc: 0.0971\n",
      "f1 score in 147th epoch is 0.07832906218180435\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1516\n",
      "Epoch: 149/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 148th epoch is 0.07893157477940294\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1509\n",
      "Epoch: 150/300 Train Loss: 0.0619 Acc: 0.0964\n",
      "f1 score in 149th epoch is 0.07943729939207946\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1519\n",
      "Epoch: 151/300 Train Loss: 0.0619 Acc: 0.0983\n",
      "f1 score in 150th epoch is 0.0789641870840551\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 152/300 Train Loss: 0.0619 Acc: 0.0995\n",
      "f1 score in 151th epoch is 0.07892714034366899\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1520\n",
      "Epoch: 153/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 152th epoch is 0.07876660617081964\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 154/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 153th epoch is 0.07883781787871944\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1526\n",
      "Epoch: 155/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 154th epoch is 0.07876752651937416\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 156/300 Train Loss: 0.0619 Acc: 0.0995\n",
      "f1 score in 155th epoch is 0.07814683770612241\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1506\n",
      "Epoch: 157/300 Train Loss: 0.0618 Acc: 0.0989\n",
      "f1 score in 156th epoch is 0.07787925921484098\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 158/300 Train Loss: 0.0619 Acc: 0.0993\n",
      "f1 score in 157th epoch is 0.07746013383889239\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1527\n",
      "Epoch: 159/300 Train Loss: 0.0619 Acc: 0.0966\n",
      "f1 score in 158th epoch is 0.07738823143802724\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1514\n",
      "Epoch: 160/300 Train Loss: 0.0618 Acc: 0.0986\n",
      "f1 score in 159th epoch is 0.07691085500591073\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1512\n",
      "Epoch: 161/300 Train Loss: 0.0619 Acc: 0.0995\n",
      "f1 score in 160th epoch is 0.07672846590404038\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1515\n",
      "Epoch: 162/300 Train Loss: 0.0619 Acc: 0.0979\n",
      "f1 score in 161th epoch is 0.07647894554820692\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 163/300 Train Loss: 0.0619 Acc: 0.1002\n",
      "f1 score in 162th epoch is 0.07642336758730182\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1505\n",
      "Epoch: 164/300 Train Loss: 0.0618 Acc: 0.0990\n",
      "f1 score in 163th epoch is 0.0766126428849544\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 165/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 164th epoch is 0.07635918812319849\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1522\n",
      "Epoch: 166/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 165th epoch is 0.07652799204868369\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1511\n",
      "Epoch: 167/300 Train Loss: 0.0619 Acc: 0.0979\n",
      "f1 score in 166th epoch is 0.0764045464234029\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 168/300 Train Loss: 0.0619 Acc: 0.0975\n",
      "f1 score in 167th epoch is 0.07649406614286372\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1519\n",
      "Epoch: 169/300 Train Loss: 0.0618 Acc: 0.1000\n",
      "f1 score in 168th epoch is 0.07657935625745091\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1518\n",
      "Epoch: 170/300 Train Loss: 0.0619 Acc: 0.0996\n",
      "f1 score in 169th epoch is 0.07706590259165223\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1521\n",
      "Epoch: 171/300 Train Loss: 0.0618 Acc: 0.0986\n",
      "f1 score in 170th epoch is 0.07689979836102906\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1507\n",
      "Epoch: 172/300 Train Loss: 0.0619 Acc: 0.0992\n",
      "f1 score in 171th epoch is 0.07669566420057866\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1504\n",
      "Epoch: 173/300 Train Loss: 0.0619 Acc: 0.0978\n",
      "f1 score in 172th epoch is 0.07642351982077386\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1513\n",
      "Epoch: 174/300 Train Loss: 0.0619 Acc: 0.0979\n",
      "f1 score in 173th epoch is 0.07626762923796514\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 175/300 Train Loss: 0.0619 Acc: 0.0990\n",
      "f1 score in 174th epoch is 0.07663560287012716\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1507\n",
      "Epoch: 176/300 Train Loss: 0.0618 Acc: 0.0979\n",
      "f1 score in 175th epoch is 0.0766425559467137\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1518\n",
      "Epoch: 177/300 Train Loss: 0.0619 Acc: 0.0975\n",
      "f1 score in 176th epoch is 0.07734692027202762\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 178/300 Train Loss: 0.0618 Acc: 0.1005\n",
      "f1 score in 177th epoch is 0.07692358028328851\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1521\n",
      "Epoch: 179/300 Train Loss: 0.0619 Acc: 0.0990\n",
      "f1 score in 178th epoch is 0.07678802672738115\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1491\n",
      "Epoch: 180/300 Train Loss: 0.0619 Acc: 0.1003\n",
      "f1 score in 179th epoch is 0.076825516040641\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1511\n",
      "Epoch: 181/300 Train Loss: 0.0619 Acc: 0.0987\n",
      "f1 score in 180th epoch is 0.07627780514392099\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1503\n",
      "Epoch: 182/300 Train Loss: 0.0619 Acc: 0.0981\n",
      "f1 score in 181th epoch is 0.07678035826543327\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1509\n",
      "Epoch: 183/300 Train Loss: 0.0619 Acc: 0.1008\n",
      "f1 score in 182th epoch is 0.0766536836252468\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1512\n",
      "Epoch: 184/300 Train Loss: 0.0619 Acc: 0.0987\n",
      "f1 score in 183th epoch is 0.07612202039786911\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1519\n",
      "Epoch: 185/300 Train Loss: 0.0620 Acc: 0.0994\n",
      "f1 score in 184th epoch is 0.07599733361367873\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1523\n",
      "Epoch: 186/300 Train Loss: 0.0619 Acc: 0.0981\n",
      "f1 score in 185th epoch is 0.07612471840377043\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1502\n",
      "Epoch: 187/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 186th epoch is 0.07628246533669106\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1511\n",
      "Epoch: 188/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 187th epoch is 0.07620036856699804\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1522\n",
      "Epoch: 189/300 Train Loss: 0.0618 Acc: 0.1009\n",
      "f1 score in 188th epoch is 0.07652507245267301\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1513\n",
      "Epoch: 190/300 Train Loss: 0.0619 Acc: 0.0984\n",
      "f1 score in 189th epoch is 0.07638458538865293\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1511\n",
      "Epoch: 191/300 Train Loss: 0.0619 Acc: 0.0992\n",
      "f1 score in 190th epoch is 0.07595961234903122\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1509\n",
      "Epoch: 192/300 Train Loss: 0.0619 Acc: 0.0993\n",
      "f1 score in 191th epoch is 0.07546542677010733\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1517\n",
      "Epoch: 193/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 192th epoch is 0.07545013217874948\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 194/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 193th epoch is 0.07522709459270491\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 195/300 Train Loss: 0.0619 Acc: 0.0986\n",
      "f1 score in 194th epoch is 0.07483754799554486\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 196/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 195th epoch is 0.0744136303605757\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1514\n",
      "Epoch: 197/300 Train Loss: 0.0618 Acc: 0.0985\n",
      "f1 score in 196th epoch is 0.07428956517532063\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1516\n",
      "Epoch: 198/300 Train Loss: 0.0619 Acc: 0.0960\n",
      "f1 score in 197th epoch is 0.07430143453763949\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 199/300 Train Loss: 0.0618 Acc: 0.0988\n",
      "f1 score in 198th epoch is 0.07522156916573529\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 200/300 Train Loss: 0.0619 Acc: 0.0971\n",
      "f1 score in 199th epoch is 0.075025081583411\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1519\n",
      "Epoch: 201/300 Train Loss: 0.0619 Acc: 0.0966\n",
      "f1 score in 200th epoch is 0.07483343831190327\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 202/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 201th epoch is 0.07466304749431894\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1521\n",
      "Epoch: 203/300 Train Loss: 0.0619 Acc: 0.0972\n",
      "f1 score in 202th epoch is 0.07471628926416403\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1527\n",
      "Epoch: 204/300 Train Loss: 0.0618 Acc: 0.1003\n",
      "f1 score in 203th epoch is 0.07483610794227548\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 205/300 Train Loss: 0.0619 Acc: 0.0980\n",
      "f1 score in 204th epoch is 0.07532398064852723\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1509\n",
      "Epoch: 206/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 205th epoch is 0.07491313564696221\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1524\n",
      "Epoch: 207/300 Train Loss: 0.0618 Acc: 0.1010\n",
      "f1 score in 206th epoch is 0.07501648875287369\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1511\n",
      "Epoch: 208/300 Train Loss: 0.0618 Acc: 0.0996\n",
      "f1 score in 207th epoch is 0.07495673534783358\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 209/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 208th epoch is 0.07492556886174054\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1515\n",
      "Epoch: 210/300 Train Loss: 0.0618 Acc: 0.0974\n",
      "f1 score in 209th epoch is 0.07491866427168982\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 211/300 Train Loss: 0.0619 Acc: 0.0966\n",
      "f1 score in 210th epoch is 0.07511310237872298\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1510\n",
      "Epoch: 212/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 211th epoch is 0.07510550043797434\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 213/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 212th epoch is 0.07502155445408477\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 214/300 Train Loss: 0.0619 Acc: 0.0964\n",
      "f1 score in 213th epoch is 0.07487740848690737\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1513\n",
      "Epoch: 215/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 214th epoch is 0.07529434462822898\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1515\n",
      "Epoch: 216/300 Train Loss: 0.0618 Acc: 0.0992\n",
      "f1 score in 215th epoch is 0.07513190665010538\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1520\n",
      "Epoch: 217/300 Train Loss: 0.0619 Acc: 0.0987\n",
      "f1 score in 216th epoch is 0.07506481028078182\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1507\n",
      "Epoch: 218/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 217th epoch is 0.07539695972910543\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1525\n",
      "Epoch: 219/300 Train Loss: 0.0619 Acc: 0.0979\n",
      "f1 score in 218th epoch is 0.07566201657441742\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1511\n",
      "Epoch: 220/300 Train Loss: 0.0619 Acc: 0.0995\n",
      "f1 score in 219th epoch is 0.07561442809354305\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 221/300 Train Loss: 0.0619 Acc: 0.0961\n",
      "f1 score in 220th epoch is 0.07568599846028636\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1506\n",
      "Epoch: 222/300 Train Loss: 0.0619 Acc: 0.0972\n",
      "f1 score in 221th epoch is 0.0754537953047755\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 223/300 Train Loss: 0.0618 Acc: 0.0992\n",
      "f1 score in 222th epoch is 0.07532336100008334\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1523\n",
      "Epoch: 224/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 223th epoch is 0.07517536526769454\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1523\n",
      "Epoch: 225/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 224th epoch is 0.0758713274659895\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1518\n",
      "Epoch: 226/300 Train Loss: 0.0618 Acc: 0.0984\n",
      "f1 score in 225th epoch is 0.075874236799527\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 227/300 Train Loss: 0.0618 Acc: 0.0997\n",
      "f1 score in 226th epoch is 0.07561694746617308\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 228/300 Train Loss: 0.0618 Acc: 0.1004\n",
      "f1 score in 227th epoch is 0.07557325586617371\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 229/300 Train Loss: 0.0619 Acc: 0.0981\n",
      "f1 score in 228th epoch is 0.0757273383768887\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1515\n",
      "Epoch: 230/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 229th epoch is 0.07605253028892128\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 231/300 Train Loss: 0.0618 Acc: 0.1000\n",
      "f1 score in 230th epoch is 0.07589673308765983\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1518\n",
      "Epoch: 232/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 231th epoch is 0.07599316334781304\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1509\n",
      "Epoch: 233/300 Train Loss: 0.0619 Acc: 0.0976\n",
      "f1 score in 232th epoch is 0.07564111346503115\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1522\n",
      "Epoch: 234/300 Train Loss: 0.0619 Acc: 0.0979\n",
      "f1 score in 233th epoch is 0.07553117539906185\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 235/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 234th epoch is 0.07537705071228139\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 236/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 235th epoch is 0.07534482860751456\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1517\n",
      "Epoch: 237/300 Train Loss: 0.0619 Acc: 0.1004\n",
      "f1 score in 236th epoch is 0.07555877596199471\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1510\n",
      "Epoch: 238/300 Train Loss: 0.0619 Acc: 0.0984\n",
      "f1 score in 237th epoch is 0.07529233866737281\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 239/300 Train Loss: 0.0619 Acc: 0.1009\n",
      "f1 score in 238th epoch is 0.07537978193053271\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1515\n",
      "Epoch: 240/300 Train Loss: 0.0619 Acc: 0.0959\n",
      "f1 score in 239th epoch is 0.07550782702692331\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1511\n",
      "Epoch: 241/300 Train Loss: 0.0619 Acc: 0.0970\n",
      "f1 score in 240th epoch is 0.07522491043578125\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1511\n",
      "Epoch: 242/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 241th epoch is 0.07511449186787941\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 243/300 Train Loss: 0.0619 Acc: 0.0970\n",
      "f1 score in 242th epoch is 0.07511311911116547\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1513\n",
      "Epoch: 244/300 Train Loss: 0.0618 Acc: 0.0995\n",
      "f1 score in 243th epoch is 0.07520597439661512\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1507\n",
      "Epoch: 245/300 Train Loss: 0.0619 Acc: 0.1009\n",
      "f1 score in 244th epoch is 0.07522416297645627\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 246/300 Train Loss: 0.0618 Acc: 0.0978\n",
      "f1 score in 245th epoch is 0.07535604695779302\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1515\n",
      "Epoch: 247/300 Train Loss: 0.0619 Acc: 0.0997\n",
      "f1 score in 246th epoch is 0.07538513076062597\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1518\n",
      "Epoch: 248/300 Train Loss: 0.0619 Acc: 0.0998\n",
      "f1 score in 247th epoch is 0.07503057452478383\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1509\n",
      "Epoch: 249/300 Train Loss: 0.0619 Acc: 0.1001\n",
      "f1 score in 248th epoch is 0.07490365162987142\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 250/300 Train Loss: 0.0619 Acc: 0.1002\n",
      "f1 score in 249th epoch is 0.07484684394201911\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1512\n",
      "Epoch: 251/300 Train Loss: 0.0618 Acc: 0.0995\n",
      "f1 score in 250th epoch is 0.07451878355679648\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1506\n",
      "Epoch: 252/300 Train Loss: 0.0619 Acc: 0.0970\n",
      "f1 score in 251th epoch is 0.07497161516678197\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1521\n",
      "Epoch: 253/300 Train Loss: 0.0619 Acc: 0.0981\n",
      "f1 score in 252th epoch is 0.07519188382438054\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1522\n",
      "Epoch: 254/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 253th epoch is 0.07506058852905431\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1515\n",
      "Epoch: 255/300 Train Loss: 0.0619 Acc: 0.0972\n",
      "f1 score in 254th epoch is 0.07504398535679478\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1523\n",
      "Epoch: 256/300 Train Loss: 0.0619 Acc: 0.0977\n",
      "f1 score in 255th epoch is 0.07514097334275398\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 257/300 Train Loss: 0.0619 Acc: 0.0990\n",
      "f1 score in 256th epoch is 0.07521741332411802\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1508\n",
      "Epoch: 258/300 Train Loss: 0.0619 Acc: 0.0988\n",
      "f1 score in 257th epoch is 0.07546810163017895\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1509\n",
      "Epoch: 259/300 Train Loss: 0.0618 Acc: 0.1001\n",
      "f1 score in 258th epoch is 0.07608835360881483\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 260/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 259th epoch is 0.0761910748148446\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1516\n",
      "Epoch: 261/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 260th epoch is 0.07629966658165821\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1522\n",
      "Epoch: 262/300 Train Loss: 0.0619 Acc: 0.0993\n",
      "f1 score in 261th epoch is 0.07613329719570375\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1499\n",
      "Epoch: 263/300 Train Loss: 0.0620 Acc: 0.0980\n",
      "f1 score in 262th epoch is 0.07584531527154348\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 264/300 Train Loss: 0.0618 Acc: 0.0985\n",
      "f1 score in 263th epoch is 0.0759355316948868\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1503\n",
      "Epoch: 265/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 264th epoch is 0.07587149007238782\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1513\n",
      "Epoch: 266/300 Train Loss: 0.0619 Acc: 0.0994\n",
      "f1 score in 265th epoch is 0.0756824472750629\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1504\n",
      "Epoch: 267/300 Train Loss: 0.0619 Acc: 0.0984\n",
      "f1 score in 266th epoch is 0.07564817077210294\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1511\n",
      "Epoch: 268/300 Train Loss: 0.0619 Acc: 0.0996\n",
      "f1 score in 267th epoch is 0.07531394005332863\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1511\n",
      "Epoch: 269/300 Train Loss: 0.0619 Acc: 0.0980\n",
      "f1 score in 268th epoch is 0.07571114010979799\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1518\n",
      "Epoch: 270/300 Train Loss: 0.0619 Acc: 0.0980\n",
      "f1 score in 269th epoch is 0.07576463890562737\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1513\n",
      "Epoch: 271/300 Train Loss: 0.0619 Acc: 0.1005\n",
      "f1 score in 270th epoch is 0.07618384048394544\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 272/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 271th epoch is 0.07628380083210007\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1514\n",
      "Epoch: 273/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 272th epoch is 0.07609451174757217\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1511\n",
      "Epoch: 274/300 Train Loss: 0.0619 Acc: 0.0976\n",
      "f1 score in 273th epoch is 0.07616821939371626\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 275/300 Train Loss: 0.0618 Acc: 0.0985\n",
      "f1 score in 274th epoch is 0.0765032141885571\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1511\n",
      "Epoch: 276/300 Train Loss: 0.0619 Acc: 0.0980\n",
      "f1 score in 275th epoch is 0.07625587655450988\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1518\n",
      "Epoch: 277/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 276th epoch is 0.07641211441306502\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1512\n",
      "Epoch: 278/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 277th epoch is 0.07650710298217812\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1510\n",
      "Epoch: 279/300 Train Loss: 0.0618 Acc: 0.1006\n",
      "f1 score in 278th epoch is 0.07621116626880557\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1520\n",
      "Epoch: 280/300 Train Loss: 0.0619 Acc: 0.0961\n",
      "f1 score in 279th epoch is 0.07613264786460355\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 281/300 Train Loss: 0.0618 Acc: 0.0985\n",
      "f1 score in 280th epoch is 0.07686614280017531\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1515\n",
      "Epoch: 282/300 Train Loss: 0.0618 Acc: 0.1001\n",
      "f1 score in 281th epoch is 0.076952995875759\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1506\n",
      "Epoch: 283/300 Train Loss: 0.0619 Acc: 0.0965\n",
      "f1 score in 282th epoch is 0.07662798233347366\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1510\n",
      "Epoch: 284/300 Train Loss: 0.0619 Acc: 0.1005\n",
      "f1 score in 283th epoch is 0.07630867462167508\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1500\n",
      "Epoch: 285/300 Train Loss: 0.0618 Acc: 0.0993\n",
      "f1 score in 284th epoch is 0.07610330473178044\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1508\n",
      "Epoch: 286/300 Train Loss: 0.0618 Acc: 0.1005\n",
      "f1 score in 285th epoch is 0.0759949312587054\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1519\n",
      "Epoch: 287/300 Train Loss: 0.0619 Acc: 0.0990\n",
      "f1 score in 286th epoch is 0.07565970694997078\n",
      "Begin test......\n",
      "Test Loss: 0.0602 Acc: 0.1510\n",
      "Epoch: 288/300 Train Loss: 0.0619 Acc: 0.0985\n",
      "f1 score in 287th epoch is 0.07540898183016106\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1515\n",
      "Epoch: 289/300 Train Loss: 0.0618 Acc: 0.0986\n",
      "f1 score in 288th epoch is 0.075095345433483\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1507\n",
      "Epoch: 290/300 Train Loss: 0.0619 Acc: 0.0993\n",
      "f1 score in 289th epoch is 0.07500990435722459\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1507\n",
      "Epoch: 291/300 Train Loss: 0.0619 Acc: 0.0976\n",
      "f1 score in 290th epoch is 0.07572172023236484\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1515\n",
      "Epoch: 292/300 Train Loss: 0.0619 Acc: 0.0991\n",
      "f1 score in 291th epoch is 0.07595469104742475\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 293/300 Train Loss: 0.0619 Acc: 0.0989\n",
      "f1 score in 292th epoch is 0.07627375804976491\n",
      "Begin test......\n",
      "Test Loss: 0.0605 Acc: 0.1515\n",
      "Epoch: 294/300 Train Loss: 0.0618 Acc: 0.0984\n",
      "f1 score in 293th epoch is 0.07640311766886375\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1514\n",
      "Epoch: 295/300 Train Loss: 0.0618 Acc: 0.0996\n",
      "f1 score in 294th epoch is 0.07616467495660484\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1520\n",
      "Epoch: 296/300 Train Loss: 0.0618 Acc: 0.0984\n",
      "f1 score in 295th epoch is 0.07650284649090576\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1521\n",
      "Epoch: 297/300 Train Loss: 0.0619 Acc: 0.0982\n",
      "f1 score in 296th epoch is 0.07638397164661886\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1516\n",
      "Epoch: 298/300 Train Loss: 0.0619 Acc: 0.0970\n",
      "f1 score in 297th epoch is 0.07612240944547978\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1505\n",
      "Epoch: 299/300 Train Loss: 0.0619 Acc: 0.0970\n",
      "f1 score in 298th epoch is 0.07584477940737343\n",
      "Begin test......\n",
      "Test Loss: 0.0604 Acc: 0.1524\n",
      "Epoch: 300/300 Train Loss: 0.0619 Acc: 0.0975\n",
      "f1 score in 299th epoch is 0.07603295105397344\n",
      "Begin test......\n",
      "Test Loss: 0.0603 Acc: 0.1506\n",
      "训练模型用时：1584.9707291126251秒\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "start_time = time.time()  # 记录开始时间\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "# 日志文件\n",
    "log_file = 'training_log.txt'\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    " \n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "     \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "    #########\n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_targets.extend(target.cpu().numpy())\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    print(f\"f1 score in {epoch}th epoch is {f1}\")\n",
    "\n",
    "############\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    \n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            ##################\n",
    "          #  target_one_hot = one_hot_encoding(target, 10)  # 转换成 one-hot 编码\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "          #  outputs, loss = test_batch(model, image, target_one_hot)  # 使用 one-hot 编码后的目标\n",
    "            #######################\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f'Epoch {epoch+1}/{NUM_EPOCHS}\\n')\n",
    "        f.write(f'Train Accuracy: {epoch_acc:.4f}%\\n')\n",
    "        f.write(f'Test Accuracy: {val_acc:.4f}%\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "            \n",
    "end_time = time.time()  # 记录结束时间\n",
    "duration = end_time - start_time  # 计算训练时间\n",
    "print(f\"训练模型用时：{duration}秒\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "input = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "###############################################################\n",
    "input_tensor = input.unsqueeze(0).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "    predict_label = torch.argmax(probabilities)\n",
    "# predict_label = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "apple: 0.0037\n",
      "aquarium_fish: 0.0025\n",
      "baby: 0.0065\n",
      "bear: 0.0065\n",
      "beaver: 0.0050\n",
      "bed: 0.0106\n",
      "bee: 0.0019\n",
      "beetle: 0.0056\n",
      "bicycle: 0.0119\n",
      "bottle: 0.0141\n",
      "bowl: 0.0071\n",
      "boy: 0.0056\n",
      "bridge: 0.0328\n",
      "bus: 0.0101\n",
      "butterfly: 0.0019\n",
      "camel: 0.0076\n",
      "can: 0.0113\n",
      "castle: 0.0305\n",
      "caterpillar: 0.0022\n",
      "cattle: 0.0032\n",
      "chair: 0.0230\n",
      "chimpanzee: 0.0036\n",
      "clock: 0.0199\n",
      "cloud: 0.0315\n",
      "cockroach: 0.0161\n",
      "couch: 0.0120\n",
      "crab: 0.0050\n",
      "crocodile: 0.0033\n",
      "cup: 0.0120\n",
      "dinosaur: 0.0103\n",
      "dolphin: 0.0124\n",
      "elephant: 0.0056\n",
      "flatfish: 0.0162\n",
      "forest: 0.0032\n",
      "fox: 0.0020\n",
      "girl: 0.0044\n",
      "hamster: 0.0056\n",
      "house: 0.0153\n",
      "kangaroo: 0.0046\n",
      "keyboard: 0.0247\n",
      "lamp: 0.0183\n",
      "lawn_mower: 0.0172\n",
      "leopard: 0.0033\n",
      "lion: 0.0011\n",
      "lizard: 0.0045\n",
      "lobster: 0.0043\n",
      "man: 0.0074\n",
      "maple_tree: 0.0034\n",
      "motorcycle: 0.0083\n",
      "mountain: 0.0339\n",
      "mouse: 0.0050\n",
      "mushroom: 0.0022\n",
      "oak_tree: 0.0052\n",
      "orange: 0.0013\n",
      "orchid: 0.0065\n",
      "otter: 0.0106\n",
      "palm_tree: 0.0145\n",
      "pear: 0.0034\n",
      "pickup_truck: 0.0105\n",
      "pine_tree: 0.0140\n",
      "plain: 0.0167\n",
      "plate: 0.0187\n",
      "poppy: 0.0010\n",
      "porcupine: 0.0015\n",
      "possum: 0.0027\n",
      "rabbit: 0.0035\n",
      "raccoon: 0.0035\n",
      "ray: 0.0092\n",
      "road: 0.0194\n",
      "rocket: 0.0259\n",
      "rose: 0.0016\n",
      "sea: 0.0443\n",
      "seal: 0.0134\n",
      "shark: 0.0102\n",
      "shrew: 0.0019\n",
      "skunk: 0.0030\n",
      "skyscraper: 0.0420\n",
      "snail: 0.0049\n",
      "snake: 0.0038\n",
      "spider: 0.0064\n",
      "squirrel: 0.0039\n",
      "streetcar: 0.0111\n",
      "sunflower: 0.0018\n",
      "sweet_pepper: 0.0015\n",
      "table: 0.0053\n",
      "tank: 0.0137\n",
      "telephone: 0.0187\n",
      "television: 0.0100\n",
      "tiger: 0.0019\n",
      "tractor: 0.0068\n",
      "train: 0.0144\n",
      "trout: 0.0145\n",
      "tulip: 0.0021\n",
      "turtle: 0.0113\n",
      "wardrobe: 0.0036\n",
      "whale: 0.0290\n",
      "willow_tree: 0.0067\n",
      "wolf: 0.0036\n",
      "woman: 0.0052\n",
      "worm: 0.0148\n"
     ]
    }
   ],
   "source": [
    "predicted_class = class_names[predict_label.item()]\n",
    "predicted_probability = probabilities[0][predict_label.item()]\n",
    "image = input.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Print probabilities for each class\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[0][i].item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01564,0.03070,0.04350,0.05448,0.06022,0.06600,0.06884,0.07284,0.07460,0.07812,0.08258,0.08380,0.08390,0.08950,0.08778,0.08958,0.09106,0.09346,0.09352,0.09458,0.09384,0.09360,0.09718,0.09528,0.09818,0.09640,0.09702,0.09724,0.09540,0.09628,0.09938,0.09746,0.09902,0.09732,0.09816,0.09796,0.09924,0.09820,0.09776,0.09890,0.10058,0.09770,0.10054,0.09888,0.09722,0.09722,0.09854,0.09892,0.09900,0.09898,0.09688,0.09954,0.09798,0.09932,0.09944,0.10076,0.09740,0.10100,0.09856,0.09692,0.09722,0.10046,0.09880,0.09848,0.09848,0.09676,0.09920,0.09992,0.09820,0.09814,0.09926,0.09856,0.10000,0.10002,0.09980,0.09766,0.09746,0.09866,0.09876,0.10022,0.09956,0.09820,0.09730,0.09750,0.09992,0.09672,0.09684,0.09996,0.09910,0.09934,0.09968,0.09950,0.09910,0.09908,0.09956,0.09750,0.09818,0.09840,0.09744,0.09960,0.10048,0.10012,0.09810,0.09888,0.09844,0.10056,0.09818,0.09896,0.09924,0.09960,0.09622,0.09968,0.09674,0.09782,0.09802,0.09956,0.09778,0.09882,0.09760,0.10000,0.09876,0.09916,0.09940,0.09852,0.09816,0.09890,0.09862,0.09734,0.09880,0.10016,0.09898,0.09986,0.09864,0.09890,0.09946,0.09972,0.09908,0.09844,0.09876,0.09880,0.09914,0.09944,0.09826,0.09788,0.09958,0.09848,0.09944,0.09708,0.09876,0.09636,0.09834,0.09948,0.09942,0.09854,0.09850,0.09952,0.09894,0.09926,0.09656,0.09864,0.09950,0.09792,0.10022,0.09902,0.09854,0.09936,0.09794,0.09748,0.09998,0.09956,0.09864,0.09918,0.09778,0.09788,0.09904,0.09790,0.09748,0.10050,0.09900,0.10028,0.09870,0.09812,0.10084,0.09868,0.09940,0.09814,0.09766,0.09768,0.10090,0.09836,0.09920,0.09928,0.09816,0.09876,0.09864,0.09854,0.09854,0.09598,0.09880,0.09710,0.09658,0.09816,0.09724,0.10032,0.09796,0.09852,0.10104,0.09964,0.09766,0.09744,0.09664,0.09768,0.09876,0.09638,0.09846,0.09924,0.09874,0.09822,0.09786,0.09946,0.09614,0.09720,0.09922,0.09774,0.09936,0.09838,0.09972,0.10036,0.09814,0.09914,0.10000,0.09770,0.09758,0.09788,0.09914,0.09940,0.10042,0.09842,0.10086,0.09594,0.09704,0.09882,0.09702,0.09946,0.10090,0.09778,0.09966,0.09980,0.10014,0.10022,0.09950,0.09696,0.09810,0.09852,0.09716,0.09774,0.09898,0.09884,0.10010,0.09914,0.09886,0.09926,0.09798,0.09846,0.09910,0.09938,0.09842,0.09962,0.09800,0.09804,0.10054,0.09854,0.09852,0.09762,0.09852,0.09800,0.09888,0.09848,0.10064,0.09606,0.09854,0.10006,0.09650,0.10052,0.09932,0.10052,0.09896,0.09846,0.09862,0.09934,0.09758,0.09908,0.09886,0.09844,0.09962,0.09840,0.09816,0.09696,0.09704,0.09748,\n",
      "\n",
      "\n",
      "0.03660,0.06190,0.07450,0.08540,0.09500,0.10170,0.10590,0.11200,0.11880,0.12380,0.12810,0.12870,0.13100,0.13470,0.13980,0.14050,0.14190,0.14410,0.14390,0.14590,0.14600,0.14650,0.14740,0.14750,0.14570,0.14850,0.14820,0.14900,0.14930,0.14980,0.14860,0.14940,0.15120,0.14940,0.15120,0.15090,0.14880,0.15050,0.15160,0.15070,0.15170,0.15030,0.15050,0.15120,0.15110,0.15050,0.15140,0.15120,0.15080,0.15120,0.15170,0.15000,0.15150,0.15140,0.15130,0.15060,0.15090,0.15040,0.15130,0.15100,0.15010,0.15210,0.15240,0.15110,0.15180,0.15130,0.15110,0.15120,0.15010,0.14980,0.15160,0.15150,0.15050,0.15090,0.15070,0.15160,0.15140,0.15240,0.15270,0.14930,0.15210,0.15130,0.15200,0.15090,0.15150,0.15140,0.15170,0.15170,0.15000,0.15120,0.15100,0.15080,0.15190,0.15050,0.15190,0.15210,0.15090,0.15070,0.15070,0.15120,0.15120,0.15100,0.15150,0.15100,0.15200,0.15120,0.15160,0.15160,0.15120,0.15220,0.15110,0.15220,0.15160,0.15160,0.15130,0.15120,0.15030,0.15310,0.15150,0.15200,0.15190,0.15100,0.15190,0.15050,0.15130,0.15010,0.15220,0.15160,0.15090,0.15070,0.15160,0.15160,0.15180,0.15130,0.15230,0.15160,0.15130,0.15020,0.14970,0.15190,0.15030,0.15040,0.15170,0.15110,0.15120,0.15160,0.15140,0.15160,0.15090,0.15190,0.15100,0.15200,0.15120,0.15260,0.15120,0.15060,0.15130,0.15270,0.15140,0.15120,0.15150,0.15160,0.15050,0.15130,0.15220,0.15110,0.15120,0.15190,0.15180,0.15210,0.15070,0.15040,0.15130,0.15190,0.15070,0.15180,0.15160,0.15210,0.14910,0.15110,0.15030,0.15090,0.15120,0.15190,0.15230,0.15020,0.15110,0.15220,0.15130,0.15110,0.15090,0.15170,0.15170,0.15130,0.15140,0.15140,0.15160,0.15100,0.15100,0.15190,0.15170,0.15210,0.15270,0.15170,0.15090,0.15240,0.15110,0.15130,0.15150,0.15190,0.15100,0.15100,0.15160,0.15130,0.15150,0.15200,0.15070,0.15250,0.15110,0.15170,0.15060,0.15120,0.15230,0.15230,0.15180,0.15160,0.15120,0.15130,0.15150,0.15120,0.15180,0.15090,0.15220,0.15120,0.15190,0.15170,0.15100,0.15140,0.15150,0.15110,0.15110,0.15140,0.15130,0.15070,0.15100,0.15150,0.15180,0.15090,0.15160,0.15120,0.15060,0.15210,0.15220,0.15150,0.15230,0.15140,0.15080,0.15090,0.15140,0.15160,0.15220,0.14990,0.15140,0.15030,0.15130,0.15040,0.15110,0.15110,0.15180,0.15130,0.15100,0.15140,0.15110,0.15190,0.15110,0.15180,0.15120,0.15100,0.15200,0.15160,0.15150,0.15060,0.15100,0.15000,0.15080,0.15190,0.15100,0.15150,0.15070,0.15070,0.15150,0.15140,0.15150,0.15140,0.15200,0.15210,0.15160,0.15050,0.15240,0.15060,"
     ]
    }
   ],
   "source": [
    "for i in np.array(training_acc):\n",
    "    print(f\"{i:.5f}\",end=',')\n",
    "print(\"\\n\\n\")\n",
    "for i in np.array(testing_acc):\n",
    "    print(f\"{i:.5f}\",end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "epochs = list(range(1, 301))\n",
    "line1 = ax.plot(epochs, np.array(training_acc), label=\"train acc\")\n",
    "line2 = ax.plot(epochs, np.array(testing_acc), label=\"test acc\")\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.grid(True)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

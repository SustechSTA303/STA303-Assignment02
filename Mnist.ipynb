{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ecd3527",
   "metadata": {},
   "source": [
    "# Basic Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f642ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import tqdm\n",
    "import clip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import funct\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058109e0",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e60276",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
    "])\n",
    "\n",
    "resnet_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)  #dataset for resnet training\n",
    "resnet_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)  #dataset for resnet testing\n",
    "clip_test =datasets.MNIST(root='./data', train=False, download=True, transform=None)          #dataset for Clip testing\n",
    "\n",
    "train_dataloader=torch.utils.data.DataLoader(resnet_train,batch_size=50,shuffle=True,num_workers=2)\n",
    "test_dataloader=torch.utils.data.DataLoader(resnet_test,batch_size=15,shuffle=False,num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c902b289",
   "metadata": {},
   "source": [
    "# Evaluating CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d299bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUAL_BACKBONE='RN50x64'\n",
    "numbers=[0,1,2,3,4,5,6,7,8,9]\n",
    "#load Clip\n",
    "model, preprocess = clip.load(VISUAL_BACKBONE, device ,download_root='/shareddata/clip/')\n",
    "\n",
    "text_inputs=torch.cat([clip.tokenize(f\"a photo of the number \\\"{c}\\\"\") for c in numbers]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a0dcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [06:33<00:00, 25.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of Clip on dataset Mnist is 84.86%, visual encoder is RN50x64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=funct.clip_testing(model,preprocess,clip_test,device,text_inputs)\n",
    "\n",
    "print(f\"the accuracy of Clip on dataset MNIST is {accuracy*100:.2f}%, visual encoder is {VISUAL_BACKBONE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12369fc2",
   "metadata": {},
   "source": [
    "# Fine-tuning and Evaluating ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74abfa59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#load ResNet50\n",
    "resnet50=models.resnet50(pretrained=True)\n",
    "resnet50.fc=torch.nn.Linear(2048,10) #add a fully connected layer to adjust the output dimension\n",
    "resnet50=resnet50.to(device)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3288542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [04:51<00:00,  4.11it/s]\n",
      "100%|██████████| 667/667 [00:13<00:00, 50.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of ResNet on Mnist dataset is 99.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#fine-tuning\n",
    "funct.resnet_training(resnet50,criterion,optimizer,train_dataloader,device)\n",
    "#evaluating\n",
    "corrects=funct.resnet_testing(resnet50,test_dataloader,device)\n",
    "accuracy=corrects/len(resnet_test)\n",
    "print(f\"the accuracy of ResNet on MNIST dataset is {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d59abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

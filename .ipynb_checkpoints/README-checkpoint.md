# STA303 Assignment 2: Applications of CLIP Model

## Model used: 

**CLIP checkpoint:** 

https://drive.google.com/uc?id=14pXWwB4Zm82rsDdvbGguLfx9F8aM7ovT

    # Relative Path:
    ./pretrained_models/conceptual_weights.pt
    
https://drive.google.com/uc?id=1IdaBtMSvtyzF0ByVaBHtvM0JYSXRExRX

    # Relative Path:
    ./pretrained_models/coco_weights.pt
    
**CoCa:** 

https://huggingface.co/laion/mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k/tree/main

    # Relative Paths:
    ./open_clip/open_clip_config.json
    ./open_clip/open_clip_pytorch_model.bin

**GPT2:**

https://huggingface.co/gpt2/tree/main
    
    # Relative Paths:
    ./pretrained_models/config.json
    ./pretrained_models/tokenizer.json
    ./pretrained_models/vocab.json
    ./pretrained_models/merges.txt
    ./pretrained_models/pytorch_model.bin

## Flickr8k Dataset: 

https://www.kaggle.com/datasets/adityajn105/flickr8k

    # Relative Paths:
    ./data/Image
    ./data/caption.txt

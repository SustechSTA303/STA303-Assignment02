{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c669f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c163b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd762578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b0169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71887e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "# cifar10 transform\n",
    "transform_cifar100_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载训练集\n",
    "train_set = torchvision.datasets.CIFAR100(root='/shareddata', train=True,\n",
    "                                        download=True, transform=transform_cifar100_test)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "test_set = torchvision.datasets.CIFAR100(root='/shareddata', train=False,\n",
    "                                        download=True, transform=transform_cifar100_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# CIFAR-100 的类名列表\n",
    "class_names = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "               'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "               'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "               'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "               'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "               'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "               'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "               'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "               'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "               'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "               'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "               'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "               'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "               'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "               'worm']\n",
    "\n",
    "# 更新数据集名称\n",
    "dataset_name = 'CIFAR100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5cce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c090ec06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=288, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1bb44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.480070070232577\n",
      "Epoch 2, Loss: 4.035427756931471\n",
      "Epoch 3, Loss: 3.7556229759665096\n",
      "Epoch 4, Loss: 3.5782850300869367\n",
      "Epoch 5, Loss: 3.466397462903386\n",
      "Epoch 6, Loss: 3.3356324473915198\n",
      "Epoch 7, Loss: 3.287794094256428\n",
      "Epoch 8, Loss: 3.2491149195014972\n",
      "Epoch 9, Loss: 3.2134600466169663\n",
      "Epoch 10, Loss: 3.1812561161987616\n",
      "Epoch 11, Loss: 3.114576476919072\n",
      "Epoch 12, Loss: 3.096572387553847\n",
      "Epoch 13, Loss: 3.0825997856266967\n",
      "Epoch 14, Loss: 3.0701592840502023\n",
      "Epoch 15, Loss: 3.0590751799171234\n",
      "Epoch 16, Loss: 3.024690830494132\n",
      "Epoch 17, Loss: 3.017720729188846\n",
      "Epoch 18, Loss: 3.012148924800746\n",
      "Epoch 19, Loss: 3.006936867828564\n",
      "Epoch 20, Loss: 3.0020942364812204\n",
      "Epoch 21, Loss: 2.9831235262439075\n",
      "Epoch 22, Loss: 2.9794080989135194\n",
      "Epoch 23, Loss: 2.9768324312956436\n",
      "Epoch 24, Loss: 2.9744162352188774\n",
      "Epoch 25, Loss: 2.9721157117877777\n",
      "Epoch 26, Loss: 2.961807836352102\n",
      "Epoch 27, Loss: 2.9599913855647797\n",
      "Epoch 28, Loss: 2.958695986691643\n",
      "Epoch 29, Loss: 2.9574777945838013\n",
      "Epoch 30, Loss: 2.9562726112277917\n",
      "Finished Training\n",
      "Finished Training. Total training time: 119.14 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "# 在训练循环开始之前记录起始时间\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % EVAL_INTERVAL == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_dataloader)}')\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# 计算总训练时间\n",
    "total_time = end_time - start_time\n",
    "print(f'Total training time: {total_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633a6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估基准模型的函数\n",
    "acc = 0\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = correct / total\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234ace10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ConvNet on CIFAR100 is 25.03%\n"
     ]
    }
   ],
   "source": [
    "# 评估基准模型\n",
    "accuracy_convnet = evaluate_model(model, test_dataloader, device)\n",
    "print(f'Accuracy of ConvNet on CIFAR100 is {accuracy_convnet}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1436d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN : 25.03%\n"
     ]
    }
   ],
   "source": [
    "print(f\"CNN : {accuracy_convnet}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72194536",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

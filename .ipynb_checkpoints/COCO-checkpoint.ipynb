{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26cd2e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "NOTE! Installing ujson may make loading annotations faster.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "!pip install ftfy\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip\n",
    "\n",
    "import clip\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from torchvision import transforms\n",
    "import json\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import random\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import torchvision.models as models\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7fd4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycocotools\n",
    "# # 下载并解压缩 COCO 训练集（2017年版）\n",
    "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
    "# !unzip train2017.zip -d ./COCO/\n",
    "\n",
    "# # 下载并解压缩 COCO 验证集（2017年版）\n",
    "# !wget http://images.cocodataset.org/zips/val2017.zip\n",
    "# !unzip val2017.zip -d ./COCO/\n",
    "\n",
    "# # 下载并解压缩 COCO 测试集（2017年版）\n",
    "# !wget http://images.cocodataset.org/zips/test2017.zip\n",
    "# !unzip test2017.zip -d ./COCO/\n",
    "\n",
    "# # 下载并解压缩 COCO 注释文件\n",
    "# !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "# !unzip annotations_trainval2017.zip -d ./COCO/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7973118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 该数据集包含120个不同种类的狗，适用于多类别分类任务。它提供了具有挑战性的狗的图像。\n",
    "# # 下载 Stanford Dogs Dataset 压缩文件\n",
    "# !wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
    "# # 解压缩文件\n",
    "# !tar xf images.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139458b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# FGVC-Aircraft 是一个包含10,000张图像的细粒度飞机分类数据集，共有100个飞机类别。这个数据集用于细粒度分类任务，其中飞机的不同型号\n",
    "# 需要进行区分。\n",
    "# '''\n",
    "# !wget https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\n",
    "# !tar zxvf fgvc-aircraft-2013b.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d77a029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 下载图像数据集（train、validation、test）\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable.tar\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/validation/validation-images-boxable.tar\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/test/test-images.tar\n",
    "\n",
    "# # 下载图像标签和元数据\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/train/train-annotations-human-imagelabels-boxable.csv\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-human-imagelabels-boxable.csv\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/test/test-annotations-human-imagelabels-boxable.csv\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv\n",
    "# !wget https://storage.googleapis.com/openimages/2018_04/test/challenge-2018-attributes-description.csv\n",
    "\n",
    "# # 解压缩图像数据集\n",
    "# !tar xf train-images-boxable.tar\n",
    "# !tar xf validation-images-boxable.tar\n",
    "# !tar xf test-images.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "936bd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个还没下载\n",
    "# '''\n",
    "# 该数据集的 GPS 坐标对应于 ISO-3166 国家/地区代码，并通过对每个国家/地区的 150 张火车图像、50 张验证图像和 100 张测试图\n",
    "# 像进行采样来创建一个平衡的数据集\n",
    "# '''\n",
    "# !wget https://openaipublic.azureedge.net/clip/data/country211.tgz\n",
    "# !tar zxvf country211.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e93e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Pillow\n",
    "# # 将coco数据集中val-2017中的所有图像大小变为一致的\n",
    "# # 指定 COCO val-2017 图像文件夹路径\n",
    "# coco_val_folder = 'COCO/val2017'\n",
    "# # 指定调整后的图像大小\n",
    "# target_size = (256, 256)\n",
    "# # 输出调整大小后的图像保存路径\n",
    "# output_folder = 'COCO/val2017_resized'\n",
    "# # 确保输出文件夹存在\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "# # 遍历 val-2017 文件夹中的所有图像文件\n",
    "# for filename in os.listdir(coco_val_folder):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         # 读取图像\n",
    "#         img_path = os.path.join(coco_val_folder, filename)\n",
    "#         img = Image.open(img_path)\n",
    "#         # 调整图像大小\n",
    "#         resized_img = img.resize(target_size)\n",
    "#         # 保存调整大小后的图像\n",
    "#         output_path = os.path.join(output_folder, filename)\n",
    "#         resized_img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bfe06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义一个自定义的 collate_fn 函数，确保每个批次的图像具有相同的大小\n",
    "# def collate_fn(batch):\n",
    "#     # 提取图像和目标\n",
    "#     images, targets = zip(*batch)\n",
    "#     images = torch.stack(images, dim=0)\n",
    "\n",
    "#     # 处理目标，确保它符合模型的期望格式\n",
    "#     if isinstance(targets[0], dict):  # 如果目标是字典类型\n",
    "#         targets_dict = {}\n",
    "#         for key in targets[0].keys():\n",
    "#             targets_dict[key] = torch.tensor([t[key] for t in targets], dtype=torch.float32)\n",
    "#         return images, targets_dict\n",
    "#     else:  # 如果目标不是字典类型，根据实际情况进行调整\n",
    "#         # 例如，假设目标是分类标签\n",
    "#         targets_tensor = torch.tensor(targets, dtype=torch.float32)\n",
    "#         return images, targets_tensor\n",
    "# # 创建 DataLoader 时指定 collate_fn\n",
    "# data_loader = DataLoader(\n",
    "#     coco_dataset, \n",
    "#     batch_size=32, \n",
    "#     shuffle=True, \n",
    "#     collate_fn=collate_fn\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed31af7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark']\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的 ResNet-50 模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 获取 ImageNet 类别名称的 URL\n",
    "imagenet_classes_url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "\n",
    "# 下载并加载类别名称\n",
    "response = requests.get(imagenet_classes_url)\n",
    "class_names = response.json()\n",
    "\n",
    "# 展示前几个类别作为示例\n",
    "print(class_names[:5])\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268659ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "存在重合\n",
      "存在重合的类别: {'vase', 'orange', 'dining table', 'refrigerator', 'zebra', 'banana', 'kite', 'parking meter', 'traffic light', 'cup', 'hot dog', 'backpack', 'pizza', 'toaster', 'umbrella', 'teddy bear', 'couch', 'sink', 'broccoli'}\n"
     ]
    }
   ],
   "source": [
    "dict = {1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', \n",
    "10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',\n",
    "21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase', \n",
    "34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', \n",
    "43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', \n",
    "54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', \n",
    "64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', \n",
    "78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', \n",
    "89: 'hair drier', 90: 'toothbrush'}\n",
    "all_values = dict.values()\n",
    "list = []\n",
    "for value in all_values:\n",
    "    list.append(value)\n",
    "# 判断是否存在重合\n",
    "if set(list) & set(class_names):\n",
    "    print(\"存在重合\")\n",
    "else:\n",
    "    print(\"不存在重合\")\n",
    "# 找到重合\n",
    "intersection_set = set(list) & set(class_names)\n",
    "if intersection_set:\n",
    "    print(\"存在重合的类别:\", intersection_set)\n",
    "else:\n",
    "    print(\"不存在重合\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dd66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "直接使用RN50进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ecf2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations into memory...\n",
      "Done (t=0.55s)\n",
      "Creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# 加载 ResNet-50 模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet50(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def my_collate_fn(batch):\n",
    "    images = [item[0] for item in batch]  # 提取所有图像\n",
    "    targets = [item[1] for item in batch]  # 提取所有标注\n",
    "    images = torch.stack(images)  # 将图像堆叠成一个批次\n",
    "    return images, targets\n",
    "\n",
    "# 加载 COCO 数据集\n",
    "coco_root = 'COCO'  \n",
    "coco_dataset = CocoDetection(root=os.path.join(coco_root, 'val2017'), \n",
    "                             annFile=os.path.join(coco_root, 'annotations/instances_val2017.json'),\n",
    "                             transform=transform)\n",
    "data_loader = DataLoader(coco_dataset, batch_size=1, shuffle=True, collate_fn=my_collate_fn)\n",
    "\n",
    "# 仅选择1000*1个图像进行训练\n",
    "selected_data_loader = islice(data_loader, 1000)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0a8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个list储存真实的类别\n",
    "true_class_list = []\n",
    "# 创建一个list储存预测类别\n",
    "predict_class_list = []\n",
    "# 创建一些可能用得上的list\n",
    "id = []\n",
    "image_id = []\n",
    "\n",
    "# 迭代数据加载器进行图像分类\n",
    "for images, targets in selected_data_loader:\n",
    "    images = images.to(device)\n",
    "    \n",
    "    tmp_class_list = []\n",
    "    tmp_id_list = []\n",
    "    tmp_image_id_list = []\n",
    "    \n",
    "    # 获取图像的类别ID\n",
    "    for list in targets:\n",
    "        for i in list:\n",
    "            tmp_class_list.append(i['category_id'])\n",
    "            tmp_id_list.append(i['id'])\n",
    "            tmp_image_id_list.append(i['image_id'])\n",
    "            \n",
    "    true_class_list.append(tmp_class_list)\n",
    "    id.append(tmp_id_list)\n",
    "    image_id.append(tmp_image_id_list)\n",
    "            \n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    # 获取预测的类别索引（选择分数最高的类别）\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "#     print(predicted)\n",
    "    # 查看预测的类别名称\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    predict_class_list.append(predicted_class)\n",
    "    \n",
    "# print(id)\n",
    "# print(image_id)\n",
    "# print(true_class_list)\n",
    "# print(predict_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b0e134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations into memory...\n",
      "Done (t=0.58s)\n",
      "Creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load COCO dataset\n",
    "coco_root = 'COCO'  # Replace with your local path to COCO dataset\n",
    "coco = COCO(os.path.join(coco_root, 'annotations/instances_val2017.json'))\n",
    "\n",
    "ture_categories_list = []\n",
    "for list in true_class_list:\n",
    "    tmp_list = []\n",
    "    for i in list:\n",
    "        category_info = coco.loadCats(i)\n",
    "        tmp_list.append(category_info[0]['name'])\n",
    "    ture_categories_list.append(tmp_list)\n",
    "# print(ture_categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48bd2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(ture_categories_list)): # 或len(predict_class_list)\n",
    "    if set(ture_categories_list[i]) & set(predict_class_list[i]):\n",
    "        count = count + 1\n",
    "Accuracy = count/len(ture_categories_list)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "微调一下（已完成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395fdb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations into memory...\n",
      "Done (t=0.55s)\n",
      "Creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# 加载 ResNet-50 模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet50(pretrained=True)\n",
    "\n",
    "# 替换最后的全连接层以匹配COCO的类别数 (90)(实际只有80个类别)\n",
    "model.fc = nn.Linear(model.fc.in_features, 90)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def my_collate_fn(batch):\n",
    "    images = [item[0] for item in batch]  # 提取所有图像\n",
    "    targets = [item[1] for item in batch]  # 提取所有标注\n",
    "    images = torch.stack(images)  # 将图像堆叠成一个批次\n",
    "    return images, targets\n",
    "\n",
    "# 加载 COCO 数据集\n",
    "coco_root = 'COCO'  \n",
    "coco_dataset = CocoDetection(root=os.path.join(coco_root, 'val2017'), \n",
    "                             annFile=os.path.join(coco_root, 'annotations/instances_val2017.json'),\n",
    "                             transform=transform)\n",
    "data_loader = DataLoader(coco_dataset, batch_size=1, shuffle=True, collate_fn=my_collate_fn)\n",
    "\n",
    "# 仅选择16*1个图像进行训练\n",
    "selected_data_loader = islice(data_loader, 16)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae170dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: sidewinder\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: sidewinder\n",
      "Predicted Class: sidewinder\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: American alligator\n",
      "Predicted Class: sidewinder\n"
     ]
    }
   ],
   "source": [
    "# 迭代数据加载器进行图像分类\n",
    "for images, _ in selected_data_loader:\n",
    "    images = images.to(device)\n",
    "\n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    # 获取预测的类别索引（选择分数最高的类别）\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    # 查看预测的类别名称\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    \n",
    "    print(f'Predicted Class: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2298a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO class labels 这是干啥的？RN-50又没法结合文本？\n",
    "with open(os.path.join(coco_root, 'annotations/instances_val2017.json')) as f:\n",
    "    coco_classes = json.load(f)['categories']\n",
    "# coco_classes相当于clip中all_categories_info\n",
    "coco_classes = {cls['id']: cls['name'] for cls in coco_classes}\n",
    "'''\n",
    "print(coco_classes)输出：\n",
    "{1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', \n",
    "10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',\n",
    "21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase', \n",
    "34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', \n",
    "43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', \n",
    "54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', \n",
    "64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', \n",
    "78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', \n",
    "89: 'hair drier', 90: 'toothbrush'}\n",
    "'''\n",
    "\n",
    "# 假设预训练模型的类别信息存储在 imagenet_labels 中\n",
    "# imagenet_labels = ...  # 根据实际情况获取预训练模型的类别信息\n",
    "\n",
    "# 将预训练类别信息与 COCO 数据集的类别信息匹配\n",
    "# coco_to_imagenet_mapping = {}\n",
    "# for coco_id, coco_name in coco_classes.items():\n",
    "#     for idx, imagenet_name in enumerate(imagenet_labels):\n",
    "#         if coco_name.lower() in imagenet_name.lower():\n",
    "#             coco_to_imagenet_mapping[coco_id] = idx\n",
    "#             break\n",
    "\n",
    "# 收集预测和真实标签\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    for images, targets in selected_data_loader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "#         print(outputs)\n",
    "#         print(outputs.shape)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "#         print(predicted)\n",
    "        class_id = predicted.item()\n",
    "\n",
    "        # Map class ID to class name using COCO class labels\n",
    "        class_name = coco_classes.get(class_id, 'Unknown')\n",
    "        if class_name != 'Unknown':\n",
    "            print(f\"Predicted Class ID: {class_id}, Class Name: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3288bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 3.1956, Accuracy: 18.38%\n",
      "Epoch [2/10], Loss: 3.6531, Accuracy: 19.02%\n",
      "Epoch [3/10], Loss: 3.8692, Accuracy: 19.20%\n",
      "Epoch [4/10], Loss: 1.6400, Accuracy: 19.22%\n",
      "Epoch [5/10], Loss: 4.3638, Accuracy: 19.22%\n",
      "Epoch [6/10], Loss: 1.6790, Accuracy: 19.20%\n",
      "Epoch [7/10], Loss: 3.4012, Accuracy: 19.16%\n",
      "Epoch [8/10], Loss: 0.9001, Accuracy: 19.29%\n",
      "Epoch [9/10], Loss: 4.9150, Accuracy: 19.20%\n",
      "Epoch [10/10], Loss: 3.9513, Accuracy: 19.39%\n",
      "微调完成！\n"
     ]
    }
   ],
   "source": [
    "# 微调模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for images, labels in data_loader:\n",
    "        images = images.to(device)\n",
    "        # 这里就是一张图里面多个图像-labels-长度不为1的原因\n",
    "        # 我们都只取第一个吧-没法子\n",
    "        # 有时候会出现[[]]?????????原因未知\n",
    "        if len(labels[0]) != 0:\n",
    "            labels = labels[0][0]['category_id']\n",
    "            labels = torch.tensor([labels])\n",
    "            labels = labels.to(device)\n",
    "#             print(labels)\n",
    "        \n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "#             print(outputs)\n",
    "#             print(len(outputs[0]))\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "print('微调完成！')\n",
    "\n",
    "# 可以保存模型以备将来使用\n",
    "torch.save(model.state_dict(), 'coco_finetuned_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "使用微调过的RN50进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12b636f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "Creating index...\n",
      "index created!\n",
      "Accuracy: 19.18%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 定义设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义预处理变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载COCO val2017数据集\n",
    "coco_val_dataset = CocoDetection(root='COCO/val2017', annFile='COCO/annotations/instances_val2017.json', transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "data_loader = DataLoader(coco_val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 加载微调后的ResNet-50模型\n",
    "model = resnet50()\n",
    "model.fc = torch.nn.Linear(2048, 90)  # 修改最后一层的输出维度\n",
    "model.load_state_dict(torch.load('coco_finetuned_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "# 进行预测\n",
    "with torch.no_grad():\n",
    "    for images, targets in data_loader:\n",
    "        images = images.to(device)\n",
    "        try:\n",
    "            targets = targets[0]['category_id'].to(device)  # 获取真实标签（category_id）\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            # 获取预测的类别索引\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # 计算准确度\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "        except IndexError: # 自动跳过错误，反正也不计入，不影响\n",
    "            # 如果发生IndexError，输出错误信息并继续下一次循环\n",
    "            continue\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算性能指标\n",
    "# accuracy = accuracy_score(true_labels, predictions)\n",
    "# precision = precision_score(true_labels, predictions, average='weighted')\n",
    "# recall = recall_score(true_labels, predictions, average='weighted')\n",
    "# f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "# print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "开始clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "574da0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/16\", device=device) # RN50, ViT-B/32, ViT-B/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52b20b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations into memory...\n",
      "Done (t=1.14s)\n",
      "Creating index...\n",
      "index created!\n",
      "[397133, 37777, 252219, 87038, 174482, 403385, 6818, 480985, 458054, 331352, 296649, 386912, 502136, 491497, 184791, 348881, 289393, 522713, 181666, 17627, 143931, 303818, 463730, 460347, 322864, 226111, 153299, 308394, 456496, 58636, 41888, 184321, 565778, 297343, 336587, 122745, 219578, 555705, 443303, 500663, 418281, 25560, 403817, 85329, 329323, 239274, 286994, 511321, 314294, 233771, 475779, 301867, 312421, 185250, 356427, 572517, 270244, 516316, 125211, 562121, 360661, 16228, 382088, 266409, 430961, 80671, 577539, 104612, 476258, 448365, 35197, 349860, 180135, 486438, 400573, 109798, 370677, 238866, 369370, 502737, 515579, 515445, 173383, 438862, 180560, 347693, 39956, 321214, 474028, 66523, 355257, 142092, 63154, 199551, 239347, 514508, 473237, 228144, 206027, 78915]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Load COCO dataset\n",
    "coco_root = 'COCO'  # Replace with your local path to COCO dataset\n",
    "coco = COCO(os.path.join(coco_root, 'annotations/instances_val2017.json'))\n",
    "\n",
    "# 随机100张图片\n",
    "# Get all image IDs\n",
    "imgIds = coco.getImgIds()\n",
    "# Randomly select 100 image IDs\n",
    "# selected_imgIds = random.sample(imgIds, 100)\n",
    "selected_imgIds = imgIds[0:100]\n",
    "print(selected_imgIds)\n",
    "# 100个图像\n",
    "coco_imgs = coco.loadImgs(selected_imgIds)  # Load a subset for demonstration\n",
    "print(len(coco_imgs))\n",
    "\n",
    "####################################\n",
    "# 获取所有类别的ID\n",
    "all_category_ids = coco.getCatIds()\n",
    "# 获取所有类别的详细信息\n",
    "all_categories_info = coco.loadCats(all_category_ids)\n",
    "# 输出格式：[{大类别，id，小类别}, {}，。。。。。。]\n",
    "####################################\n",
    "\n",
    "# Prepare images and texts for CLIP\n",
    "images = [preprocess(Image.open(os.path.join(coco_root, 'val2017', img['file_name']))).unsqueeze(0).to(device) for img in coco_imgs]\n",
    "# 注意下zero-shot的原理：1*n的matrix\n",
    "texts = [clip.tokenize(f\"a photo of a {ann['name']}\") for ann in all_categories_info]\n",
    "texts = torch.cat(texts).to(device)\n",
    "\n",
    "# Inference and evaluation\n",
    "with torch.no_grad():\n",
    "    image_features = torch.cat([model.encode_image(img) for img in images])\n",
    "    text_features = model.encode_text(texts)\n",
    "    # Normalize features\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    # Calculate similarity and top predictions\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    top_predictions = similarity.topk(5, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fb2bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建一个list储存这些真实的类别\n",
    "true_categories_list = []\n",
    "\n",
    "# 加载并显示这50张图像及其真实类别\n",
    "for imgId in selected_imgIds:\n",
    "    img = coco.loadImgs(imgId)[0]\n",
    "    image_path = os.path.join(coco_root, 'val2017', img['file_name'])\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Get annotations for the image\n",
    "    annIds = coco.getAnnIds(imgIds=img['id'])\n",
    "    anns = coco.loadAnns(annIds)\n",
    "\n",
    "    # Extract and print true categories\n",
    "    categories = [coco.loadCats(ann['category_id'])[0]['name'] for ann in anns]\n",
    "#     print(f\"Image ID: {img['id']}, True Categories: {', '.join(categories)}\")\n",
    "    # 创建list，储存一张图的多个类别\n",
    "    list = []\n",
    "    for ann in anns:\n",
    "        list.append(coco.loadCats(ann['category_id'])[0]['name'])\n",
    "    true_categories_list.append(list)\n",
    "\n",
    "# print(true_categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "下面是只取概率最大的那一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd88cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = top_predictions[0]  # 排序后的值张量\n",
    "indices = top_predictions[1]  # 对应的索引张量 \n",
    "\n",
    "# 将tensor转化成list\n",
    "indices_list = [[int(aa) for aa in row.tolist()] for row in indices]\n",
    "values_list = [[float(aa) for aa in row.tolist()] for row in values]\n",
    "\n",
    "# 创建一个list，储存这些预测的类别\n",
    "predict_categories_list = []\n",
    "\n",
    "# Display top 5 predictions for each image\n",
    "for i, img in enumerate(coco_imgs): # i从1：50，因为我们选取[:50]的图像\n",
    "    index = indices_list[i]\n",
    "    value = values_list[i]\n",
    "    # 判断概率最大代表的类别的标签是否存在于val-2017中\n",
    "    if index[0] in all_category_ids:\n",
    "#         print(f\"\\nImage: {img['file_name']}\")\n",
    "        category_info = coco.loadCats(index[0])\n",
    "#         print(category_info)\n",
    "#         # 输出是一个dict套在list里面:[{'supercategory': 'food', 'id': 60, 'name': 'donut'}]\n",
    "#         print(\"ID:\", category_info[0]['id'], \"Name:\", category_info[0]['name'], \"Value:\", value[0])\n",
    "        predict_categories_list.append(category_info[0]['name'])\n",
    "    else:\n",
    "#         print(f\"\\nImage: {img['file_name']}\")\n",
    "#         print(\"ID:\", \"unknown\", \"Name:\", \"unknown\", \"Value:\", \"unknown\")\n",
    "        predict_categories_list.append(\"unknown\")\n",
    "    \n",
    "# print(predict_categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "838cf1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n"
     ]
    }
   ],
   "source": [
    "# 看看clip在这些图像上的正确率\n",
    "length = len(true_categories_list) # or length = len(predict_categories_list)\n",
    "# 设置一个count，记录正确的个数\n",
    "count = 0\n",
    "for i in range(length):\n",
    "    if predict_categories_list[i] in true_categories_list[i]:\n",
    "        count+=1\n",
    "accuracy = count/length\n",
    "print(\"{:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "下面是取概率（存在的）前5个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c091829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n"
     ]
    }
   ],
   "source": [
    "values = top_predictions[0]  # 排序后的值张量\n",
    "indices = top_predictions[1]  # 对应的索引张量 \n",
    "\n",
    "# 将tensor转化成list\n",
    "indices_list = [[int(aa) for aa in row.tolist()] for row in indices]\n",
    "values_list = [[float(aa) for aa in row.tolist()] for row in values]\n",
    "\n",
    "# 创建一个list，储存这些预测的类别\n",
    "predict_categories_list = []\n",
    "\n",
    "# Display top 5 predictions for each image\n",
    "for i, img in enumerate(coco_imgs): # i从1：50，因为我们选取[:50]的图像\n",
    "    index = indices_list[i]\n",
    "    value = values_list[i]\n",
    "    # 初始化list\n",
    "    list = []\n",
    "    # 修改这里即可看出前n大\n",
    "    for m in range(1):\n",
    "        if index[m] in all_category_ids:\n",
    "            category_info = coco.loadCats(index[m])\n",
    "            list.append(category_info[0]['name'])\n",
    "        else:\n",
    "            list.append(\"unknown\")\n",
    "    \n",
    "    predict_categories_list.append(list)\n",
    "    \n",
    "# 看看clip在这些图像上的正确率\n",
    "length = len(true_categories_list) # or length = len(predict_categories_list)\n",
    "# 设置一个count，记录正确的个数\n",
    "count = 0\n",
    "for i in range(length):\n",
    "    if set(predict_categories_list[i]) & set(true_categories_list[i]):\n",
    "        count+=1\n",
    "accuracy = count/length\n",
    "print(\"{:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef950a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "下面是对比clip和基线模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dfe839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不显示\n",
    "%%capture\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 假设你已经有了 CLIP 和基准模型的预测结果\n",
    "clip_predictions = [...]  # CLIP 模型的预测\n",
    "baseline_predictions = [...]  # 基准模型的预测\n",
    "true_labels = [...]  # 真实标签\n",
    "\n",
    "# 计算性能指标\n",
    "clip_accuracy = accuracy_score(true_labels, clip_predictions)\n",
    "baseline_accuracy = accuracy_score(true_labels, baseline_predictions)\n",
    "# ...同样计算其他指标\n",
    "\n",
    "# 可视化性能比较\n",
    "plt.bar(['CLIP', 'Baseline'], [clip_accuracy, baseline_accuracy])\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "cm = confusion_matrix(true_labels, clip_predictions)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('Confusion Matrix for CLIP Model')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c15a344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import CLIPProcessor, CLIPTokenizer, CLIPModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from transformers import CLIPModel, CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21350a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c904dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['automobile', 'airplane', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "dataset_name = 'CIFAR10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd2a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备text\n",
    "prompt = \"This is a\"\n",
    "text_inputs = torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in class_names]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7283ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model, image):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "    ##################### Write your answer here ##################\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    logit_scale = model.logit_scale.exp()\n",
    "\n",
    "    logits = logit_scale * image_features @ text_features.t()\n",
    "    ###############################################################\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f4c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接使用clip进行zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc74c256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR10 is 42.97%, visual encoder is RN50.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "VISUAL_BACKBONE = 'RN50' # RN50, ViT-B/32, ViT-B/16\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device)\n",
    "model.to(device)\n",
    "# zero-shot\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    \n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1903377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR10 is 68.45%, visual encoder is ViT-B/32.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "VISUAL_BACKBONE = 'ViT-B/32' # RN50, ViT-B/32, ViT-B/16\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device)\n",
    "model.to(device)\n",
    "# zero-shot\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    \n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69e34ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR10 is 69.59%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "VISUAL_BACKBONE = 'ViT-B/16' # RN50, ViT-B/32, ViT-B/16\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device)\n",
    "model.to(device)\n",
    "# zero-shot\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    \n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ecd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "开始使用ResNet50，不处理最后一层，直接使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16668304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载RN50在预训练过程中的1000个类别，判断与cifar10中的类别是否存在重合\n",
    "# 加载预训练的 ResNet-50 模型\n",
    "import torchvision.models as models\n",
    "import requests\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 获取 ImageNet 类别名称的 URL\n",
    "imagenet_classes_url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "\n",
    "# 下载并加载类别名称\n",
    "response = requests.get(imagenet_classes_url)\n",
    "RN50_class_names = response.json()\n",
    "\n",
    "cifar10_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "for name in cifar10_class_names:\n",
    "    if name in RN50_class_names:\n",
    "        print(name, \"in cifar10,\", \"is also in RN50_class_names\")\n",
    "    else:\n",
    "        print(name, \"in cifar10,\", \"is not in RN50_class_names\")\n",
    "        \n",
    "if set(RN50_class_names) & set(cifar10_class_names):\n",
    "    print(\"存在重合\")\n",
    "else:\n",
    "    print(\"不存在重合\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "没有直接预测的必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "训练ResNet50，对ResNet50最后一层进行处理1000——10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "383a69a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 设定设备\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 数据预处理\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-10 数据集\n",
    "batch_size = 128\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# 加载预训练的 ResNet-50 模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 替换最后的全连接层以匹配 CIFAR-10 的类别数 (10)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# 将模型发送到设备\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfd643f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.263, Training Accuracy: 55.52%\n",
      "Training time: 20.83 seconds\n",
      "GPU memory used: 200301568 bytes\n",
      "GPU memory cache: 50331648 bytes\n",
      "Epoch 1, Testing Loss: 0.850, Accuracy: 70.32%\n",
      "Epoch 2, Training Loss: 0.765, Training Accuracy: 73.30%\n",
      "Training time: 20.55 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 2, Testing Loss: 0.699, Accuracy: 76.03%\n",
      "Epoch 3, Training Loss: 0.637, Training Accuracy: 77.91%\n",
      "Training time: 20.46 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 3, Testing Loss: 0.633, Accuracy: 78.66%\n",
      "Epoch 4, Training Loss: 0.559, Training Accuracy: 80.50%\n",
      "Training time: 20.43 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 4, Testing Loss: 0.586, Accuracy: 80.09%\n",
      "Epoch 5, Training Loss: 0.502, Training Accuracy: 82.55%\n",
      "Training time: 20.42 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 5, Testing Loss: 0.549, Accuracy: 81.51%\n",
      "Epoch 6, Training Loss: 0.458, Training Accuracy: 84.16%\n",
      "Training time: 20.39 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 6, Testing Loss: 0.530, Accuracy: 82.08%\n",
      "Epoch 7, Training Loss: 0.422, Training Accuracy: 85.23%\n",
      "Training time: 20.45 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 7, Testing Loss: 0.521, Accuracy: 82.29%\n",
      "Epoch 8, Training Loss: 0.385, Training Accuracy: 86.52%\n",
      "Training time: 20.35 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 8, Testing Loss: 0.514, Accuracy: 82.97%\n",
      "Epoch 9, Training Loss: 0.366, Training Accuracy: 87.22%\n",
      "Training time: 20.44 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 9, Testing Loss: 0.503, Accuracy: 83.21%\n",
      "Epoch 10, Training Loss: 0.334, Training Accuracy: 88.41%\n",
      "Training time: 20.46 seconds\n",
      "GPU memory used: 3584 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch 10, Testing Loss: 0.512, Accuracy: 83.25%\n",
      "Finished training and testing!\n"
     ]
    }
   ],
   "source": [
    "# 每个epoch记录一下train和test的acc和loss\n",
    "\n",
    "# 记录每个 epoch 的准确度和损失\n",
    "train_losses = []  # 训练集上的loss\n",
    "train_accuracies = []    # 训练集上的acc\n",
    "test_losses = []   # 测试集上的loss\n",
    "test_accuracies = [] # 测试集上的acc\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    ######################################################################\n",
    "    start_time = time.time()\n",
    "\n",
    "    initial_gpu_memory = torch.cuda.memory_allocated()\n",
    "    initial_gpu_memory_cache = torch.cuda.memory_reserved()\n",
    "    ########################################################\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # 每 2000 批次打印一次\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "    # 计算并记录每个 epoch 的训练损失和训练准确度\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {train_loss:.3f}, Training Accuracy: {train_accuracy:.2f}%')\n",
    "\n",
    "    ##########################################################\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Training time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    final_gpu_memory = torch.cuda.memory_allocated()\n",
    "    final_gpu_memory_cache = torch.cuda.memory_reserved()\n",
    "    print(f\"GPU memory used: {final_gpu_memory - initial_gpu_memory} bytes\")\n",
    "    print(f\"GPU memory cache: {final_gpu_memory_cache - initial_gpu_memory_cache} bytes\")\n",
    "    ##############################################################################\n",
    "\n",
    "    # 在测试集上测试模型\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    # 计算并记录每个 epoch 的测试损失和准确度\n",
    "    test_loss = test_loss / len(test_dataloader)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracy = 100 * correct_test / total_test\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Testing Loss: {test_loss:.3f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "#     print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "print('Finished training and testing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cf7f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the losses during the training [1.2629457576500485, 0.7647699090221044, 0.6374699798081537, 0.5594700205966335, 0.5020830824856868, 0.4579552922712263, 0.4218782549700164, 0.38457601576509987, 0.3655237842475057, 0.33381875187082366] \n",
      "\n",
      "This is the accuracies during the training [55.52, 73.304, 77.908, 80.5, 82.546, 84.164, 85.232, 86.52, 87.224, 88.406] \n",
      "\n",
      "This is the losses during the testing [0.8503681926787654, 0.6985623447955409, 0.6334442541569094, 0.5855103734927841, 0.5490107909788059, 0.5304075558728809, 0.5212985941126377, 0.5138863989069492, 0.5030311968507646, 0.5120128046108198] \n",
      "\n",
      "This is the accuracies during the testing [70.32, 76.03, 78.66, 80.09, 81.51, 82.08, 82.29, 82.97, 83.21, 83.25] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the losses during the training\", train_losses, \"\\n\")\n",
    "print(\"This is the accuracies during the training\", train_accuracies, \"\\n\")\n",
    "print(\"This is the losses during the testing\", test_losses, \"\\n\")\n",
    "print(\"This is the accuracies during the testing\", test_accuracies, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "353511b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "x = torch.arange(1, 11)\n",
    "\n",
    "plt.scatter(x, train_losses, color='red', label='train_losses')\n",
    "plt.scatter(x, train_accuracies, color='blue', label='train_accuracies')\n",
    "plt.scatter(x, test_losses, color='green', label='test_losses')\n",
    "plt.scatter(x, test_accuracies, color='yellow', label='test_accuracies')\n",
    "\n",
    "plt.title(\"Scatter Plot\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Acuracy AND Loss\")\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 0.05))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "训练clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision transformers # 运行过了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d366ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以保证结果的可重复性\n",
    "torch.manual_seed(100)\n",
    "\n",
    "# 初始化CLIP模型和处理器，并指定视觉骨干为ResNet-50\n",
    "VISUAL_BACKBONE = 'RN50' # RN50, ViT-B/32, ViT-B/16\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load the model\n",
    "model, processor = clip.load(name=VISUAL_BACKBONE, device=device)\n",
    "model.to(device)\n",
    "\n",
    "# 数据预处理\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-10 数据集\n",
    "BATCH_SIZE = 32\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b058228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] Loss: nan Accuracy: 0.1000\n",
      "Training time: 457.18 seconds\n",
      "GPU memory used: 811683328 bytes\n",
      "GPU memory cache: 3248488448 bytes\n",
      "Epoch [2/3] Loss: nan Accuracy: 0.1000\n",
      "Training time: 450.12 seconds\n",
      "GPU memory used: 0 bytes\n",
      "GPU memory cache: 0 bytes\n",
      "Epoch [3/3] Loss: nan Accuracy: 0.1000\n",
      "Training time: 448.74 seconds\n",
      "GPU memory used: 0 bytes\n",
      "GPU memory cache: 0 bytes\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CLIP' object has no attribute 'save_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 60\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU memory cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_gpu_memory_cache\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39minitial_gpu_memory_cache\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# 保存训练后的模型权重\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_cifar10_finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_cifar10_finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CLIP' object has no attribute 'save_pretrained'"
     ]
    }
   ],
   "source": [
    "# 训练参数\n",
    "num_epochs = 3\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    \n",
    "    ###############################################################################\n",
    "    start_time = time.time()\n",
    "\n",
    "    initial_gpu_memory = torch.cuda.memory_allocated()\n",
    "    initial_gpu_memory_cache = torch.cuda.memory_reserved()\n",
    "    #####################################################################################################################\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 文本预处理\n",
    "        text_descriptions = [\"a photo of a \" + str(label) for label in labels.tolist()]\n",
    "        text_inputs = clip.tokenize(text_descriptions).to(device)\n",
    "        # 图像预处理-注意：图像已经通过 DataLoader 和 transform_cifar10_train 进行了预处理-因此，这里不需要额外的图像处理代码\n",
    "        \n",
    "        # 训练过程\n",
    "        optimizer.zero_grad()\n",
    "        # 将处理后的图像和文本输入传递给模型\n",
    "        image_features = model.encode_image(images)\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "        # 计算损失\n",
    "        logits_per_image = model.logit_scale.exp() * image_features @ text_features.t()\n",
    "        loss = criterion(logits_per_image, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()        \n",
    "        # 记录预测和真实标签\n",
    "        predictions.extend(logits_per_image.argmax(1).cpu().tolist())\n",
    "        ground_truths.extend(labels.cpu().tolist())\n",
    "\n",
    "    # 计算准确度\n",
    "    accuracy = accuracy_score(ground_truths, predictions)\n",
    "\n",
    "    # 打印每个epoch的损失和准确度\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {total_loss / len(train_dataloader):.4f} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    ##########################################################\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Training time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    final_gpu_memory = torch.cuda.memory_allocated()\n",
    "    final_gpu_memory_cache = torch.cuda.memory_reserved()\n",
    "    print(f\"GPU memory used: {final_gpu_memory - initial_gpu_memory} bytes\")\n",
    "    print(f\"GPU memory cache: {final_gpu_memory_cache - initial_gpu_memory_cache} bytes\")\n",
    "    ##############################################################################\n",
    "    \n",
    "# 保存训练后的模型权重\n",
    "model.save_pretrained(\"clip_cifar10_finetuned\")\n",
    "tokenizer.save_pretrained(\"clip_cifar10_finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

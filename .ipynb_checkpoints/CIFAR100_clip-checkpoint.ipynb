{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84631c86",
   "metadata": {},
   "source": [
    "# CLIP zero-shot prediction\n",
    "## Basic import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416d1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4245c",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48ecb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random seed\n",
    "# SEED = 1 \n",
    "# NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "# NUM_EPOCHS = 30\n",
    "# EVAL_INTERVAL=1\n",
    "# SAVE_DIR = './log'\n",
    "\n",
    "# # Optimizer\n",
    "# LEARNING_RATE = 1e-1\n",
    "# MOMENTUM = 0.9\n",
    "# STEP=5\n",
    "# GAMMA=0.5\n",
    "\n",
    "# CLIP\n",
    "VISUAL_BACKBONE = 'RN50' # RN50, ViT-B/32, ViT-B/16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330841c2",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e6f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a5781",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a62dafd",
   "metadata": {},
   "source": [
    "### Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a72bc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model, preprocess= clip.load(name=VISUAL_BACKBONE, device=device, download_root='/clip/')\n",
    "model.to(device)\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce33f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR100(root='/shareddata', train=False,\n",
    "                                       download=True, transform=transform_cifar100_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle',\n",
    "    'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',\n",
    "    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard',\n",
    "    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain',\n",
    "    'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree',\n",
    "    'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea',\n",
    "    'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower',\n",
    "    'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle',\n",
    "    'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
    "]\n",
    "\n",
    "dataset_name = 'CIFAR100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ded646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'a photo of a' # you can try different prompt\n",
    "\n",
    "def prompt_encode(prompt):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        prompt (str): the text prefix before the class\n",
    "\n",
    "    Returns:\n",
    "        text_inputs(torch.Tensor)\n",
    "\n",
    "    \"\"\"\n",
    "    ##################### Write your answer here ##################\n",
    "    # 将文本编码为tensor    \n",
    "    text_inputs= torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in class_names]).to(device)\n",
    "    ###############################################################\n",
    "    return text_inputs\n",
    "\n",
    "# 编码文本提示\n",
    "text_inputs = prompt_encode(prompt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73eadc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model, image, text_inputs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (torch.nn.Module): 训练好的机器学习模型\n",
    "        image (torch.Tensor): 输入图像张量\n",
    "        text_inputs (torch.Tensor): 输入文本张量\n",
    "\n",
    "    Returns:\n",
    "        logits (torch.Tensor): 模型的预测logits\n",
    "    \"\"\"\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    logits = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1052abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR100 is 25.81%, visual encoder is RN50.\n"
     ]
    }
   ],
   "source": [
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  \n",
    "    ##################### Write your answer here ##################\n",
    "    correct_predictions = 0\n",
    "    for image, class_id in test_dataloader:\n",
    "        image=image.to(device)\n",
    "        class_id=class_id.to(device)\n",
    "        \n",
    "        logits=model_inference(model,image,text_inputs)\n",
    "        \n",
    "        predictions = logits.argmax(dim=-1)\n",
    "#         print(predictions,class_id)\n",
    "        correct_predictions += (predictions == class_id).sum().item()\n",
    "    \n",
    "    val_acc = correct_predictions / len(test_set)\n",
    "    \n",
    "    ###############################################################\n",
    "\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02: Multi-class Classification \n",
    "In this exercise, you will train a deep model on the CIFAR10 from the scratch using PyTorch. The following tasks should be done:\n",
    "- Task 1: per batch training/testing\n",
    "- Task 2: Instance inference and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 9144\n",
      "Training dataset size: 6400\n",
      "Testing dataset size: 2744\n",
      "Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "# 定义数据集的根目录\n",
    "root_directory = \"caltech101/101_ObjectCategories\"\n",
    "\n",
    "# 定义转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# 创建数据集实例\n",
    "caltech_dataset = torchvision.datasets.ImageFolder(root=root_directory+'/', transform=transform)\n",
    "\n",
    "# 设置训练和测试数据集的比例\n",
    "train_ratio = 0.7\n",
    "dataset_size = len(caltech_dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "# 划分训练和测试数据集\n",
    "train_set, test_set = random_split(caltech_dataset, [train_size, test_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=12)\n",
    "test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=12)\n",
    "\n",
    "# 打印数据集和加载器的大小\n",
    "print(f\"Total dataset size: {dataset_size}\")\n",
    "print(f\"Training dataset size: {len(train_set)}\")\n",
    "print(f\"Testing dataset size: {len(test_set)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(32 * 27 * 27, 32)\n",
    "        self.fc2 = nn.Linear(32, 102)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 27 * 27)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=23328, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=102, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output,target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0357 Acc: 0.0816\n",
      "Begin test......\n",
      "Test Loss: 0.0339 Acc: 0.0842\n",
      "Epoch: 2/30 Train Loss: 0.0328 Acc: 0.0891\n",
      "Begin test......\n",
      "Test Loss: 0.0336 Acc: 0.0907\n",
      "Epoch: 3/30 Train Loss: 0.0327 Acc: 0.0841\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 4/30 Train Loss: 0.0327 Acc: 0.0864\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 5/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 6/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0907\n",
      "Epoch: 7/30 Train Loss: 0.0326 Acc: 0.0880\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 8/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 9/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 10/30 Train Loss: 0.0326 Acc: 0.0877\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0907\n",
      "Epoch: 11/30 Train Loss: 0.0326 Acc: 0.0867\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 12/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 13/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 14/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 15/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 16/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 17/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 18/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 19/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 20/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 21/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 22/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 23/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 24/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 25/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 26/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 27/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 28/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 29/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n",
      "Epoch: 30/30 Train Loss: 0.0326 Acc: 0.0889\n",
      "Begin test......\n",
      "Test Loss: 0.0335 Acc: 0.0842\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################ew\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for  image, target in train_dataloader:\n",
    "#         print(f\"Image shape: {image.shape}, Target shape: {target.shape}\")\n",
    "#         print(batch_idx)\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

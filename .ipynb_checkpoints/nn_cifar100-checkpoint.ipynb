{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 60\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A30 MIG 1g.6gb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Check if CUDA is available\n",
    "print(torch.cuda.get_device_name(0))  # Check the name of the CUDA device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform= transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR100(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR100(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = train_set.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu3(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        \n",
    "        x = self.relu4(self.dropout1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "#         self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "#         self.fc2 = nn.Linear(32, 100)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 8 * 6 * 6)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (relu4): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(target, num_classes):\n",
    "    return F.one_hot(target, num_classes=num_classes).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=1.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: raw scores (logits) for each class. [batch_size, num_classes]\n",
    "        y_true: ground truth labels. [batch_size]\n",
    "        \"\"\"\n",
    "        # Convert y_true labels into one-hot encoding\n",
    "        y_true_onehot = torch.zeros(y_pred.size(), device=y_pred.device).scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "        \n",
    "        # Calculate softmax over y_pred for calculating probabilities\n",
    "        probs = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        focal_loss = -self.alpha * (y_true_onehot * torch.log(probs) * (1 - probs) ** self.gamma).sum(dim=1).mean()\n",
    "        \n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = FocalLoss()\n",
    "#criterion = nn.L1Loss()\n",
    "#lossfunction = 'epo100FC201'\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated by the defined loss function loss_fn().\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    output = model(image)\n",
    "    loss = criterion(output, target)\n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 Begin test......\n",
      "epoch:0 finished\n",
      "epoch:1 Begin test......\n",
      "epoch:1 finished\n",
      "epoch:2 Begin test......\n",
      "epoch:2 finished\n",
      "epoch:3 Begin test......\n",
      "epoch:3 finished\n",
      "epoch:4 Begin test......\n",
      "epoch:4 finished\n",
      "epoch:5 Begin test......\n",
      "epoch:5 finished\n",
      "epoch:6 Begin test......\n",
      "epoch:6 finished\n",
      "epoch:7 Begin test......\n",
      "epoch:7 finished\n",
      "epoch:8 Begin test......\n",
      "epoch:8 finished\n",
      "epoch:9 Begin test......\n",
      "epoch:9 finished\n",
      "epoch:10 Begin test......\n",
      "epoch:10 finished\n",
      "epoch:11 Begin test......\n",
      "epoch:11 finished\n",
      "epoch:12 Begin test......\n",
      "epoch:12 finished\n",
      "epoch:13 Begin test......\n",
      "epoch:13 finished\n",
      "epoch:14 Begin test......\n",
      "epoch:14 finished\n",
      "epoch:15 Begin test......\n",
      "epoch:15 finished\n",
      "epoch:16 Begin test......\n",
      "epoch:16 finished\n",
      "epoch:17 Begin test......\n",
      "epoch:17 finished\n",
      "epoch:18 Begin test......\n",
      "epoch:18 finished\n",
      "epoch:19 Begin test......\n",
      "epoch:19 finished\n",
      "epoch:20 Begin test......\n",
      "epoch:20 finished\n",
      "epoch:21 Begin test......\n",
      "epoch:21 finished\n",
      "epoch:22 Begin test......\n",
      "epoch:22 finished\n",
      "epoch:23 Begin test......\n",
      "epoch:23 finished\n",
      "epoch:24 Begin test......\n",
      "epoch:24 finished\n",
      "epoch:25 Begin test......\n",
      "epoch:25 finished\n",
      "epoch:26 Begin test......\n",
      "epoch:26 finished\n",
      "epoch:27 Begin test......\n",
      "epoch:27 finished\n",
      "epoch:28 Begin test......\n",
      "epoch:28 finished\n",
      "epoch:29 Begin test......\n",
      "epoch:29 finished\n",
      "epoch:30 Begin test......\n",
      "epoch:30 finished\n",
      "epoch:31 Begin test......\n",
      "epoch:31 finished\n",
      "epoch:32 Begin test......\n",
      "epoch:32 finished\n",
      "epoch:33 Begin test......\n",
      "epoch:33 finished\n",
      "epoch:34 Begin test......\n",
      "epoch:34 finished\n",
      "epoch:35 Begin test......\n",
      "epoch:35 finished\n",
      "epoch:36 Begin test......\n",
      "epoch:36 finished\n",
      "epoch:37 Begin test......\n",
      "epoch:37 finished\n",
      "epoch:38 Begin test......\n",
      "epoch:38 finished\n",
      "epoch:39 Begin test......\n",
      "epoch:39 finished\n",
      "epoch:40 Begin test......\n",
      "epoch:40 finished\n",
      "epoch:41 Begin test......\n",
      "epoch:41 finished\n",
      "epoch:42 Begin test......\n",
      "epoch:42 finished\n",
      "epoch:43 Begin test......\n",
      "epoch:43 finished\n",
      "epoch:44 Begin test......\n",
      "epoch:44 finished\n",
      "epoch:45 Begin test......\n",
      "epoch:45 finished\n",
      "epoch:46 Begin test......\n",
      "epoch:46 finished\n",
      "epoch:47 Begin test......\n",
      "epoch:47 finished\n",
      "epoch:48 Begin test......\n",
      "epoch:48 finished\n",
      "epoch:49 Begin test......\n",
      "epoch:49 finished\n",
      "epoch:50 Begin test......\n",
      "epoch:50 finished\n",
      "epoch:51 Begin test......\n",
      "epoch:51 finished\n",
      "epoch:52 Begin test......\n",
      "epoch:52 finished\n",
      "epoch:53 Begin test......\n",
      "epoch:53 finished\n",
      "epoch:54 Begin test......\n",
      "epoch:54 finished\n",
      "epoch:55 Begin test......\n",
      "epoch:55 finished\n",
      "epoch:56 Begin test......\n",
      "epoch:56 finished\n",
      "epoch:57 Begin test......\n",
      "epoch:57 finished\n",
      "epoch:58 Begin test......\n",
      "epoch:58 finished\n",
      "epoch:59 Begin test......\n",
      "epoch:59 finished\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "run_num = 1\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Now run your training code\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "    \n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        \n",
    "#         print(\"Image shape:\", image.shape)\n",
    "#         print(\"Image dtype:\", image.dtype)\n",
    "#         print(\"Contains NaN:\", torch.isnan(image).any())\n",
    "#         print(\"Contains Inf:\", torch.isinf(image).any())\n",
    "\n",
    "#         print(run_num)\n",
    "#         run_num += 1\n",
    "#         print(target.shape)\n",
    "#         print(target)\n",
    "#         print('\\n')\n",
    "        \n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear gradients before the forward pass\n",
    "\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        loss_data = loss.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('Loss is NaN while training')\n",
    "\n",
    "        running_cls_loss += loss_data\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    #print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    # Rest of your code for testing and checkpoint saving...\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print(f'epoch:{epoch} Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):  #CE-Loss/FCLoss\n",
    "\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)           #CE-Loss/FCLoss\n",
    "      \n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        #print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        print(f'epoch:{epoch} finished')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy on CIFAR-100 test images: 39.71%\n"
     ]
    }
   ],
   "source": [
    "print(f'NN Accuracy on CIFAR-100 test images: {testing_acc[-1] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

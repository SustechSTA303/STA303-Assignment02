{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244b9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e85ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4048489",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f912ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载训练集\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "# 加载完整测试集\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cc310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a074793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=288, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ebe047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9281428034043373\n",
      "Epoch 2, Loss: 1.6396934961723855\n",
      "Epoch 3, Loss: 1.559083075169712\n",
      "Epoch 4, Loss: 1.4930246303148587\n",
      "Epoch 5, Loss: 1.4682737817544766\n",
      "Epoch 6, Loss: 1.396606067257464\n",
      "Epoch 7, Loss: 1.377064997277906\n",
      "Epoch 8, Loss: 1.3581045259295217\n",
      "Epoch 9, Loss: 1.353447189416422\n",
      "Epoch 10, Loss: 1.3473803247027385\n",
      "Epoch 11, Loss: 1.3116161323264433\n",
      "Epoch 12, Loss: 1.3093953309461588\n",
      "Epoch 13, Loss: 1.3017824308951493\n",
      "Epoch 14, Loss: 1.2897248239163548\n",
      "Epoch 15, Loss: 1.2915869932955184\n",
      "Epoch 16, Loss: 1.2736687702900917\n",
      "Epoch 17, Loss: 1.2681980730627505\n",
      "Epoch 18, Loss: 1.2712319311888323\n",
      "Epoch 19, Loss: 1.2712471372331196\n",
      "Epoch 20, Loss: 1.2663163617443856\n",
      "Epoch 21, Loss: 1.2555104178540848\n",
      "Epoch 22, Loss: 1.2545206266291\n",
      "Epoch 23, Loss: 1.2489402580749043\n",
      "Epoch 24, Loss: 1.2474176229723275\n",
      "Epoch 25, Loss: 1.2514717136807454\n",
      "Epoch 26, Loss: 1.247416433928263\n",
      "Epoch 27, Loss: 1.2479285006328007\n",
      "Epoch 28, Loss: 1.241444101571427\n",
      "Epoch 29, Loss: 1.2431836161772003\n",
      "Epoch 30, Loss: 1.2410916707399862\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % EVAL_INTERVAL == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_dataloader)}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7228a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估基准模型的函数\n",
    "acc = 0\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = correct / total\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba8e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ConvNet on CIFAR10 is 59.45%\n"
     ]
    }
   ],
   "source": [
    "# 评估基准模型\n",
    "accuracy_convnet = evaluate_model(model, test_dataloader, device)\n",
    "print(f'Accuracy of ConvNet on CIFAR10 is {accuracy_convnet}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1224ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN : 59.45%\n"
     ]
    }
   ],
   "source": [
    "print(f\"CNN : {accuracy_convnet}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f62a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f115ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70a7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39702dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad3cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='/shareddata', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "dataset_name = 'CIFAR10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5aa0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [f\"A photo of a {class_name}\" for class_name in class_names]\n",
    "\n",
    "text_inputs = torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in class_names]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497bec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model, image):\n",
    "    \n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    logit_scale = model.logit_scale.exp()\n",
    "\n",
    "    logits = logit_scale * image_features @ text_features.t()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70b9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef19508",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): ModifiedResNet(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (attnpool): AttentionPool2d(\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VISUAL_BACKBONE = 'RN50'\n",
    "# Load the model\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device, download_root='/shareddata/clip/')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9581301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR10 is 55.60%, visual encoder is RN50.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "acc1 = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58184def",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5bfe943",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VISUAL_BACKBONE = 'ViT-B/32'\n",
    "# Load the model\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device, download_root='/shareddata/clip/')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf82530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR10 is 83.84%, visual encoder is ViT-B/32.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "acc2 = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad7d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273c157a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VISUAL_BACKBONE = 'ViT-B/16'\n",
    "# Load the model\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device, download_root='/shareddata/clip/')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00fdb387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR10 is 86.14%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "acc3 = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea1023",
   "metadata": {},
   "source": [
    "### Cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6da3f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RN50 : 55.60%\n",
      "ViT-B/32 : 83.84%\n",
      "ViT-B/16 : 86.14%\n"
     ]
    }
   ],
   "source": [
    "print(f\"RN50 : {acc1*100:.2f}%\")\n",
    "print(f\"ViT-B/32 : {acc2*100:.2f}%\")\n",
    "print(f\"ViT-B/16 : {acc3*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db986e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc1 = 55.60  # RN50\n",
    "acc2 = 83.84  # ViT-B/32\n",
    "acc3 = 86.14  # ViT-B/16\n",
    "accuracy_convnet = 59.45  # CNN\n",
    "acc_percentages = [acc1, acc2, acc3, accuracy_convnet]\n",
    "\n",
    "models = ['RN50', 'ViT-B/32', 'ViT-B/16', 'CNN']\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "# 重新绘制柱状图\n",
    "\n",
    "# 设置更大的图像尺寸\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# 绘制柱状图，增加边框宽度\n",
    "bars = plt.bar(models, acc_percentages, color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# 在柱状图上方添加数值标签\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f\"{yval:.2f}%\", ha='center', va='bottom')\n",
    "\n",
    "# 设置标题和轴标签样式\n",
    "plt.title('Model Accuracy Comparison', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Model', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 设置纵轴范围和刻度样式\n",
    "plt.ylim(0, 100)\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "# 设置横轴刻度样式\n",
    "plt.xticks(models, fontsize=12, fontweight='bold')\n",
    "\n",
    "# 添加网格线，设置透明度\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753e9d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

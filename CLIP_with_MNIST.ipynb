{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6700b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9646b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544e7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76e0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # CLIP 模型需要的输入尺寸\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # 重复通道以获得3通道图像\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 为三通道图像归一化\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5899a8f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, preprocess = clip.load('ViT-B/16', device=device)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4430c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.41%\n"
     ]
    }
   ],
   "source": [
    "# 定义手写数字的文本提示\n",
    "text_prompts = [f\"A handwritten digit {i}\" for i in range(10)]\n",
    "text_inputs = clip.tokenize(text_prompts).to(device)\n",
    "\n",
    "# 计算正确率\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # CLIP 模型推理\n",
    "        image_features = model.encode_image(images)\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "\n",
    "        # 计算相似度\n",
    "        logits = image_features @ text_features.T\n",
    "        predictions = logits.argmax(dim=-1)\n",
    "\n",
    "        # 更新正确率统计\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff8f663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Model Prediction: 9\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# 随机生成一个手写数字图像\n",
    "def generate_random_digit():\n",
    "    digit = np.random.randint(0, 10)\n",
    "    image = mnist_test.data[mnist_test.targets == digit][np.random.randint(len(mnist_test.data[mnist_test.targets == digit]))]\n",
    "    return Image.fromarray(image.numpy(), mode='L'), digit\n",
    "\n",
    "# 显示图像\n",
    "random_image, actual_digit = generate_random_digit()\n",
    "plt.imshow(random_image, cmap='gray')\n",
    "plt.title(f'Generated Digit: {actual_digit}')\n",
    "plt.show()\n",
    "\n",
    "# 应用变换并添加批处理维度\n",
    "random_image = transform(random_image).unsqueeze(0).to(device)\n",
    "\n",
    "# 使用 CLIP 模型进行分类\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(random_image)\n",
    "    logits = image_features @ text_features.T\n",
    "    predicted_digit = logits.argmax(dim=-1).item()\n",
    "\n",
    "print(f\"CLIP Model Prediction: {predicted_digit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef453ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # CLIP 模型需要的输入尺寸\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # 重复通道以获得3通道图像\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 为三通道图像归一化\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3052a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 在这里添加验证/测试代码\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

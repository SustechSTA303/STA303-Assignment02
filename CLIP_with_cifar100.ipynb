{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5d6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68f23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede2dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5172ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 定义对 CIFAR-100 测试集的转换\n",
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-100 测试集\n",
    "test_set = torchvision.datasets.CIFAR100(root='/shareddata', train=False,\n",
    "                                        download=True, transform=transform_cifar100_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# CIFAR-100 的类名列表\n",
    "class_names = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "               'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "               'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "               'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "               'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "               'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "               'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "               'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "               'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "               'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "               'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "               'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "               'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "               'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "               'worm']\n",
    "\n",
    "# 更新数据集名称\n",
    "dataset_name = 'CIFAR100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6202a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = torch.cat([clip.tokenize(f\"A photo of a {class_name}\").to(device) for class_name in class_names], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da47047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90320ec0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): ModifiedResNet(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (attnpool): AttentionPool2d(\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VISUAL_BACKBONE = 'RN50'\n",
    "# Load the model\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device, download_root='/shareddata/clip/')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9734f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model, image, text_inputs):\n",
    "    \n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    logit_scale = model.logit_scale.exp()\n",
    "\n",
    "    logits = logit_scale * image_features @ text_features.t()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74862fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR100 is 37.38%, visual encoder is RN50.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image, text_inputs)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "\n",
    "acc1 = val_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6b8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ff47c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VISUAL_BACKBONE = 'ViT-B/32'\n",
    "# Load the model\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device, download_root='/shareddata/clip/')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65fccbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR100 is 60.19%, visual encoder is ViT-B/32.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image, text_inputs)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "\n",
    "acc2 = val_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096dd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b5cca38",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VISUAL_BACKBONE = 'ViT-B/16'\n",
    "# Load the model\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device, download_root='/shareddata/clip/')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a97d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on CIFAR100 is 64.57%, visual encoder is ViT-B/16.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    val_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # test model\n",
    "        logits = model_inference(model, image, text_inputs)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        \n",
    "        val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    val_acc = val_corrects.double() / len(test_set)\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {val_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "\n",
    "acc3 = val_acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d829fb0",
   "metadata": {},
   "source": [
    "### Cifar-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9233f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RN50 : 37.38%\n",
      "ViT-B/32 : 60.19%\n",
      "ViT-B/16 : 64.57%\n"
     ]
    }
   ],
   "source": [
    "print(f\"RN50 : {acc1*100:.2f}%\")\n",
    "print(f\"ViT-B/32 : {acc2*100:.2f}%\")\n",
    "print(f\"ViT-B/16 : {acc3*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a4d3f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc1 = 37.38  # RN50\n",
    "acc2 = 60.19  # ViT-B/32\n",
    "acc3 = 64.57  # ViT-B/16\n",
    "accuracy_convnet = 25.03  # CNN\n",
    "acc_percentages = [acc1, acc2, acc3, accuracy_convnet]\n",
    "\n",
    "models = ['RN50', 'ViT-B/32', 'ViT-B/16', 'CNN']\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "# 重新绘制柱状图\n",
    "\n",
    "# 设置更大的图像尺寸\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# 绘制柱状图，增加边框宽度\n",
    "bars = plt.bar(models, acc_percentages, color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# 在柱状图上方添加数值标签\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f\"{yval:.2f}%\", ha='center', va='bottom')\n",
    "\n",
    "# 设置标题和轴标签样式\n",
    "plt.title('Model Accuracy Comparison', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Model', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 设置纵轴范围和刻度样式\n",
    "plt.ylim(0, 100)\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "# 设置横轴刻度样式\n",
    "plt.xticks(models, fontsize=12, fontweight='bold')\n",
    "\n",
    "# 添加网格线，设置透明度\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6df54b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development for Legacy model\n",
    "- Train word embeddings from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'build_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbuild_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# features = feature_extractions(\"Flickr8k_Dataset\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# #save features for future use.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# with open(\"features.pkl\", \"wb\") as f:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#    dump(features, f)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'build_model'"
     ]
    }
   ],
   "source": [
    "from build_model import *\n",
    "\n",
    "# features = feature_extractions(\"Flickr8k_Dataset\")\n",
    "\n",
    "# #save features for future use.\n",
    "# with open(\"features.pkl\", \"wb\") as f:\n",
    "#    dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Flickr8k_text/Flickr8k.token.txt\", \"r\") as f:\n",
    "    raw_caption = f.read()\n",
    "\n",
    "caption_dict = caption_dictionary(raw_caption)\n",
    "caption_dict = caption_cleaning(caption_dict)\n",
    "\n",
    "#Save the caption_dict for future use\n",
    "with open(\"captions.pkl\", \"wb\") as f:\n",
    "    dump(caption_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset(\"Flickr8k_text/Flickr_8k.trainImages.txt\")\n",
    "dev = dataset(\"Flickr8k_text/Flickr_8k.devImages.txt\")\n",
    "test = dataset(\"Flickr8k_text/Flickr_8k.testImages.txt\")\n",
    "\n",
    "train_caption_dict = load_captions(train, 1)\n",
    "train_features = load_features(train)\n",
    "dev_caption_dict = load_captions(dev, 1)\n",
    "dev_features = load_features(dev)\n",
    "test_caption_dict = load_captions(test, 0)\n",
    "test_features = load_features(test)\n",
    "\n",
    "#Initialize the tokenizer\n",
    "vocab_size = 3001\n",
    "tokenizer = create_tokenizer(train_caption_dict, num_vocab=vocab_size)\n",
    "\n",
    "#Save the tokenizer for caption_generation\n",
    "with open(\"../tokenizer.json\", \"w\") as f:\n",
    "    json.dump(tokenizer.to_json(), f)\n",
    "\n",
    "print(\"vocab size: {}\".format(vocab_size))\n",
    "max_length = max([len(c.split()) for c in caption_to_list(train_caption_dict)]) - 1 #Maximum length of input sequence\n",
    "print(\"max length: {}\".format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = \"./glove.6B/glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "#Initialize embedding matrix\n",
    "embed_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embed_dim))\n",
    "coverage = set()\n",
    "for i in range(1, vocab_size):\n",
    "    w = tokenizer.index_word[i]\n",
    "    if w in embeddings_index.keys():\n",
    "        embedding_matrix[i] = embeddings_index.get(w) #use the pre-trained embeddings, set 0 otherwise\n",
    "        coverage.add(w)\n",
    "\n",
    "oov = check_coverage(tokenizer, coverage, vocab_size=vocab_size)\n",
    "print(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoches = 10\n",
    "num_photos = 32 #photos per batch\n",
    "\n",
    "steps_per_epoch = int(len(train_caption_dict) / num_photos)\n",
    "val_steps = int(len(dev_caption_dict) / num_photos)\n",
    "\n",
    "model = define_model(max_length, vocab_size, dp_rate=0.1, embed_size=embed_dim, embedding_matrix=None)\n",
    "\n",
    "train_generator = generate_dataset(train_caption_dict, train_features, tokenizer, max_length, vocab_size, num_photos)\n",
    "dev_generator = generate_dataset(dev_caption_dict, dev_features, tokenizer, max_length, vocab_size, num_photos)\n",
    "\n",
    "for i in range(num_epoches):\n",
    "    for step in range(5*steps_per_epoch):\n",
    "        X, Y = next(train_generator)\n",
    "        model.train_on_batch(X, Y)\n",
    "    \n",
    "    model.save(\"../model/model_v{i}.h5\".format(i=i))\n",
    "    print(\"finish saving model: model_v{i}\".format(i=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluate_model(model, tokenizer, test_caption_dict, test_features, max_length, vocab_size)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

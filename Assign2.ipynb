{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 03: CLIP zero-shot prediction\n",
    "In this exercise, you will perform zero-shot prediction using CLIP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random seed\n",
    "# SEED = 1 \n",
    "# NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "# NUM_EPOCHS = 30\n",
    "# EVAL_INTERVAL=1\n",
    "# SAVE_DIR = './log'\n",
    "\n",
    "# # Optimizer\n",
    "# LEARNING_RATE = 1e-1\n",
    "# MOMENTUM = 0.9\n",
    "# STEP=5\n",
    "# GAMMA=0.5\n",
    "\n",
    "# CLIP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import tarfile\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# 定义DTD数据集路径\n",
    "dtd_data_path = \"/data/lab/STA303-Assignment02/data/dtd/images\"  # 请替换为实际的DTD数据集路径\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 数据集预处理\n",
    "class DTDDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 读取图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # 应用变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def read_data(data_path):\n",
    "    classes = os.listdir(data_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        class_images = [os.path.join(class_path, filename) for filename in os.listdir(class_path) if filename.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        class_labels = [class_name] * len(class_images)\n",
    "\n",
    "        images.extend(class_images)\n",
    "        labels.extend(class_labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# 数据集划分\n",
    "dtd_images, dtd_labels = read_data(dtd_data_path)\n",
    "\n",
    "# 定义图像变换\n",
    "dtd_image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 划分训练集和测试集\n",
    "image_label_pairs = list(zip(dtd_images, dtd_labels))\n",
    "train_data, test_data = train_test_split(image_label_pairs, test_size=0.2, random_state=1)\n",
    "\n",
    "# 创建DTD训练集和测试集\n",
    "train_dataset = DTDDataset([item[0] for item in train_data], [item[1] for item in train_data], transform=dtd_image_transform)\n",
    "test_dataset = DTDDataset([item[0] for item in test_data], [item[1] for item in test_data], transform=dtd_image_transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = ['knitted', 'crosshatched', 'scaly', 'polka-dotted', 'woven', 'stratified', 'striped', 'wrinkled', 'cobwebbed', 'smeared', 'veined', 'zigzagged', 'banded', 'fibrous', 'crystalline', 'blotchy', 'freckled', 'grooved', 'spiralled', 'marbled', 'frilly', 'interlaced', 'bubbly', 'porous', 'lacelike', 'swirly', 'bumpy', 'potholed', 'honeycombed', 'stained', 'meshed', 'sprinkled', 'pleated', 'gauzy', 'matted', 'dotted', 'paisley', 'flecked', 'studded', 'braided', 'waffled', 'chequered', 'grid', 'perforated', 'cracked', 'pitted', 'lined']\n",
    "\n",
    "dataset_name = 'DTD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(32 * 56 * 56, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'knitted': 0, 'crosshatched': 1, 'scaly': 2, 'polka-dotted': 3, 'woven': 4, 'stratified': 5, 'striped': 6, 'wrinkled': 7, 'cobwebbed': 8, 'smeared': 9, 'veined': 10, 'zigzagged': 11, 'banded': 12, 'fibrous': 13, 'crystalline': 14, 'blotchy': 15, 'freckled': 16, 'grooved': 17, 'spiralled': 18, 'marbled': 19, 'frilly':  20, 'interlaced': 21, 'bubbly': 22, 'porous': 23, 'lacelike': 24, 'swirly': 25, 'bumpy': 26, 'potholed':  27, 'honeycombed': 28, 'stained': 29, 'meshed': 30, 'sprinkled': 31, 'pleated': 32, 'gauzy': 33, 'matted': 34, 'dotted': 35, 'paisley': 36, 'flecked': 37, 'studded': 38, 'braided': 39, 'waffled': 40, 'chequered': 41, 'grid': 42, 'perforated': 43, 'cracked': 44, 'pitted': 45, 'lined': 46}\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    #for images, labels in dataloader:\n",
    "        #images, labels = images.to(device), labels.to(device)\n",
    "    for batch in dataloader:\n",
    "        #images, labels = batch[0].to(device), batch[1].to(device)\n",
    "        images = batch[0].to(device)\n",
    "        #labels = batch[1].to(device)\n",
    "        #labels = torch.tensor(batch[1], dtype=torch.long).to(device)\n",
    "        labels_str = batch[1]\n",
    "        labels = torch.tensor([label_dict[label] for label in labels_str], dtype=torch.long).to(device)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss = running_loss / len(dataloader)\n",
    "    train_acc = correct / total\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            #images, labels = images.to(device), labels.to(device)\n",
    "            images = images.to(device)\n",
    "            #labels = labels.to(device)\n",
    "            #images = batch[0].to(device)\n",
    "            #labels_str = batch[1]\n",
    "            labels_str = labels\n",
    "            labels = torch.tensor([label_dict[label] for label in labels_str], dtype=torch.long).to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    test_loss = running_loss / len(dataloader)\n",
    "    test_acc = correct / total\n",
    "    \n",
    "    return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 4.4094 | Train Acc: 0.0361\n",
      "Test Loss: 3.8398 | Test Acc: 0.0479\n",
      "--------------------------------------------------\n",
      "Epoch 2/10:\n",
      "Train Loss: 3.6644 | Train Acc: 0.0842\n",
      "Test Loss: 3.6849 | Test Acc: 0.0913\n",
      "--------------------------------------------------\n",
      "Epoch 3/10:\n",
      "Train Loss: 2.6925 | Train Acc: 0.3757\n",
      "Test Loss: 3.7445 | Test Acc: 0.1410\n",
      "--------------------------------------------------\n",
      "Epoch 4/10:\n",
      "Train Loss: 1.0444 | Train Acc: 0.7786\n",
      "Test Loss: 5.2658 | Test Acc: 0.1365\n",
      "--------------------------------------------------\n",
      "Epoch 5/10:\n",
      "Train Loss: 0.4939 | Train Acc: 0.8938\n",
      "Test Loss: 6.3754 | Test Acc: 0.1108\n",
      "--------------------------------------------------\n",
      "Epoch 6/10:\n",
      "Train Loss: 0.3174 | Train Acc: 0.9324\n",
      "Test Loss: 6.6343 | Test Acc: 0.1223\n",
      "--------------------------------------------------\n",
      "Epoch 7/10:\n",
      "Train Loss: 0.2076 | Train Acc: 0.9521\n",
      "Test Loss: 7.0997 | Test Acc: 0.1073\n",
      "--------------------------------------------------\n",
      "Epoch 8/10:\n",
      "Train Loss: 0.1607 | Train Acc: 0.9639\n",
      "Test Loss: 7.6710 | Test Acc: 0.1259\n",
      "--------------------------------------------------\n",
      "Epoch 9/10:\n",
      "Train Loss: 0.1188 | Train Acc: 0.9732\n",
      "Test Loss: 8.1847 | Test Acc: 0.1223\n",
      "--------------------------------------------------\n",
      "Epoch 10/10:\n",
      "Train Loss: 0.1101 | Train Acc: 0.9738\n",
      "Test Loss: 8.3387 | Test Acc: 0.1170\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 定义模型和损失函数\n",
    "model = BaselineModel(num_classes=len(class_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 设置训练参数\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# 开始训练和测试\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # 训练模型\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # 测试模型\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "    \n",
    "    # 打印训练和测试结果\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
